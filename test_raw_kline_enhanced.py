#!/usr/bin/env python3
"""
å¢å¼ºç‰ˆåŸå§‹Kçº¿æ•°æ®åˆ†ææµ‹è¯•è„šæœ¬
æ”¯æŒå¤šæ—¶é—´æ¡†æ¶åˆ†æå’Œæ‰¹é‡æ¨¡å‹æµ‹è¯•
"""

import asyncio
import logging
import sys
import time
import json
from datetime import datetime
from typing import Dict, Any, List

from data.binance_fetcher import BinanceFetcher
from ai.openrouter_client import OpenRouterClient
from formatters.data_formatter import DataFormatter
from config import Settings

# è®¾ç½®é¡¹ç›®è·¯å¾„
sys.path.append('/opt/ai-trader')

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class EnhancedKLineAnalyzer:
    """å¢å¼ºç‰ˆKçº¿åˆ†æå™¨"""
    
    def __init__(self):
        self.fetcher = BinanceFetcher()
        self.client = OpenRouterClient()
        self.formatter = DataFormatter()
        
        # å¤šæ—¶é—´æ¡†æ¶é…ç½®
        self.timeframes = {
            '1d': {'weight': 0.4, 'data_points': 30, 'priority': 'high'},
            '4h': {'weight': 0.3, 'data_points': 50, 'priority': 'high'},
            '1h': {'weight': 0.2, 'data_points': 100, 'priority': 'medium'},
            '15m': {'weight': 0.1, 'data_points': 200, 'priority': 'low'}
        }
    
    async def multi_timeframe_analysis(self, symbol: str = 'ETH/USDT', 
                                     model: str = 'gemini-flash') -> Dict[str, Any]:
        """å¤šæ—¶é—´æ¡†æ¶åˆ†æ"""
        print(f"ğŸ” å¼€å§‹å¤šæ—¶é—´æ¡†æ¶åˆ†æ: {symbol}")
        
        timeframe_results = {}
        total_cost = 0
        
        for tf, config in self.timeframes.items():
            print(f"\nâ° åˆ†ææ—¶é—´æ¡†æ¶: {tf} (æƒé‡: {config['weight']:.1%})")
            
            try:
                # è·å–æ•°æ®
                df = self.fetcher.get_ohlcv(symbol, tf, config['data_points'])
                current_price = df['close'].iloc[-1]
                price_change = ((df['close'].iloc[-1] / df['close'].iloc[0]) - 1) * 100
                
                print(f"   ğŸ“Š è·å–{len(df)}æ¡{tf}æ•°æ®, å½“å‰ä»·æ ¼: ${current_price:.2f}")
                print(f"   ğŸ“ˆ åŒºé—´æ¶¨è·Œ: {price_change:+.2f}%")
                
                # æ ¼å¼åŒ–æ•°æ®
                raw_data = self.formatter.to_csv_format(df.tail(min(30, len(df))))
                
                # æ„å»ºæç¤ºè¯
                prompt = self._build_timeframe_prompt(tf, raw_data, symbol)
                
                # AIåˆ†æ
                start_time = time.time()
                result = self.client.generate_response(prompt, model)
                analysis_time = time.time() - start_time
                
                if result.get('success'):
                    # æˆæœ¬è®¡ç®—
                    cost = self.client.estimate_cost(
                        model,
                        result['usage']['prompt_tokens'],
                        result['usage']['completion_tokens']
                    )['estimated_cost']
                    
                    total_cost += cost
                    
                    print(f"   âœ… åˆ†æå®Œæˆ: {analysis_time:.1f}s, ${cost:.6f}")
                    
                    # å­˜å‚¨ç»“æœ
                    timeframe_results[tf] = {
                        'analysis': result['analysis'],
                        'weight': config['weight'],
                        'priority': config['priority'],
                        'cost': cost,
                        'time': analysis_time,
                        'market_data': {
                            'current_price': current_price,
                            'price_change': price_change,
                            'data_points': len(df)
                        }
                    }
                    
                    # æ˜¾ç¤ºç®€è¦åˆ†æ
                    summary = result['analysis'][:150] + "..." if len(result['analysis']) > 150 else result['analysis']
                    print(f"   ğŸ“ {summary}")
                    
                else:
                    print(f"   âŒ åˆ†æå¤±è´¥: {result.get('error')}")
                    timeframe_results[tf] = {
                        'error': result.get('error'),
                        'weight': config['weight']
                    }
                
                # é¿å…é¢‘ç‡é™åˆ¶
                await asyncio.sleep(1)
                
            except Exception as e:
                print(f"   âŒ {tf}åˆ†æå¼‚å¸¸: {e}")
                timeframe_results[tf] = {
                    'error': str(e),
                    'weight': config['weight']
                }
        
        # ç”Ÿæˆç»¼åˆåˆ†æ
        consensus = self._calculate_timeframe_consensus(timeframe_results)
        
        return {
            'timeframe_results': timeframe_results,
            'consensus': consensus,
            'total_cost': total_cost,
            'symbol': symbol,
            'timestamp': datetime.now().isoformat()
        }
    
    def _build_timeframe_prompt(self, timeframe: str, raw_data: str, symbol: str) -> str:
        """æ„å»ºæ—¶é—´æ¡†æ¶ç‰¹å®šçš„åˆ†ææç¤ºè¯"""
        
        timeframe_context = {
            '1d': "æ—¥çº¿çº§åˆ«åˆ†æï¼Œé‡ç‚¹å…³æ³¨ä¸»è¦è¶‹åŠ¿å’Œé•¿æœŸå¸‚åœºé˜¶æ®µ",
            '4h': "4å°æ—¶çº§åˆ«åˆ†æï¼Œå…³æ³¨ä¸­æœŸè¶‹åŠ¿ç¡®è®¤å’Œé‡è¦æŠ€æœ¯ä½",
            '1h': "å°æ—¶çº§åˆ«åˆ†æï¼Œå…³æ³¨çŸ­æœŸè¶‹åŠ¿å’Œå…¥åœºæ—¶æœº",
            '15m': "15åˆ†é’Ÿçº§åˆ«åˆ†æï¼Œå…³æ³¨ç²¾ç¡®å…¥åœºå’Œå¾®è§‚ç»“æ„"
        }
        
        return f"""ä½ æ˜¯ä¸“ä¸šçš„{timeframe_context.get(timeframe, '')}åˆ†æå¸ˆã€‚

è¯·åˆ†æä»¥ä¸‹{symbol} {timeframe}æ—¶é—´æ¡†æ¶çš„åŸå§‹Kçº¿æ•°æ®ï¼š

{raw_data}

è¯·æä¾›ä¸“ä¸šçš„VPAåˆ†æï¼ŒåŒ…æ‹¬ï¼š
1. è¯¥æ—¶é—´æ¡†æ¶ä¸‹çš„è¶‹åŠ¿æ–¹å‘å’Œå¼ºåº¦
2. å…³é”®æ”¯æ’‘é˜»åŠ›ä½è¯†åˆ«  
3. æˆäº¤é‡ä¸ä»·æ ¼å…³ç³»åˆ†æ
4. Anna Coulling VSAä¿¡å·è¯†åˆ«
5. é’ˆå¯¹{timeframe}æ—¶é—´æ¡†æ¶çš„äº¤æ˜“å»ºè®®

æ³¨æ„ï¼š
- ä½¿ç”¨ä¸“ä¸šVPA/VSAæœ¯è¯­
- å¼•ç”¨å…·ä½“ä»·æ ¼æ•°æ®
- æä¾›è¯¥æ—¶é—´æ¡†æ¶ä¸‹çš„é£é™©è¯„ä¼°
- è€ƒè™‘{timeframe}çº§åˆ«çš„æ“ä½œç‰¹ç‚¹"""

    def _calculate_timeframe_consensus(self, timeframe_results: Dict) -> Dict[str, Any]:
        """è®¡ç®—å¤šæ—¶é—´æ¡†æ¶å…±è¯†"""
        
        if not timeframe_results:
            return {'error': 'No valid timeframe results'}
        
        # æå–æˆåŠŸçš„åˆ†æç»“æœ
        valid_results = {tf: result for tf, result in timeframe_results.items() 
                        if 'analysis' in result}
        
        if not valid_results:
            return {'error': 'No successful analyses'}
        
        consensus = {
            'trend_signals': {},
            'vpa_signals': {},
            'confidence_score': 0,
            'weighted_recommendation': '',
            'timeframe_alignment': 0
        }
        
        # åˆ†æè¶‹åŠ¿ä¸€è‡´æ€§
        trend_votes = {'bullish': 0, 'bearish': 0, 'neutral': 0}
        
        for tf, result in valid_results.items():
            analysis = result['analysis'].lower()
            weight = result['weight']
            
            # è¶‹åŠ¿æŠ•ç¥¨
            if any(word in analysis for word in ['bullish', 'uptrend', 'çœ‹æ¶¨', 'ä¸Šå‡']):
                trend_votes['bullish'] += weight
            elif any(word in analysis for word in ['bearish', 'downtrend', 'çœ‹è·Œ', 'ä¸‹é™']):
                trend_votes['bearish'] += weight
            else:
                trend_votes['neutral'] += weight
        
        # ç¡®å®šä¸»å¯¼è¶‹åŠ¿
        dominant_trend = max(trend_votes, key=trend_votes.get)
        trend_strength = trend_votes[dominant_trend]
        
        consensus['trend_signals'] = {
            'dominant_trend': dominant_trend,
            'strength': trend_strength,
            'votes': trend_votes
        }
        
        # è®¡ç®—æ—¶é—´æ¡†æ¶å¯¹é½åº¦
        alignment_score = trend_strength  # ä¸»å¯¼è¶‹åŠ¿çš„æƒé‡æ€»å’Œ
        consensus['timeframe_alignment'] = round(alignment_score * 100, 1)
        
        # ç½®ä¿¡åº¦è¯„åˆ†
        if alignment_score >= 0.7:
            consensus['confidence_score'] = 90
        elif alignment_score >= 0.5:
            consensus['confidence_score'] = 75
        else:
            consensus['confidence_score'] = 60
        
        # ç”Ÿæˆç»¼åˆå»ºè®®
        if dominant_trend == 'bullish' and alignment_score >= 0.6:
            consensus['weighted_recommendation'] = f"å¤šæ—¶é—´æ¡†æ¶çœ‹æ¶¨ç¡®è®¤ï¼Œå»ºè®®é€¢ä½åšå¤š (ç½®ä¿¡åº¦: {alignment_score:.1%})"
        elif dominant_trend == 'bearish' and alignment_score >= 0.6:
            consensus['weighted_recommendation'] = f"å¤šæ—¶é—´æ¡†æ¶çœ‹è·Œç¡®è®¤ï¼Œå»ºè®®é€¢é«˜åšç©º (ç½®ä¿¡åº¦: {alignment_score:.1%})"
        else:
            consensus['weighted_recommendation'] = f"æ—¶é—´æ¡†æ¶ä¿¡å·åˆ†æ­§ï¼Œå»ºè®®è§‚æœ›ç­‰å¾…æ˜ç¡®ä¿¡å·"
        
        return consensus

    async def batch_model_test(self, symbol: str = 'ETH/USDT', 
                              models: List[str] = None) -> Dict[str, Any]:
        """æ‰¹é‡æ¨¡å‹æµ‹è¯•"""
        
        if models is None:
            models = ['gemini-flash', 'gpt4o-mini', 'claude-haiku', 'gpt5-mini']
        
        print(f"ğŸš€ å¼€å§‹æ‰¹é‡æ¨¡å‹æµ‹è¯•: {len(models)}ä¸ªæ¨¡å‹")
        
        # è·å–æµ‹è¯•æ•°æ®
        df = self.fetcher.get_ohlcv(symbol, '1h', 50)
        raw_data = self.formatter.to_csv_format(df.tail(30))
        
        test_prompt = f"""è¯·åˆ†æä»¥ä¸‹{symbol}åŸå§‹Kçº¿æ•°æ®ï¼Œæä¾›ä¸“ä¸šVPAåˆ†æï¼š

{raw_data}

è¦æ±‚ï¼š
1. è¯†åˆ«å½“å‰è¶‹åŠ¿å’Œå¸‚åœºé˜¶æ®µ
2. æ ‡è¯†å…³é”®æ”¯æ’‘é˜»åŠ›ä½  
3. åˆ†ææˆäº¤é‡ä»·æ ¼å…³ç³»
4. æä¾›å…·ä½“äº¤æ˜“å»ºè®®å’Œé£é™©æ§åˆ¶"""

        model_results = {}
        total_cost = 0
        
        for model in models:
            print(f"\nğŸ”¬ æµ‹è¯•æ¨¡å‹: {model}")
            
            try:
                start_time = time.time()
                result = self.client.generate_response(test_prompt, model)
                analysis_time = time.time() - start_time
                
                if result.get('success'):
                    cost = self.client.estimate_cost(
                        model,
                        result['usage']['prompt_tokens'],
                        result['usage']['completion_tokens']
                    )['estimated_cost']
                    
                    total_cost += cost
                    
                    print(f"   âœ… æˆåŠŸ: {analysis_time:.1f}s, ${cost:.6f}")
                    
                    model_results[model] = {
                        'analysis': result['analysis'],
                        'cost': cost,
                        'time': analysis_time,
                        'tokens': result['usage']['total_tokens'],
                        'success': True
                    }
                    
                    # æ˜¾ç¤ºåˆ†ææ‘˜è¦
                    summary = result['analysis'][:120] + "..." if len(result['analysis']) > 120 else result['analysis']
                    print(f"   ğŸ“ {summary}")
                    
                else:
                    print(f"   âŒ å¤±è´¥: {result.get('error')}")
                    model_results[model] = {
                        'error': result.get('error'),
                        'success': False
                    }
                
                # é¿å…é¢‘ç‡é™åˆ¶
                await asyncio.sleep(1)
                
            except Exception as e:
                print(f"   âŒ å¼‚å¸¸: {e}")
                model_results[model] = {
                    'error': str(e),
                    'success': False
                }
        
        # ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š
        comparison = self._generate_model_comparison(model_results, total_cost)
        
        return {
            'model_results': model_results,
            'comparison': comparison,
            'total_cost': total_cost,
            'symbol': symbol,
            'timestamp': datetime.now().isoformat()
        }
    
    def _generate_model_comparison(self, model_results: Dict, total_cost: float) -> Dict[str, Any]:
        """ç”Ÿæˆæ¨¡å‹å¯¹æ¯”æŠ¥å‘Š"""
        
        successful_models = {model: result for model, result in model_results.items() 
                           if result.get('success', False)}
        
        if not successful_models:
            return {'error': 'No successful model tests'}
        
        comparison = {
            'performance_ranking': [],
            'cost_ranking': [],
            'speed_ranking': [],
            'summary': {}
        }
        
        # æ€§èƒ½æ’å (æŒ‰å“åº”æ—¶é—´)
        speed_sorted = sorted(successful_models.items(), key=lambda x: x[1]['time'])
        comparison['speed_ranking'] = [(model, f"{result['time']:.1f}s") 
                                     for model, result in speed_sorted]
        
        # æˆæœ¬æ’å
        cost_sorted = sorted(successful_models.items(), key=lambda x: x[1]['cost'])
        comparison['cost_ranking'] = [(model, f"${result['cost']:.6f}") 
                                    for model, result in cost_sorted]
        
        # è´¨é‡è¯„ä¼° (æŒ‰åˆ†æé•¿åº¦å’Œä¸“ä¸šæœ¯è¯­)
        quality_scores = {}
        for model, result in successful_models.items():
            analysis = result['analysis'].lower()
            
            # åŸºç¡€è´¨é‡è¯„åˆ†
            quality_score = 0
            
            # é•¿åº¦è¯„åˆ† (åˆç†é•¿åº¦)
            length = len(result['analysis'])
            if 500 <= length <= 2000:
                quality_score += 30
            elif length > 300:
                quality_score += 20
            
            # VPAæœ¯è¯­è¯„åˆ†
            vpa_terms = ['vsa', 'volume', 'support', 'resistance', 'trend', 'bullish', 'bearish']
            vpa_count = sum(1 for term in vpa_terms if term in analysis)
            quality_score += min(vpa_count * 10, 40)
            
            # æ•°å€¼å¼•ç”¨è¯„åˆ†
            import re
            price_mentions = len(re.findall(r'\d+[\.,]?\d*', result['analysis']))
            quality_score += min(price_mentions * 2, 30)
            
            quality_scores[model] = quality_score
        
        quality_sorted = sorted(quality_scores.items(), key=lambda x: x[1], reverse=True)
        comparison['performance_ranking'] = [(model, f"{score}/100") 
                                          for model, score in quality_sorted]
        
        # ç»¼åˆè¯„åˆ†
        comparison['summary'] = {
            'total_models_tested': len(model_results),
            'successful_tests': len(successful_models),
            'success_rate': len(successful_models) / len(model_results) * 100,
            'total_cost': total_cost,
            'fastest_model': speed_sorted[0][0] if speed_sorted else None,
            'cheapest_model': cost_sorted[0][0] if cost_sorted else None,
            'highest_quality': quality_sorted[0][0] if quality_sorted else None
        }
        
        return comparison


async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¢å¼ºç‰ˆåŸå§‹Kçº¿æ•°æ®åˆ†ææµ‹è¯•")
    print("æ”¯æŒå¤šæ—¶é—´æ¡†æ¶åˆ†æå’Œæ‰¹é‡æ¨¡å‹æµ‹è¯•")
    print("="*60)
    
    try:
        # éªŒè¯APIé…ç½®
        Settings.validate()
        print("âœ… APIé…ç½®éªŒè¯é€šè¿‡")
        
        # åˆå§‹åŒ–åˆ†æå™¨
        analyzer = EnhancedKLineAnalyzer()
        
        # é€‰æ‹©æµ‹è¯•æ¨¡å¼
        print("\nè¯·é€‰æ‹©æµ‹è¯•æ¨¡å¼:")
        print("1. å¤šæ—¶é—´æ¡†æ¶åˆ†æ")
        print("2. æ‰¹é‡æ¨¡å‹æµ‹è¯•")
        print("3. å®Œæ•´æµ‹è¯• (ä¸¤ç§æ¨¡å¼)")
        
        # é»˜è®¤æ‰§è¡Œå®Œæ•´æµ‹è¯•
        choice = "3"
        
        results = {}
        
        if choice in ["1", "3"]:
            print("\n" + "="*40)
            print("ğŸ“Š æ‰§è¡Œå¤šæ—¶é—´æ¡†æ¶åˆ†æ")
            print("="*40)
            
            mtf_result = await analyzer.multi_timeframe_analysis('ETH/USDT', 'gemini-flash')
            results['multi_timeframe'] = mtf_result
            
            # æ˜¾ç¤ºå…±è¯†ç»“æœ
            consensus = mtf_result.get('consensus', {})
            if 'error' not in consensus:
                print(f"\nğŸ¯ å¤šæ—¶é—´æ¡†æ¶å…±è¯†ç»“æœ:")
                print(f"   ä¸»å¯¼è¶‹åŠ¿: {consensus['trend_signals']['dominant_trend']}")
                print(f"   æ—¶é—´æ¡†æ¶å¯¹é½åº¦: {consensus['timeframe_alignment']}%")
                print(f"   ç½®ä¿¡åº¦: {consensus['confidence_score']}/100")
                print(f"   ç»¼åˆå»ºè®®: {consensus['weighted_recommendation']}")
        
        if choice in ["2", "3"]:
            print("\n" + "="*40)
            print("ğŸ”¬ æ‰§è¡Œæ‰¹é‡æ¨¡å‹æµ‹è¯•")
            print("="*40)
            
            batch_result = await analyzer.batch_model_test('ETH/USDT')
            results['batch_models'] = batch_result
            
            # æ˜¾ç¤ºå¯¹æ¯”ç»“æœ
            comparison = batch_result.get('comparison', {})
            if 'error' not in comparison:
                summary = comparison['summary']
                print(f"\nğŸ“ˆ æ‰¹é‡æµ‹è¯•ç»“æœæ±‡æ€»:")
                print(f"   æˆåŠŸç‡: {summary['success_rate']:.1f}%")
                print(f"   æ€»æˆæœ¬: ${summary['total_cost']:.6f}")
                print(f"   æœ€å¿«æ¨¡å‹: {summary['fastest_model']}")
                print(f"   æœ€çœé’±æ¨¡å‹: {summary['cheapest_model']}")
                print(f"   æœ€é«˜è´¨é‡: {summary['highest_quality']}")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = f"/opt/ai-trader/results/enhanced_analysis_report_{timestamp}.json"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        print("="*60)
        print("ğŸ‰ å¢å¼ºç‰ˆæµ‹è¯•å®Œæˆï¼")
        
        return True
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")
        import traceback  # pylint: disable=import-outside-toplevel
        traceback.print_exc()
        return False


if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nâ¹ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error("âŒ ç¨‹åºå¼‚å¸¸: %s", e)
        import traceback  # pylint: disable=import-outside-toplevel
        traceback.print_exc()