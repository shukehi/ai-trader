# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview
AI-Trader - A streamlined AI-powered trading analysis system that validates modern LLM models can directly analyze raw OHLCV data for professional Volume Price Analysis (VPA). **Core breakthrough: AI directly understands raw candlestick data without traditional technical indicator preprocessing.**

**ðŸ† System Status**: Production-ready AI-direct analysis system (simplified architecture)
**ðŸŽ¯ Current Architecture**: Pure AI Direct Analysis - focused on API data retrieval and AI analysis

### ðŸš€ **AI-Direct Analysis Architecture**
**Complete elimination of traditional technical analysis preprocessing**:
- **AI-Direct Analysis**: RawDataAnalyzer handles direct OHLCV interpretation
- **Verified Quality**: 80-100/100 professional VPA analysis scores achieved
- **Efficiency Revolution**: Dramatic simplification vs traditional methods
- **Architecture Simplification**: ~80% code reduction, focused AI-centric design

## Core Architecture: Simplified AI-Direct Data Understanding

### Streamlined Data Flow
```
Raw OHLCV Data â†’ AI Direct Analysis â†’ Professional VPA Report
     â†“                    â†“                     â†“
Binance API     RawDataAnalyzer/AnalysisEngine    Analysis Results
(No Preprocessing)       (Pure AI)              (Text Output)
```

**Key Innovation**: No intermediate calculations - AI directly comprehends market data patterns.

### Multi-Model AI Support
- **Fast Analysis**: gemini-flash (optimized for speed)
- **Balanced Quality**: gpt4o-mini, claude (standard analysis)
- **Premium Quality**: gpt5-chat, claude-opus-41 (highest quality)

## Essential Commands

### ðŸŽ¯ **AI Direct Analysis (Enhanced Typer + Rich CLI)**
```bash
# Core AI analysis commands
python main.py analyze                                            # Basic analysis with defaults
python main.py analyze --symbol BTCUSDT --model claude           # Custom symbol and model
python main.py analyze -s ETHUSDT -m gemini-flash -a enhanced    # Enhanced analysis (short flags)

# Analysis with specific methods
python main.py analyze --method volume-analysis-vpa-classic      # VPA analysis
python main.py analyze --method ict-concepts-fair-value-gaps     # ICT FVG analysis
python main.py analyze --method price-action-trend-analysis      # Price action analysis

# Utility commands
python main.py methods                                           # List all available analysis methods
python main.py config                                           # Configuration management
python main.py demo                                             # Quick demonstration

# Verbose and debugging
python main.py analyze --verbose                                # Show detailed logs
python main.py analyze --help                                   # Command help

# See CLI_USAGE.md for comprehensive usage examples and output formatting
```

### ðŸŽ¨ **Rich CLI Features (NEW)**
- **Beautiful Progress Bars**: Real-time analysis progress with spinners and timers
- **Rich Tables**: Formatted market data display with colors
- **Interactive Prompts**: User-friendly configuration and demo modes  
- **Panel Displays**: Elegant result presentation with borders and styling
- **Color-coded Output**: Success (green), errors (red), info (blue), warnings (yellow)
- **Professional Layout**: Structured information display with proper spacing


### ðŸ”§ **Development Environment Setup**
```bash
# Environment preparation
source venv/bin/activate
pip install -r requirements.txt

# API configuration (see .env.example for complete template)
cp .env.example .env
# Edit .env to add:
# OPENROUTER_API_KEY=your_openrouter_api_key_here
# DEFAULT_MODELS=gpt4o-mini,claude-haiku,gemini-flash
# FLAGSHIP_MODELS=gpt5-chat,gpt5-mini,claude-opus-41

# Core system validation
python -c "from config import Settings; Settings.validate()"
python -c "from ai import RawDataAnalyzer; print('AI Direct Analysis ready')"
python -c "from data import BinanceFetcher; print('Data fetching ready')"
python -c "from formatters import DataFormatter; print('Data formatting ready')"
```

### ðŸ§ª **Component Testing**
```bash
# Individual component testing
python -c "from ai import RawDataAnalyzer; analyzer = RawDataAnalyzer(); print('âœ… RawDataAnalyzer ready')"
python -c "from ai import AnalysisEngine; engine = AnalysisEngine(); print('âœ… AnalysisEngine ready')"
python -c "from data import BinanceFetcher; fetcher = BinanceFetcher(); print('âœ… BinanceFetcher ready')"

# Test data retrieval (no AI analysis)
python -c "
from data import BinanceFetcher
fetcher = BinanceFetcher()
df = fetcher.get_ohlcv('ETH/USDT', '1h', 5)
print(f'âœ… Data retrieved: {len(df)} records')
print(f'Latest price: ${df.iloc[-1][\"close\"]:.2f}')
"
```

## Token Management System
**Critical Recent Change**: Removed hardcoded 4000 token response limits for better analysis quality.

### Dynamic Token Allocation
- **Analysis-Type Based**: Different response ratios (30%-60%) based on analysis complexity
- **Model-Aware**: Utilizes full model capacity (e.g., Gemini-Flash 1M tokens, Claude 200K tokens)
- **Smart Allocation**: `max_response_tokens = max(1000, min(available_response_tokens, max_model_tokens - estimated_tokens - 500))`
- **Safety Mechanisms**: 70% input warning threshold, minimum 1000 token guarantee

### Response Space by Analysis Type
```python
response_ratios = {
    'general': 0.3,
    'vpa': 0.5,
    'technical': 0.4, 
    'pattern': 0.4,
    'perpetual_vpa': 0.6,  # VPA analysis needs more space
    'raw_vpa': 0.5
}
```

## Architecture Deep Dive

### Core Components (Simplified Design)

#### 1. **RawDataAnalyzer** (`ai/raw_data_analyzer.py`)
**Primary analysis engine** - directly processes raw OHLCV data:
- `analyze_raw_ohlcv()`: Single model analysis with quality scoring and external prompt support
- Supports all analysis types: simple, complete, enhanced  
- **NEW**: Supports `analysis_method` parameter for external prompt system
- Built-in quality scoring and performance metrics (specialized evaluators per method)
- **Key Change**: Batch analysis methods removed for system simplification
- Returns structured results: `{'analysis_text', 'quality_score', 'performance_metrics', 'market_context'}`

#### 2. **AnalysisEngine** (`ai/analysis_engine.py`)
**Simplified analysis interface**:
- `raw_data_analysis()`: Core AI analysis method
- Streamlined prompt building for different analysis types
- Direct integration with OpenRouterClient

#### 3. **OpenRouterClient** (`ai/openrouter_client.py`)
**Unified LLM interface** supporting 15+ models:
- GPT-5 series, Claude models, Gemini series, Llama, Grok
- Dynamic response token allocation based on model capacity and analysis type
- Methods: `analyze_market_data()`, `generate_response()`
- **Recent Update**: Removed hardcoded 4000 token limits, implements intelligent allocation

#### 4. **DataFormatter** (`formatters/data_formatter.py`)
**Token-optimized data formats**:
- `to_csv_format()`: Raw OHLCV for AI consumption (primary format)
- Token optimization: price precision to 2 decimals, volume as integers
- Multiple format options for different use cases

#### 5. **BinanceFetcher** (`data/binance_fetcher.py`)
**Market data retrieval**:
- CCXT-based Binance perpetual futures API integration
- Automatic symbol format handling (ETHUSDT â†” ETH/USDT)
- Rate limiting and error handling

#### 6. **Settings** (`config/settings.py`)
**Configuration management**:
- OpenRouter API key management
- Model definitions and mappings
- Environment variable handling

#### 7. **PromptManager** (`prompts/prompt_manager.py`) **NEW**
**External prompt management system**:
- Loads analysis-specific prompts from external files
- Supports multiple analysis methodologies: VPA, ICT, Price Action
- Method-specific quality evaluators
- Caching and dynamic prompt loading
- Available methods: `list_available_methods()`, `get_method_info()`, `load_prompt()`

### Simplified Data Flow Pipeline
1. **BinanceFetcher** â†’ Raw OHLCV data from Binance API
2. **DataFormatter** â†’ Token-optimized CSV format for AI
3. **PromptManager** â†’ Load external analysis method prompts (if specified)
4. **RawDataAnalyzer/AnalysisEngine** â†’ Direct AI interpretation with method-specific prompts
5. **OpenRouterClient** â†’ LLM model execution
6. **Formatted Results** â†’ Professional analysis text (VPA/ICT/Price Action specific)

## Important Development Patterns

### Key Result Structure
When main.py displays results, it expects these keys from RawDataAnalyzer:
- `result['analysis_text']` - The main analysis content (NOT `result['analysis']`)
- `result['quality_score']` - 5-dimensional quality evaluation (0-100)
- `result['performance_metrics']['analysis_time']` - Response timing
- `result['success']` - Boolean success indicator

### Error Handling Pattern
RawDataAnalyzer vs AnalysisEngine return different error structures:
- RawDataAnalyzer: `{'error': str(e), 'success': False}`
- AnalysisEngine: `{'analysis': f'åˆ†æžå¤±è´¥: {error}', 'success': False}`

### Model Selection Strategy
Focus on single-model analysis (batch methods removed):
- **Development/Testing**: `gemini-flash` (fast, economical)
- **Production/Quality**: `claude`, `gpt4o-mini` 
- **Premium Analysis**: `gpt5-mini`, `claude-opus-41`

## Development Workflow

### Quick Start Development
```bash
# 1. Environment setup
source venv/bin/activate
pip install -r requirements.txt

# 2. Configuration (see .env.example for all available options)
cp .env.example .env
# Edit .env to add OPENROUTER_API_KEY and configure model preferences

# 3. Verify setup
python -c "from config import Settings; Settings.validate(); print('âœ… Configuration valid')"

# 4. Test basic functionality (no API calls)
python -c "
from ai import RawDataAnalyzer
from data import BinanceFetcher
analyzer = RawDataAnalyzer()
fetcher = BinanceFetcher()
print('âœ… All components initialized successfully')
"
```

### Development Testing
```bash
# Test data retrieval only
python -c "
from data import BinanceFetcher
fetcher = BinanceFetcher()
df = fetcher.get_ohlcv('ETH/USDT', '1h', 10)
print('Data shape:', df.shape)
"

# Test AI analysis with fast model (NEW Typer CLI)
python main.py analyze --model gemini-flash --limit 10

# Full analysis with specific method
python main.py analyze --analysis-type complete --method volume-analysis-vpa-classic

# Test configuration and system status
python main.py config

# Quick demonstration
python main.py demo
```

## Critical Dependencies

### Core Requirements (Minimal Set)
- **openai>=1.0.0**: OpenRouter API client
- **python-dotenv>=1.0.0**: Environment configuration
- **requests>=2.31.0**: HTTP client for API calls
- **pandas>=2.0.0**: Data manipulation
- **numpy>=1.24.0**: Numerical operations
- **ccxt>=4.0.0**: Binance API integration
- **websockets>=11.0.0**: Real-time data support
- **aiohttp>=3.8.0**: Async HTTP operations
- **python-dateutil>=2.8.0, pytz>=2023.3**: Time handling
- **typer>=0.12.0**: Modern CLI framework (NEW)
- **rich>=13.0.0**: Beautiful console output (NEW)

### Architecture Simplifications
- **No traditional technical analysis libraries** (ta, talib removed)
- **No complex testing frameworks** (test files removed)
- **No trading execution system** (trading modules removed)
- **No deployment scripts** (deployment directory removed)
- **No batch analysis** (multi-model comparison removed for focus)
- **No TUI framework** (Textual removed, replaced with Typer + Rich)

### Recent System Changes (Important)
- **TUI Removed**: Complex Textual-based TUI interface eliminated for simplicity
- **Typer + Rich CLI**: Modern CLI with beautiful formatting and progress bars
- **Token Limits Removed**: Hardcoded 4000 token response limits eliminated
- **Batch Analysis Removed**: `--batch-models` flag and related methods deleted
- **Focus on Quality**: Single-model analysis optimization over multi-model comparison
- **Dynamic Allocation**: Smart token distribution based on analysis type and model capacity
- **External Prompt System**: Prompts externalized to files, supporting multiple analysis methodologies

## External Prompt Management System

### Available Analysis Methods
The system now supports specialized analysis methodologies through external prompt files:

**Volume Analysis Methods:**
- `volume-analysis-vpa-classic`: Classical VPA (Volume Price Analysis) based on Wyckoff theory
- `volume-analysis-vsa-coulling`: Anna Coulling VSA (Volume Spread Analysis) methodology

**ICT Concepts Methods:**
- `ict-concepts-fair-value-gaps`: ICT Fair Value Gap identification and analysis
- `ict-concepts-liquidity-zones`: ICT liquidity analysis and order flow
- `ict-concepts-order-blocks`: ICT order block identification and mitigation

**Price Action Methods:**
- `price-action-support-resistance`: Support and resistance level analysis
- `price-action-trend-analysis`: Trend structure analysis using Dow theory

### Method Discovery
```bash
# List all available analysis methods with descriptions (NEW Typer CLI)
python main.py methods
```

### Quality Evaluation System
Each analysis method has specialized quality evaluators:
- **VPA/VSA**: VSA signal identification, market phase analysis, volume-price relationship scoring
- **ICT**: FVG quality assessment, confluence analysis, structure identification
- **Price Action**: Trend integrity, S&R strength, pattern completion scoring

### Prompt System Architecture
- **External Files**: Prompts stored in `/prompts/` directory, organized by methodology
- **Dynamic Loading**: PromptManager loads appropriate prompts based on selected method
- **Fallback Mechanism**: System falls back to default prompts if external method fails
- **Caching**: Loaded prompts are cached for performance

## Performance Benchmarks (Verified)
- **Speed**: 5-7 seconds average response time
- **Quality**: 80-100/100 professional VPA scores
- **Efficiency**: 99%+ simplification vs traditional technical analysis
- **Token Optimization**: Optimized CSV format reduces tokens by ~60%

## File Structure (Actual)
```
/opt/ai-trader/
â”œâ”€â”€ ai/                    # AI Analysis Core
â”‚   â”œâ”€â”€ __init__.py        # Module exports
â”‚   â”œâ”€â”€ raw_data_analyzer.py    # Primary AI analyzer
â”‚   â”œâ”€â”€ analysis_engine.py      # Simplified analysis engine
â”‚   â””â”€â”€ openrouter_client.py    # LLM API client
â”œâ”€â”€ data/                  # Market Data
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ binance_fetcher.py      # Binance API integration
â”‚   â””â”€â”€ binance_websocket.py    # WebSocket support
â”œâ”€â”€ config/                # Configuration
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py            # API keys and model config
â”œâ”€â”€ formatters/            # Data Formatting
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ data_formatter.py      # AI-optimized formats
â”œâ”€â”€ prompts/               # External Prompt System (NEW)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ prompt_manager.py       # Prompt management and loading
â”‚   â”œâ”€â”€ composite/              # Composite analysis prompts
â”‚   â”œâ”€â”€ volume_analysis/        # VPA and VSA analysis prompts
â”‚   â”‚   â”œâ”€â”€ vpa_classic.txt     # Classical VPA analysis
â”‚   â”‚   â””â”€â”€ vsa_coulling.txt    # Anna Coulling VSA methodology
â”‚   â”œâ”€â”€ ict_concepts/           # ICT (Inner Circle Trader) prompts
â”‚   â”‚   â”œâ”€â”€ fair_value_gaps.txt      # FVG analysis
â”‚   â”‚   â”œâ”€â”€ liquidity_zones.txt      # Liquidity analysis
â”‚   â”‚   â””â”€â”€ order_blocks.txt         # Order block identification
â”‚   â””â”€â”€ price_action/           # Price action analysis prompts
â”‚       â”œâ”€â”€ support_resistance.txt   # S&R analysis
â”‚       â””â”€â”€ trend_analysis.txt       # Trend structure analysis
â”œâ”€â”€ main.py               # Enhanced CLI with Typer + Rich
â”œâ”€â”€ main_old.py           # Previous version (legacy)
â”œâ”€â”€ requirements.txt      # Dependencies (with Typer + Rich)
â”œâ”€â”€ CLI_USAGE.md         # Comprehensive CLI usage examples
â”œâ”€â”€ CLAUDE.md            # This file
â”œâ”€â”€ .env.example         # Environment configuration template
â””â”€â”€ venv/                # Python virtual environment
```

## Architecture Philosophy: Why AI-Direct Analysis

### Traditional Approach Problems (Eliminated)
- **Complex Pipeline**: Raw Data â†’ 20+ Indicators â†’ Rule Engine â†’ Signals
- **High Maintenance**: Constant indicator tuning and rule adjustment
- **Computing Overhead**: Extensive mathematical preprocessing
- **Brittle Logic**: Hard-coded rules break with market changes

### AI-Direct Approach Benefits (Current System)
- **Simplified Pipeline**: Raw Data â†’ AI Analysis â†’ Professional Signals
- **Self-Learning**: AI adapts to new market patterns automatically
- **Minimal Computing**: Direct data interpretation, no preprocessing
- **Robust Analysis**: Natural language understanding of market dynamics

### System Validation
- **Quality Verified**: 80-100/100 scores on professional VPA criteria
- **Efficiency Validated**: 99%+ reduction in computational complexity
- **Speed Confirmed**: <7 second response times
- **Production Ready**: Streamlined architecture, minimal dependencies

This architecture represents a fundamental shift from traditional quantitative analysis to natural language understanding of market data, implemented in a simplified, maintainable codebase.

## Additional Resources

### Documentation Files
- **CLI_USAGE.md**: Comprehensive CLI usage guide with Rich formatting examples and parameter details
- **.env.example**: Complete environment configuration template with all available models and settings
- **main_old.py**: Legacy implementation for comparison (do not use for development)

### Model Configuration Reference (from .env.example)
```bash
# Economy models for development/testing
ECONOMY_MODELS=gpt5-nano,gpt4o-mini,claude-haiku,gemini-flash

# Balanced models for production
BALANCED_MODELS=gpt5-mini,gpt4o,claude,gemini

# Premium models for highest quality analysis
PREMIUM_MODELS=gpt5-chat,claude-opus-41,gemini-25-pro,o1
```