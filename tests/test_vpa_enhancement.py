#!/usr/bin/env python3
"""
VPAå¢å¼ºåŠŸèƒ½ä¸“é¡¹æµ‹è¯•
éªŒè¯VSAåˆ†æã€æ°¸ç»­åˆçº¦ç‰¹è‰²ã€å¤šæ—¶é—´æ¡†æ¶ç­‰æ–°åŠŸèƒ½

æµ‹è¯•è¦†ç›–ï¼š
1. VSAè®¡ç®—å™¨åŠŸèƒ½æµ‹è¯•
2. æ°¸ç»­åˆçº¦æ•°æ®è·å–æµ‹è¯•  
3. å¤šæ—¶é—´æ¡†æ¶åˆ†ææµ‹è¯•
4. å¢å¼ºå…±è¯†è®¡ç®—å™¨æµ‹è¯•
5. Patternæ ¼å¼VPAæè¿°æµ‹è¯•
"""

import unittest
import sys
import os
import pandas as pd
import numpy as np
from unittest.mock import Mock, patch, MagicMock
from datetime import datetime, timezone

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from data.vsa_calculator import VSACalculator, VSASignalType, SpreadType
from data.binance_fetcher import BinanceFetcher
from data.data_processor import DataProcessor
from ai.timeframe_analyzer import TimeframeAnalyzer, TimeframeSignal, MultiTimeframeAnalysis
from ai.consensus_calculator import ConsensusCalculator, VPASignal
from formatters.data_formatter import DataFormatter

class TestVSACalculator(unittest.TestCase):
    """VSAè®¡ç®—å™¨æµ‹è¯•"""
    
    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.vsa_calculator = VSACalculator()
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        self.test_df = pd.DataFrame({
            'datetime': pd.date_range('2025-01-01', periods=50, freq='H'),
            'open': np.random.uniform(4000, 4500, 50),
            'high': np.random.uniform(4100, 4600, 50),
            'low': np.random.uniform(3900, 4400, 50),
            'close': np.random.uniform(4000, 4500, 50),
            'volume': np.random.uniform(100000, 1000000, 50)
        })
        
        # ç¡®ä¿OHLCé€»è¾‘æ­£ç¡®
        for i in range(len(self.test_df)):
            high = max(self.test_df.iloc[i]['open'], self.test_df.iloc[i]['close']) + np.random.uniform(0, 50)
            low = min(self.test_df.iloc[i]['open'], self.test_df.iloc[i]['close']) - np.random.uniform(0, 50)
            self.test_df.at[i, 'high'] = high
            self.test_df.at[i, 'low'] = low
    
    def test_vsa_indicators_calculation(self):
        """æµ‹è¯•VSAæŒ‡æ ‡è®¡ç®—"""
        result_df = self.vsa_calculator.calculate_vsa_indicators(self.test_df)
        
        # æ£€æŸ¥æ–°å¢çš„VSAåˆ—
        expected_columns = [
            'spread', 'close_position', 'volume_ratio', 'spread_type',
            'vsa_signal', 'signal_strength', 'professional_activity',
            'effort_result_ratio', 'supply_demand_balance'
        ]
        
        for col in expected_columns:
            self.assertIn(col, result_df.columns, f"ç¼ºå°‘VSAæŒ‡æ ‡: {col}")
        
        # æ£€æŸ¥æ•°æ®ç±»å‹å’ŒèŒƒå›´
        self.assertTrue(all(result_df['close_position'].between(0, 1)), 
                       "close_positionåº”è¯¥åœ¨0-1èŒƒå›´å†…")
        self.assertTrue(all(result_df['signal_strength'].between(0, 1)), 
                       "signal_strengthåº”è¯¥åœ¨0-1èŒƒå›´å†…")
        self.assertTrue(all(result_df['supply_demand_balance'].between(-1, 1)), 
                       "supply_demand_balanceåº”è¯¥åœ¨-1åˆ°1èŒƒå›´å†…")
    
    def test_vsa_signal_identification(self):
        """æµ‹è¯•VSAä¿¡å·è¯†åˆ«"""
        # åˆ›å»ºç‰¹å®šçš„æµ‹è¯•åœºæ™¯
        
        # No Demandåœºæ™¯ï¼šä¸Šæ¶¨ä½†ä½æˆäº¤é‡
        test_df = self.test_df.copy()
        test_df.at[test_df.index[-1], 'close'] = test_df.iloc[-1]['open'] + 50  # ä¸Šæ¶¨
        test_df.at[test_df.index[-1], 'volume'] = test_df['volume'].mean() * 0.5  # ä½é‡
        
        result_df = self.vsa_calculator.calculate_vsa_indicators(test_df)
        
        # åº”è¯¥æ£€æµ‹åˆ°æŸäº›VSAä¿¡å·
        self.assertIsNotNone(result_df['vsa_signal'].iloc[-1])
        self.assertIn(result_df['vsa_signal'].iloc[-1], [signal.value for signal in VSASignalType])
    
    def test_vsa_summary_generation(self):
        """æµ‹è¯•VSAæ‘˜è¦ç”Ÿæˆ"""
        summary = self.vsa_calculator.get_vsa_summary(self.test_df)
        
        expected_keys = [
            'signal_distribution', 'professional_activity_count',
            'recent_strong_signals', 'supply_demand_balance',
            'latest_vsa_signal', 'latest_signal_strength',
            'wide_spread_count', 'narrow_spread_count'
        ]
        
        for key in expected_keys:
            self.assertIn(key, summary, f"VSAæ‘˜è¦ç¼ºå°‘: {key}")
        
        # æ£€æŸ¥æ•°æ®ç±»å‹
        self.assertIsInstance(summary['professional_activity_count'], int)
        self.assertIsInstance(summary['supply_demand_balance'], float)
        self.assertIsInstance(summary['latest_signal_strength'], float)
    
    def test_vsa_interpretation(self):
        """æµ‹è¯•VSAä¿¡å·è§£é‡Š"""
        summary = self.vsa_calculator.get_vsa_summary(self.test_df)
        interpretation = self.vsa_calculator.interpret_vsa_signals(summary)
        
        self.assertIsInstance(interpretation, str)
        self.assertGreater(len(interpretation), 0, "VSAè§£é‡Šä¸åº”ä¸ºç©º")

class TestPerpetualDataFetching(unittest.TestCase):
    """æ°¸ç»­åˆçº¦æ•°æ®è·å–æµ‹è¯•"""
    
    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.fetcher = BinanceFetcher()
    
    @patch('ccxt.binance')
    def test_funding_rate_fetching(self, mock_exchange):
        """æµ‹è¯•èµ„é‡‘è´¹ç‡è·å–"""
        # Mockèµ„é‡‘è´¹ç‡å“åº”
        mock_exchange.return_value.fetch_funding_rate.return_value = {
            'symbol': 'ETH/USDT',
            'fundingRate': 0.0001,
            'timestamp': 1640995200000,
            'datetime': '2022-01-01T00:00:00.000Z'
        }
        
        # è¿™é‡Œéœ€è¦å®é™…æµ‹è¯•æ—¶éœ€è¦æœ‰æ•ˆçš„APIè¿æ¥
        # å½“å‰åªæµ‹è¯•æ¥å£å­˜åœ¨æ€§
        self.assertTrue(hasattr(self.fetcher, 'get_funding_rate'))
        self.assertTrue(hasattr(self.fetcher, 'get_funding_rate_history'))
        self.assertTrue(hasattr(self.fetcher, 'get_open_interest'))
        self.assertTrue(hasattr(self.fetcher, 'get_perpetual_data'))
    
    def test_perpetual_data_structure(self):
        """æµ‹è¯•æ°¸ç»­åˆçº¦æ•°æ®ç»“æ„"""
        # æµ‹è¯•æ–¹æ³•æ˜¯å¦å­˜åœ¨å’Œè¿”å›æ ¼å¼
        with patch.object(self.fetcher, 'get_ohlcv') as mock_ohlcv, \
             patch.object(self.fetcher, 'get_funding_rate') as mock_funding, \
             patch.object(self.fetcher, 'get_open_interest') as mock_oi, \
             patch.object(self.fetcher, 'get_funding_rate_history') as mock_funding_hist:
            
            # Mockè¿”å›å€¼
            mock_ohlcv.return_value = pd.DataFrame({
                'datetime': ['2025-01-01 00:00:00'],
                'open': [4000], 'high': [4100], 'low': [3900], 
                'close': [4050], 'volume': [100000]
            })
            mock_funding.return_value = {'fundingRate': 0.0001}
            mock_oi.return_value = {'openInterestAmount': 1000000}
            mock_funding_hist.return_value = pd.DataFrame({'fundingRate': [0.0001, 0.0002]})
            
            try:
                result = self.fetcher.get_perpetual_data()
                
                # æ£€æŸ¥è¿”å›ç»“æ„
                expected_keys = ['ohlcv_data', 'current_funding_rate', 
                               'open_interest', 'funding_rate_history', 'stats']
                for key in expected_keys:
                    self.assertIn(key, result, f"æ°¸ç»­åˆçº¦æ•°æ®ç¼ºå°‘: {key}")
                    
            except Exception as e:
                # å¦‚æœæ²¡æœ‰APIè¿æ¥ï¼Œè·³è¿‡å®é™…è°ƒç”¨æµ‹è¯•
                self.skipTest(f"éœ€è¦æœ‰æ•ˆçš„APIè¿æ¥: {e}")

class TestTimeframeAnalyzer(unittest.TestCase):
    """å¤šæ—¶é—´æ¡†æ¶åˆ†æå™¨æµ‹è¯•"""
    
    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.analyzer = TimeframeAnalyzer()
    
    def test_timeframe_config(self):
        """æµ‹è¯•æ—¶é—´æ¡†æ¶é…ç½®"""
        config = self.analyzer.timeframe_config
        
        # æ£€æŸ¥é…ç½®å®Œæ•´æ€§
        expected_timeframes = ['1d', '4h', '1h', '15m']
        for tf in expected_timeframes:
            self.assertIn(tf, config, f"ç¼ºå°‘æ—¶é—´æ¡†æ¶é…ç½®: {tf}")
            
            # æ£€æŸ¥æ¯ä¸ªé…ç½®çš„å¿…è¦å­—æ®µ
            tf_config = config[tf]
            self.assertIn('importance', tf_config)
            self.assertIn('weight', tf_config)
            self.assertIn('limit', tf_config)
            self.assertIn('description', tf_config)
        
        # æ£€æŸ¥æƒé‡æ€»å’Œ
        total_weight = sum(tf_config['weight'] for tf_config in config.values())
        self.assertAlmostEqual(total_weight, 1.0, places=1, 
                              msg="æ—¶é—´æ¡†æ¶æƒé‡æ€»å’Œåº”æ¥è¿‘1.0")
    
    @patch('data.binance_fetcher.BinanceFetcher.get_ohlcv')
    @patch('data.data_processor.DataProcessor.add_vsa_indicators')
    def test_single_timeframe_analysis(self, mock_vsa, mock_ohlcv):
        """æµ‹è¯•å•æ—¶é—´æ¡†æ¶åˆ†æ"""
        # Mockæ•°æ®
        mock_df = pd.DataFrame({
            'datetime': pd.date_range('2025-01-01', periods=50, freq='H'),
            'open': np.random.uniform(4000, 4500, 50),
            'high': np.random.uniform(4100, 4600, 50),
            'low': np.random.uniform(3900, 4400, 50),
            'close': np.random.uniform(4000, 4500, 50),
            'volume': np.random.uniform(100000, 1000000, 50),
            'vsa_signal': ['normal'] * 50,
            'professional_activity': [False] * 50,
            'supply_demand_balance': np.random.uniform(-1, 1, 50)
        })
        
        mock_ohlcv.return_value = mock_df
        mock_vsa.return_value = mock_df
        
        # æµ‹è¯•å•ä¸ªæ—¶é—´æ¡†æ¶åˆ†æ
        signal = self.analyzer._analyze_single_timeframe('ETH/USDT', '1h')
        
        if signal is not None:
            self.assertIsInstance(signal, TimeframeSignal)
            self.assertEqual(signal.timeframe, '1h')
            self.assertIsNotNone(signal.market_phase)
            self.assertIsNotNone(signal.vpa_signal)
        else:
            self.skipTest("ä¿¡å·åˆ†æè¿”å›Noneï¼Œå¯èƒ½æ˜¯ç”±äºæ•°æ®ä¸è¶³æˆ–APIé™åˆ¶")
    
    def test_consensus_calculation(self):
        """æµ‹è¯•å…±è¯†è®¡ç®—"""
        # åˆ›å»ºæµ‹è¯•ä¿¡å·
        signals = [
            TimeframeSignal(
                timeframe='1d',
                importance=self.analyzer.timeframe_config['1d']['importance'],
                market_phase='accumulation',
                vpa_signal='bullish',
                price_direction='up',
                signal_strength=0.8
            ),
            TimeframeSignal(
                timeframe='4h',
                importance=self.analyzer.timeframe_config['4h']['importance'],
                market_phase='accumulation',
                vpa_signal='bullish',
                price_direction='up',
                signal_strength=0.7
            )
        ]
        
        consensus = self.analyzer._calculate_consensus_score(signals)
        
        self.assertIsInstance(consensus, float)
        self.assertGreaterEqual(consensus, 0.0)
        self.assertLessEqual(consensus, 1.0)
        
        # å®Œå…¨ä¸€è‡´çš„ä¿¡å·åº”è¯¥æœ‰é«˜å…±è¯†
        self.assertGreater(consensus, 0.8, "å®Œå…¨ä¸€è‡´çš„ä¿¡å·åº”è¯¥æœ‰é«˜å…±è¯†å¾—åˆ†")

class TestEnhancedConsensusCalculator(unittest.TestCase):
    """å¢å¼ºå…±è¯†è®¡ç®—å™¨æµ‹è¯•"""
    
    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.calculator = ConsensusCalculator()
    
    def test_enhanced_weight_structure(self):
        """æµ‹è¯•å¢å¼ºçš„æƒé‡ç»“æ„"""
        weights = self.calculator.weights
        
        # æ£€æŸ¥æ–°å¢çš„æƒé‡ç»´åº¦
        expected_dimensions = [
            'market_phase', 'vpa_signal', 'price_direction',
            'vsa_signals', 'timeframe_consistency', 'perpetual_factors',
            'confidence'
        ]
        
        for dimension in expected_dimensions:
            self.assertIn(dimension, weights, f"ç¼ºå°‘æƒé‡ç»´åº¦: {dimension}")
        
        # æ£€æŸ¥æƒé‡æ€»å’Œ
        total_weight = sum(weights.values())
        self.assertAlmostEqual(total_weight, 1.0, places=2, 
                              msg="æƒé‡æ€»å’Œåº”ä¸º1.0")
    
    def test_vsa_signal_extraction(self):
        """æµ‹è¯•VSAä¿¡å·æå–"""
        test_analysis = """
        åŸºäºVSAåˆ†æï¼Œå½“å‰å¸‚åœºæ˜¾ç¤ºå‡ºæ˜æ˜¾çš„No Demandä¿¡å·ï¼Œä¸Šæ¶¨ç¼ºä¹æˆäº¤é‡æ”¯æŒã€‚
        åŒæ—¶æ£€æµ‹åˆ°Wide Spreadç°è±¡ï¼Œè¡¨æ˜å¸‚åœºæ³¢åŠ¨åŠ å‰§ã€‚
        ä»å¤šæ—¶é—´æ¡†æ¶æ¥çœ‹ï¼Œå„å‘¨æœŸä¿¡å·åŸºæœ¬ä¸€è‡´ã€‚
        æ°¸ç»­åˆçº¦çš„æ­£èµ„é‡‘è´¹ç‡æ˜¾ç¤ºå¤šå¤´æƒ…ç»ªæµ“åšã€‚
        """
        
        signal = self.calculator._extract_vpa_signals(test_analysis, 'test_model')
        
        # æ£€æŸ¥æ–°å¢å­—æ®µ
        self.assertIsInstance(signal.vsa_signals, list)
        self.assertIsInstance(signal.perpetual_factors, list)
        self.assertIsNotNone(signal.timeframe_consistency)
        
        # æ£€æŸ¥VSAä¿¡å·æ˜¯å¦è¢«æ­£ç¡®è¯†åˆ«
        if signal.vsa_signals:
            self.assertIn('no_demand', signal.vsa_signals)
            self.assertIn('wide_spread', signal.vsa_signals)
    
    def test_list_consensus_calculation(self):
        """æµ‹è¯•åˆ—è¡¨ç±»å‹å…±è¯†è®¡ç®—"""
        # åˆ›å»ºæµ‹è¯•ä¿¡å·
        model_signals = {
            'model1': VPASignal(
                vsa_signals=['no_demand', 'wide_spread'],
                perpetual_factors=['funding_rate_positive']
            ),
            'model2': VPASignal(
                vsa_signals=['no_demand', 'climax_volume'],
                perpetual_factors=['funding_rate_positive', 'leverage_effect']
            ),
            'model3': VPASignal(
                vsa_signals=['wide_spread'],
                perpetual_factors=['funding_rate_positive']
            )
        }
        
        # æµ‹è¯•VSAä¿¡å·ä¸€è‡´æ€§
        vsa_consensus = self.calculator._calculate_list_consensus(model_signals, 'vsa_signals')
        self.assertIsInstance(vsa_consensus, float)
        self.assertGreaterEqual(vsa_consensus, 0.0)
        self.assertLessEqual(vsa_consensus, 1.0)
        
        # æµ‹è¯•æ°¸ç»­åˆçº¦å› ç´ ä¸€è‡´æ€§
        perpetual_consensus = self.calculator._calculate_list_consensus(model_signals, 'perpetual_factors')
        self.assertIsInstance(perpetual_consensus, float)

class TestEnhancedPatternFormat(unittest.TestCase):
    """å¢å¼ºPatternæ ¼å¼æµ‹è¯•"""
    
    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.formatter = DataFormatter()
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        self.test_df = pd.DataFrame({
            'datetime': [f'2025-01-01 {i:02d}:00:00' for i in range(24)],
            'open': np.random.uniform(4000, 4500, 24),
            'high': np.random.uniform(4100, 4600, 24),
            'low': np.random.uniform(3900, 4400, 24),
            'close': np.random.uniform(4000, 4500, 24),
            'volume': np.random.uniform(100000, 1000000, 24)
        })
        
        # ç¡®ä¿OHLCé€»è¾‘æ­£ç¡®
        for i in range(len(self.test_df)):
            high = max(self.test_df.iloc[i]['open'], self.test_df.iloc[i]['close']) + np.random.uniform(0, 50)
            low = min(self.test_df.iloc[i]['open'], self.test_df.iloc[i]['close']) - np.random.uniform(0, 50)
            self.test_df.at[i, 'high'] = high
            self.test_df.at[i, 'low'] = low
    
    def test_enhanced_pattern_description(self):
        """æµ‹è¯•å¢å¼ºçš„Patternæè¿°"""
        result = self.formatter.to_pattern_description(
            self.test_df, 
            include_vsa=True, 
            include_perpetual_context=True
        )
        
        self.assertIsInstance(result, str)
        self.assertGreater(len(result), 0)
        
        # æ£€æŸ¥VPAä¸“ä¸šå†…å®¹
        vpa_keywords = [
            'VPA', 'VSA', 'Volume Spread Analysis', 
            'Smart Money', 'Professional', 'Wyckoff',
            'æ°¸ç»­åˆçº¦', 'èµ„é‡‘è´¹ç‡', 'æŒä»“é‡'
        ]
        
        result_lower = result.lower()
        found_keywords = [kw for kw in vpa_keywords if kw.lower() in result_lower]
        self.assertGreater(len(found_keywords), 3, 
                          f"åº”åŒ…å«æ›´å¤šVPAä¸“ä¸šæœ¯è¯­ï¼Œå½“å‰æ‰¾åˆ°: {found_keywords}")
    
    def test_vsa_analysis_formatting(self):
        """æµ‹è¯•VSAåˆ†ææ ¼å¼åŒ–"""
        vsa_lines = self.formatter._format_vsa_analysis(self.test_df)
        
        self.assertIsInstance(vsa_lines, list)
        self.assertGreater(len(vsa_lines), 0)
        
        # æ£€æŸ¥VSAä¸“ä¸šæœ¯è¯­
        vsa_content = ' '.join(vsa_lines)
        vsa_terms = ['Wide Spread', 'Close Position', 'No Demand', 'No Supply', 'Climax Volume']
        
        # è‡³å°‘åº”è¯¥åŒ…å«VSAåˆ†æçš„æ¡†æ¶
        self.assertIn('VSA', vsa_content)
    
    def test_perpetual_context_formatting(self):
        """æµ‹è¯•æ°¸ç»­åˆçº¦èƒŒæ™¯æ ¼å¼åŒ–"""
        perpetual_lines = self.formatter._format_perpetual_context()
        
        self.assertIsInstance(perpetual_lines, list)
        self.assertGreater(len(perpetual_lines), 0)
        
        # æ£€æŸ¥æ°¸ç»­åˆçº¦ä¸“ä¸šæœ¯è¯­
        perpetual_content = ' '.join(perpetual_lines)
        perpetual_terms = ['èµ„é‡‘è´¹ç‡', 'æŒä»“é‡', 'æ æ†', 'Smart Money', 'å¼ºå¹³']
        
        found_terms = [term for term in perpetual_terms if term in perpetual_content]
        self.assertGreater(len(found_terms), 2, 
                          f"åº”åŒ…å«æ›´å¤šæ°¸ç»­åˆçº¦æœ¯è¯­ï¼Œå½“å‰æ‰¾åˆ°: {found_terms}")

class TestVPAIntegration(unittest.TestCase):
    """VPAåŠŸèƒ½é›†æˆæµ‹è¯•"""
    
    def setUp(self):
        """è®¾ç½®æµ‹è¯•ç¯å¢ƒ"""
        self.processor = DataProcessor()
        self.formatter = DataFormatter()
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        self.test_df = pd.DataFrame({
            'datetime': pd.date_range('2025-01-01', periods=50, freq='H'),
            'open': np.random.uniform(4000, 4500, 50),
            'high': np.random.uniform(4100, 4600, 50),
            'low': np.random.uniform(3900, 4400, 50),
            'close': np.random.uniform(4000, 4500, 50),
            'volume': np.random.uniform(100000, 1000000, 50)
        })
    
    def test_vsa_integration_with_data_processor(self):
        """æµ‹è¯•VSAä¸æ•°æ®å¤„ç†å™¨çš„é›†æˆ"""
        # æ·»åŠ VSAæŒ‡æ ‡
        result_df = self.processor.add_vsa_indicators(self.test_df)
        
        # æ£€æŸ¥VSAæŒ‡æ ‡æ˜¯å¦è¢«æ­£ç¡®æ·»åŠ 
        vsa_columns = ['spread', 'close_position', 'volume_ratio', 'vsa_signal']
        for col in vsa_columns:
            self.assertIn(col, result_df.columns, f"ç¼ºå°‘VSAæŒ‡æ ‡: {col}")
        
        # è·å–VSAæ‘˜è¦
        summary = self.processor.get_vsa_summary(self.test_df)
        self.assertIsInstance(summary, dict)
        self.assertIn('latest_vsa_signal', summary)
        
        # è·å–VSAè§£é‡Š
        interpretation = self.processor.interpret_vsa_signals(summary)
        self.assertIsInstance(interpretation, str)
        self.assertGreater(len(interpretation), 0)
    
    def test_enhanced_pattern_with_vsa(self):
        """æµ‹è¯•å¢å¼ºPatternæ ¼å¼ä¸VSAçš„é›†æˆ"""
        # ç”Ÿæˆå¢å¼ºçš„Patternæè¿°
        pattern_text = self.formatter.to_pattern_description(
            self.test_df, 
            include_vsa=True, 
            include_perpetual_context=True
        )
        
        # æ£€æŸ¥é›†æˆæ•ˆæœ
        self.assertIn('VSA', pattern_text)
        self.assertIn('æ°¸ç»­åˆçº¦', pattern_text)
        self.assertIn('Wyckoff', pattern_text)
        
        # æ£€æŸ¥æ ¼å¼ç»“æ„
        sections = pattern_text.split('##')
        self.assertGreater(len(sections), 3, "åº”åŒ…å«å¤šä¸ªåˆ†æç« èŠ‚")

def run_vpa_enhancement_tests():
    """è¿è¡ŒVPAå¢å¼ºåŠŸèƒ½æµ‹è¯•å¥—ä»¶"""
    print("=" * 60)
    print("ğŸ§ª VPAå¢å¼ºåŠŸèƒ½æµ‹è¯•å¥—ä»¶")
    print("=" * 60)
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    test_classes = [
        TestVSACalculator,
        TestPerpetualDataFetching,
        TestTimeframeAnalyzer,
        TestEnhancedConsensusCalculator,
        TestEnhancedPatternFormat,
        TestVPAIntegration
    ]
    
    suite = unittest.TestSuite()
    
    for test_class in test_classes:
        tests = unittest.TestLoader().loadTestsFromTestCase(test_class)
        suite.addTests(tests)
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    # è¾“å‡ºæµ‹è¯•ç»“æœæ‘˜è¦
    print("\n" + "=" * 60)
    print("ğŸ“Š VPAå¢å¼ºåŠŸèƒ½æµ‹è¯•ç»“æœæ‘˜è¦")
    print("=" * 60)
    print(f"âœ… é€šè¿‡æµ‹è¯•: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"âŒ å¤±è´¥æµ‹è¯•: {len(result.failures)}")
    print(f"ğŸ’¥ é”™è¯¯æµ‹è¯•: {len(result.errors)}")
    print(f"â­ï¸  è·³è¿‡æµ‹è¯•: {len(result.skipped) if hasattr(result, 'skipped') else 0}")
    
    if result.failures:
        print("\nâŒ å¤±è´¥çš„æµ‹è¯•:")
        for test, traceback in result.failures:
            last_line = traceback.split('\n')[-2]
            print(f"  - {test}: {last_line}")
    
    if result.errors:
        print("\nğŸ’¥ é”™è¯¯çš„æµ‹è¯•:")
        for test, traceback in result.errors:
            last_line = traceback.split('\n')[-2]
            print(f"  - {test}: {last_line}")
    
    # è¯„ä¼°æ•´ä½“æˆåŠŸç‡
    success_rate = (result.testsRun - len(result.failures) - len(result.errors)) / result.testsRun * 100
    print(f"\nğŸ¯ æ•´ä½“æˆåŠŸç‡: {success_rate:.1f}%")
    
    if success_rate >= 90:
        print("ğŸ† VPAå¢å¼ºåŠŸèƒ½æµ‹è¯•è¡¨ç°ä¼˜ç§€!")
    elif success_rate >= 75:
        print("âœ… VPAå¢å¼ºåŠŸèƒ½æµ‹è¯•åŸºæœ¬é€šè¿‡")
    else:
        print("âš ï¸ VPAå¢å¼ºåŠŸèƒ½éœ€è¦è¿›ä¸€æ­¥æ”¹è¿›")
    
    return result

if __name__ == '__main__':
    run_vpa_enhancement_tests()