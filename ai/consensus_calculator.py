#!/usr/bin/env python3
"""
å…±è¯†ç®—æ³•æ¨¡å—
è®¡ç®—å¤šæ¨¡å‹åˆ†æç»“æœçš„ä¸€è‡´æ€§å’Œå…±è¯†å¾—åˆ†
"""

import re
from typing import Dict, List, Any, Optional
from dataclasses import dataclass
from collections import Counter
import logging

logger = logging.getLogger(__name__)

@dataclass
class VPASignal:
    """å¢å¼ºçš„VPAä¿¡å·æå–ç»“æœ"""
    market_phase: Optional[str] = None  # Accumulation, Distribution, Markup, Markdown
    vpa_signal: Optional[str] = None    # bullish, bearish, neutral
    price_direction: Optional[str] = None  # up, down, sideways
    confidence: Optional[str] = None    # high, medium, low
    vsa_signals: Optional[List[str]] = None       # VSAä¸“ä¸šä¿¡å· (æ–°å¢)
    timeframe_consistency: Optional[str] = None  # æ—¶é—´æ¡†æ¶ä¸€è‡´æ€§ (æ–°å¢)
    perpetual_factors: Optional[List[str]] = None          # æ°¸ç»­åˆçº¦å› ç´  (æ–°å¢)
    key_levels: Optional[List[float]] = None      # å…³é”®ä»·ä½

    def __post_init__(self):
        if self.key_levels is None:
            self.key_levels = []
        if self.vsa_signals is None:
            self.vsa_signals = []
        if self.perpetual_factors is None:
            self.perpetual_factors = []

class ConsensusCalculator:
    """
    å…±è¯†è®¡ç®—å™¨
    
    åŠŸèƒ½ï¼š
    1. ä»åˆ†ææ–‡æœ¬ä¸­æå–å…³é”®æŒ‡æ ‡
    2. è®¡ç®—æ¨¡å‹é—´ä¸€è‡´æ€§å¾—åˆ†
    3. è¯†åˆ«å…·ä½“åˆ†æ­§ç‚¹
    4. ç”Ÿæˆå…±è¯†æ‘˜è¦
    """
    
    def __init__(self):
        # å¢å¼ºçš„VPAæƒé‡é…ç½® (ä¼˜åŒ–å7ç»´åº¦)
        self.weights = {
            'market_phase': 0.25,      # å¸‚åœºé˜¶æ®µ (é™ä½ä»¥å¹³è¡¡å…¶ä»–ç»´åº¦)
            'vpa_signal': 0.20,        # VPAä¿¡å·
            'price_direction': 0.20,   # ä»·æ ¼æ–¹å‘
            'vsa_signals': 0.15,       # VSAä¸“ä¸šä¿¡å· (æ–°å¢)
            'timeframe_consistency': 0.10,  # æ—¶é—´æ¡†æ¶ä¸€è‡´æ€§ (æ–°å¢)
            'perpetual_factors': 0.05,      # æ°¸ç»­åˆçº¦ç‰¹æ®Šå› ç´  (æ–°å¢)
            'confidence': 0.05         # ç½®ä¿¡åº¦ (é™ä½æƒé‡)
        }
        
        # æ¨¡å¼åŒ¹é…è§„åˆ™
        self._init_patterns()
        
        logger.info("âœ… ConsensusCalculatoråˆå§‹åŒ–å®Œæˆ")
    
    def _init_patterns(self):
        """åˆå§‹åŒ–æ–‡æœ¬æ¨¡å¼åŒ¹é…è§„åˆ™"""
        
        # å¸‚åœºé˜¶æ®µå…³é”®è¯
        self.market_phase_patterns = {
            'accumulation': [
                r'accumulation', r'å¸ç­¹', r'æ”¶é›†', r'å»ºä»“', r'ä¹°å…¥ç´¯ç§¯',
                r'wyckoff.*accumulation', r'smart.*money.*buying'
            ],
            'distribution': [
                r'distribution', r'æ´¾å‘', r'åˆ†é…', r'å‡ºè´§', r'è·åˆ©äº†ç»“',
                r'wyckoff.*distribution', r'smart.*money.*selling'
            ],
            'markup': [
                r'markup', r'æ‹‰å‡', r'ä¸Šæ¶¨é˜¶æ®µ', r'ç‰›å¸‚', r'æ¨å‡',
                r'bullish.*trend', r'upward.*movement'
            ],
            'markdown': [
                r'markdown', r'ä¸‹è·Œé˜¶æ®µ', r'ç†Šå¸‚', r'å›è°ƒ', r'ä¸‹é™',
                r'bearish.*trend', r'downward.*movement'
            ]
        }
        
        # VPAä¿¡å·å…³é”®è¯
        self.vpa_signal_patterns = {
            'bullish': [
                r'bullish', r'çœ‹æ¶¨', r'ä¹°å…¥', r'åšå¤š', r'ä¸Šæ¶¨ä¿¡å·',
                r'positive.*signal', r'buy.*signal', r'å¥åº·.*ä¸Šæ¶¨'
            ],
            'bearish': [
                r'bearish', r'çœ‹è·Œ', r'å–å‡º', r'åšç©º', r'ä¸‹è·Œä¿¡å·',
                r'negative.*signal', r'sell.*signal', r'å¥åº·.*ä¸‹è·Œ'
            ],
            'neutral': [
                r'neutral', r'ä¸­æ€§', r'éœ‡è¡', r'ç›˜æ•´', r'è§‚æœ›',
                r'sideways', r'range.*bound', r'wait.*and.*see'
            ]
        }
        
        # ä»·æ ¼æ–¹å‘å…³é”®è¯
        self.price_direction_patterns = {
            'up': [
                r'ä¸Šæ¶¨', r'ä¸Šå‡', r'çªç ´', r'å†²é«˜', r'åå¼¹',
                r'upward', r'rising', r'breakout', r'rally'
            ],
            'down': [
                r'ä¸‹è·Œ', r'ä¸‹é™', r'è·³æ°´', r'å›è½', r'æš´è·Œ',
                r'downward', r'falling', r'decline', r'dump'
            ],
            'sideways': [
                r'æ¨ªç›˜', r'éœ‡è¡', r'ç›˜æ•´', r'çª„å¹…', r'æ•´ç†',
                r'sideways', r'consolidation', r'range'
            ]
        }
        
        # ç½®ä¿¡åº¦å…³é”®è¯
        self.confidence_patterns = {
            'high': [
                r'é«˜åº¦ç¡®ä¿¡', r'å¼ºçƒˆ', r'æ˜ç¡®', r'ç¡®å®š', r'è‚¯å®š', r'éå¸¸', r'ååˆ†',
                r'æ˜æ˜¾', r'æ˜¾è‘—', r'æ¸…æ™°', r'æ¯«æ— ç–‘é—®', r'ç»å¯¹',
                r'strongly', r'clearly', r'definitely', r'confident', r'certain',
                r'obvious', r'significant', r'clear', r'absolutely', r'very'
            ],
            'medium': [
                r'å¯èƒ½', r'å€¾å‘', r'å€¾å‘äº', r'æœ‰å¯èƒ½', r'è¾ƒä¸º', r'ç›¸å¯¹',
                r'é¢„è®¡', r'é¢„æœŸ', r'ä¼°è®¡', r'å¤§æ¦‚', r'æˆ–è®¸',
                r'likely', r'probably', r'tends.*to', r'appears', r'seems',
                r'expected', r'estimated', r'perhaps', r'moderate'
            ],
            'low': [
                r'ä¸ç¡®å®š', r'è°¨æ…', r'éœ€è¦è§‚å¯Ÿ', r'å­˜åœ¨é£é™©', r'å»ºè®®ç­‰å¾…',
                r'å­˜ç–‘', r'å¾…è§‚å¯Ÿ', r'éœ€è°¨æ…', r'ä¸æ˜ç¡®', r'æœ‰å¾…éªŒè¯',
                r'uncertain', r'cautious', r'risky', r'wait.*and.*see',
                r'unclear', r'questionable', r'need.*verification', r'weak'
            ]
        }
        
        # VSAä¸“ä¸šä¿¡å·å…³é”®è¯ (æ–°å¢)
        self.vsa_signal_patterns = {
            'no_demand': [
                r'no.*demand', r'éœ€æ±‚ä¸è¶³', r'æ— é‡ä¸Šæ¶¨', r'å¯ç–‘.*ä¸Šæ¶¨', r'å‡çªç ´',
                r'upthrust', r'è¯±å¤š', r'weak.*rally'
            ],
            'no_supply': [
                r'no.*supply', r'ä¾›ç»™ä¸è¶³', r'æ— é‡ä¸‹è·Œ', r'å¯ç–‘.*ä¸‹è·Œ', r'å‡è·Œç ´',
                r'spring', r'æ´—ç›˜', r'weak.*decline'
            ],
            'climax_volume': [
                r'climax.*volume', r'æˆäº¤é‡é«˜æ½®', r'æ”¾é‡', r'å·¨é‡', r'å¼‚å¸¸.*é‡',
                r'selling.*climax', r'buying.*climax', r'æç«¯.*æˆäº¤é‡'
            ],
            'wide_spread': [
                r'wide.*spread', r'å®½.*ä»·å·®', r'å¤§å¹…æ³¢åŠ¨', r'é«˜æ³¢åŠ¨', r'å‰§çƒˆ.*æ³¢åŠ¨'
            ],
            'narrow_spread': [
                r'narrow.*spread', r'çª„.*ä»·å·®', r'å°å¹…æ³¢åŠ¨', r'ä½æ³¢åŠ¨', r'æ¸©å’Œ.*æ³¢åŠ¨'
            ]
        }
        
        # æ°¸ç»­åˆçº¦ä¸“ä¸šæœ¯è¯­ (æ–°å¢)
        self.perpetual_patterns = {
            'funding_rate_positive': [
                r'æ­£.*èµ„é‡‘è´¹ç‡', r'å¤šå¤´.*è´¹ç‡', r'funding.*rate.*positive', r'å¤šå¤´.*æ”¯ä»˜'
            ],
            'funding_rate_negative': [
                r'è´Ÿ.*èµ„é‡‘è´¹ç‡', r'ç©ºå¤´.*è´¹ç‡', r'funding.*rate.*negative', r'ç©ºå¤´.*æ”¯ä»˜'
            ],
            'open_interest_increase': [
                r'æŒä»“é‡.*å¢åŠ ', r'OI.*å¢é•¿', r'open.*interest.*increase', r'æŒä»“.*ä¸Šå‡'
            ],
            'open_interest_decrease': [
                r'æŒä»“é‡.*å‡å°‘', r'OI.*ä¸‹é™', r'open.*interest.*decrease', r'æŒä»“.*ä¸‹é™'
            ],
            'leverage_effect': [
                r'æ æ†.*æ•ˆåº”', r'å¼ºå¹³', r'çˆ†ä»“', r'cascade', r'liquidation', r'margin.*call'
            ]
        }
    
    def calculate_consensus(self, results: Dict[str, Any]) -> float:
        """
        è®¡ç®—æ¨¡å‹é—´å…±è¯†å¾—åˆ†
        
        Args:
            results: {model_name: analysis_result} å­—å…¸
            
        Returns:
            float: 0-1ä¹‹é—´çš„å…±è¯†å¾—åˆ†
        """
        try:
            logger.info(f"ğŸ”„ å¼€å§‹è®¡ç®— {len(results)} ä¸ªæ¨¡å‹çš„å…±è¯†å¾—åˆ†...")
            
            # æå–æ‰€æœ‰æ¨¡å‹çš„VPAä¿¡å·
            model_signals = {}
            for model_name, result in results.items():
                if result.get('success') and result.get('analysis'):
                    signal = self._extract_vpa_signals(result['analysis'], model_name)
                    model_signals[model_name] = signal
                else:
                    logger.warning(f"âš ï¸ è·³è¿‡æ¨¡å‹ {model_name}: åˆ†æå¤±è´¥æˆ–æ— å†…å®¹")
            
            if len(model_signals) < 2:
                logger.warning("âš ï¸ æœ‰æ•ˆæ¨¡å‹å°‘äº2ä¸ªï¼Œæ— æ³•è®¡ç®—å…±è¯†")
                return 0.0
            
            # è®¡ç®—å„ç»´åº¦çš„ä¸€è‡´æ€§
            dimension_scores = {}
            for dimension, weight in self.weights.items():
                score = self._calculate_dimension_consensus(model_signals, dimension)
                dimension_scores[dimension] = score
                logger.info(f"  ğŸ“Š {dimension}: {score:.3f} (æƒé‡: {weight})")
            
            # è®¡ç®—åŠ æƒæ€»åˆ†
            consensus_score = sum(
                score * self.weights[dimension] 
                for dimension, score in dimension_scores.items()
            )
            
            logger.info(f"ğŸ¯ æœ€ç»ˆå…±è¯†å¾—åˆ†: {consensus_score:.3f}")
            return consensus_score
            
        except Exception as e:
            logger.error(f"âŒ è®¡ç®—å…±è¯†å¾—åˆ†å¤±è´¥: {e}")
            return 0.0
    
    def _extract_vpa_signals(self, analysis_text: str, model_name: str) -> VPASignal:
        """ä»åˆ†ææ–‡æœ¬ä¸­æå–å¢å¼ºçš„VPAä¿¡å·"""
        text = analysis_text.lower()
        
        # æå–ä¼ ç»ŸVPAä¿¡å·
        market_phase = self._extract_category(text, self.market_phase_patterns)
        vpa_signal = self._extract_category(text, self.vpa_signal_patterns)
        price_direction = self._extract_category(text, self.price_direction_patterns)
        confidence = self._extract_category(text, self.confidence_patterns)
        key_levels = self._extract_key_levels(text)
        
        # æå–VSAä¸“ä¸šä¿¡å· (æ–°å¢)
        vsa_signals = self._extract_multiple_categories(text, self.vsa_signal_patterns)
        
        # æå–æ—¶é—´æ¡†æ¶ä¸€è‡´æ€§ä¿¡å· (æ–°å¢)
        timeframe_consistency = self._infer_timeframe_consistency(text)
        
        # æå–æ°¸ç»­åˆçº¦å› ç´  (æ–°å¢) 
        perpetual_factors = self._extract_multiple_categories(text, self.perpetual_patterns)
        
        signal = VPASignal(
            market_phase=market_phase,
            vpa_signal=vpa_signal,
            price_direction=price_direction,
            confidence=confidence,
            vsa_signals=vsa_signals,
            timeframe_consistency=timeframe_consistency,
            perpetual_factors=perpetual_factors,
            key_levels=key_levels
        )
        
        logger.debug(f"ğŸ“ {model_name} å¢å¼ºVPAä¿¡å·: {signal}")
        return signal
    
    def _extract_category(self, text: str, patterns: Dict[str, List[str]]) -> Optional[str]:
        """ä»æ–‡æœ¬ä¸­æå–åˆ†ç±»ä¿¡æ¯"""
        scores = {}
        text_lower = text.lower()  # è½¬æ¢ä¸ºå°å†™è¿›è¡ŒåŒ¹é…
        
        for category, pattern_list in patterns.items():
            score = 0
            for pattern in pattern_list:
                # ä½¿ç”¨å¤§å°å†™æ— å…³çš„æ­£åˆ™åŒ¹é…
                matches = len(re.findall(pattern, text_lower, re.IGNORECASE))
                score += matches
            scores[category] = score
        
        # è¿”å›å¾—åˆ†æœ€é«˜çš„åˆ†ç±»
        if scores and max(scores.values()) > 0:
            return max(scores.keys(), key=lambda k: scores[k])
        
        # å¦‚æœæ˜¯ç½®ä¿¡åº¦æ¨¡å¼ï¼Œæä¾›æ™ºèƒ½é»˜è®¤å€¼
        if patterns == self.confidence_patterns:
            # åŸºäºæ–‡æœ¬é•¿åº¦å’Œå†…å®¹å¤æ‚åº¦æ¨æ–­ç½®ä¿¡åº¦
            if len(text) > 500 and ('åˆ†æ' in text or 'analysis' in text_lower):
                return 'medium'
            elif '?' in text or 'ï¼Ÿ' in text or 'maybe' in text_lower or 'æˆ–è®¸' in text:
                return 'low'
            else:
                return 'medium'  # é»˜è®¤ä¸­ç­‰ç½®ä¿¡åº¦
        
        return None
    
    def _extract_key_levels(self, text: str) -> List[float]:
        """æå–å…³é”®ä»·ä½"""
        # åŒ¹é…ä»·æ ¼æ•°å­—ï¼ˆETHé€šå¸¸åœ¨1000-10000èŒƒå›´ï¼‰
        price_patterns = [
            r'(\d{4}\.\d{1,2})',  # 4ä½.2ä½å°æ•°
            r'(\d{4})',           # 4ä½æ•´æ•°
            r'æ”¯æ’‘.*?(\d{4})',     # ä¸­æ–‡æ”¯æ’‘ä½
            r'é˜»åŠ›.*?(\d{4})',     # ä¸­æ–‡é˜»åŠ›ä½
            r'support.*?(\d{4})',  # è‹±æ–‡æ”¯æ’‘ä½
            r'resistance.*?(\d{4})' # è‹±æ–‡é˜»åŠ›ä½
        ]
        
        levels = []
        for pattern in price_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                try:
                    level = float(match)
                    if 1000 <= level <= 10000:  # ETHä»·æ ¼åˆç†èŒƒå›´
                        levels.append(level)
                except ValueError:
                    continue
        
        # å»é‡å¹¶æ’åº
        return sorted(list(set(levels)))
    
    def _extract_multiple_categories(self, text: str, patterns: Dict[str, List[str]]) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå–å¤šä¸ªåŒ¹é…çš„åˆ†ç±» (ç”¨äºVSAä¿¡å·å’Œæ°¸ç»­åˆçº¦å› ç´ )"""
        matched_categories = []
        text_lower = text.lower()
        
        for category, pattern_list in patterns.items():
            for pattern in pattern_list:
                if re.search(pattern, text_lower, re.IGNORECASE):
                    matched_categories.append(category)
                    break  # æ‰¾åˆ°ä¸€ä¸ªåŒ¹é…å°±å¤Ÿäº†ï¼Œé¿å…é‡å¤
        
        return matched_categories
    
    def _infer_timeframe_consistency(self, text: str) -> Optional[str]:
        """æ¨æ–­æ—¶é—´æ¡†æ¶ä¸€è‡´æ€§"""
        text_lower = text.lower()
        
        # æ£€æŸ¥æ˜¯å¦æåˆ°å¤šæ—¶é—´æ¡†æ¶åˆ†æ
        timeframe_indicators = [
            r'å¤š.*æ—¶é—´.*æ¡†æ¶', r'ä¸åŒ.*å‘¨æœŸ', r'æ—¥çº¿.*å°æ—¶', r'é•¿.*çŸ­.*å‘¨æœŸ',
            r'multi.*timeframe', r'different.*timeframes', r'daily.*hourly',
            r'higher.*lower.*timeframe'
        ]
        
        has_timeframe_analysis = any(
            re.search(pattern, text_lower, re.IGNORECASE) 
            for pattern in timeframe_indicators
        )
        
        if has_timeframe_analysis:
            # æ£€æŸ¥ä¸€è‡´æ€§æè¿°
            consistency_patterns = {
                'consistent': [
                    r'ä¸€è‡´', r'åŒå‘', r'æ”¯æŒ', r'ç¡®è®¤', r'å»åˆ',
                    r'consistent', r'aligned', r'confirm', r'support'
                ],
                'conflicting': [
                    r'å†²çª', r'çŸ›ç›¾', r'åˆ†æ­§', r'ä¸ä¸€è‡´', r'èƒŒç¦»',
                    r'conflict', r'diverge', r'inconsistent', r'contradict'
                ],
                'mixed': [
                    r'æ··åˆ', r'éƒ¨åˆ†', r'æœ‰é™', r'å±€éƒ¨',
                    r'mixed', r'partial', r'limited', r'some'
                ]
            }
            
            for category, pattern_list in consistency_patterns.items():
                for pattern in pattern_list:
                    if re.search(pattern, text_lower, re.IGNORECASE):
                        return category
        
        return None
    
    def _calculate_dimension_consensus(self, model_signals: Dict[str, VPASignal], dimension: str) -> float:
        """è®¡ç®—æŸä¸ªç»´åº¦çš„ä¸€è‡´æ€§å¾—åˆ† (æ”¯æŒæ–°çš„VPAç»´åº¦)"""
        if dimension == 'vsa_signals':
            return self._calculate_list_consensus(model_signals, dimension)
        elif dimension == 'perpetual_factors':
            return self._calculate_list_consensus(model_signals, dimension)
        elif dimension == 'timeframe_consistency':
            return self._calculate_categorical_consensus(model_signals, dimension)
        elif dimension == 'key_levels':
            return self._calculate_key_levels_consensus(model_signals)
        else:
            # ä¼ ç»Ÿçš„åˆ†ç±»ç»´åº¦
            return self._calculate_categorical_consensus(model_signals, dimension)
    
    def _calculate_categorical_consensus(self, model_signals: Dict[str, VPASignal], dimension: str) -> float:
        """è®¡ç®—åˆ†ç±»ç»´åº¦çš„ä¸€è‡´æ€§"""
        values = []
        
        for signal in model_signals.values():
            value = getattr(signal, dimension, None)
            if value is not None:
                values.append(value)
        
        if not values:
            return 0.0
        
        # å¯¹äºåˆ†ç±»å˜é‡ï¼Œè®¡ç®—æœ€é¢‘ç¹å€¼çš„å æ¯”
        counter = Counter(values)
        most_common_count = counter.most_common(1)[0][1]
        consensus_ratio = most_common_count / len(values)
        
        return consensus_ratio
    
    def _calculate_list_consensus(self, model_signals: Dict[str, VPASignal], dimension: str) -> float:
        """è®¡ç®—åˆ—è¡¨ç±»å‹ç»´åº¦çš„ä¸€è‡´æ€§ (VSAä¿¡å·ã€æ°¸ç»­åˆçº¦å› ç´ ç­‰)"""
        all_values: List[str] = []
        model_count = 0
        
        for signal in model_signals.values():
            value_list = getattr(signal, dimension, [])
            if value_list:
                all_values.extend(value_list)
                model_count += 1
        
        if not all_values or model_count == 0:
            return 0.0
        
        # è®¡ç®—å„ç±»åˆ«çš„å‡ºç°é¢‘ç‡
        counter = Counter(all_values)
        total_mentions = len(all_values)
        
        # è®¡ç®—åŠ æƒä¸€è‡´æ€§ï¼šè€ƒè™‘æœ€é¢‘ç¹é¡¹ç›®çš„å æ¯”å’Œæ¨¡å‹è¦†ç›–ç‡
        if counter:
            most_common_count = counter.most_common(1)[0][1]
            frequency_consensus = most_common_count / total_mentions
            coverage_bonus = min(model_count / len(model_signals), 1.0) * 0.2
            
            return min(frequency_consensus + coverage_bonus, 1.0)
        
        return 0.0
    
    def _calculate_key_levels_consensus(self, model_signals: Dict[str, VPASignal]) -> float:
        """è®¡ç®—å…³é”®ä»·ä½çš„ä¸€è‡´æ€§"""
        all_levels = []
        for signal in model_signals.values():
            if signal.key_levels:
                all_levels.extend(signal.key_levels)
        
        if len(all_levels) < 2:
            return 0.0
        
        # è®¡ç®—ä»·ä½èšç±»çš„ä¸€è‡´æ€§
        # è¿™é‡Œä½¿ç”¨ç®€å•çš„èŒƒå›´åŒ¹é…ï¼šä»·ä½ç›¸å·®<1%è®¤ä¸ºä¸€è‡´
        consensus_groups: List[List[float]] = []
        tolerance = 0.01  # 1%å®¹å·®
        
        for level in all_levels:
            matched = False
            for group in consensus_groups:
                avg_group_level = sum(group) / len(group)
                if abs(level - avg_group_level) / avg_group_level <= tolerance:
                    group.append(level)
                    matched = True
                    break
            
            if not matched:
                consensus_groups.append([level])
        
        # æ‰¾åˆ°æœ€å¤§çš„ä¸€è‡´ç»„
        max_group_size = max(len(group) for group in consensus_groups) if consensus_groups else 0
        consensus_ratio = max_group_size / len(all_levels) if all_levels else 0
        
        return consensus_ratio
    
    def identify_disagreements(self, results: Dict[str, Any]) -> List[str]:
        """è¯†åˆ«å…·ä½“çš„åˆ†æ­§ç‚¹"""
        disagreements: List[str] = []
        
        # æå–ä¿¡å·
        model_signals = {}
        for model_name, result in results.items():
            if result.get('success') and result.get('analysis'):
                signal = self._extract_vpa_signals(result['analysis'], model_name)
                model_signals[model_name] = signal
        
        if len(model_signals) < 2:
            return disagreements
        
        # æ£€æŸ¥å„ç»´åº¦åˆ†æ­§
        for dimension in ['market_phase', 'vpa_signal', 'price_direction']:
            values = []
            model_values = {}
            
            for model_name, signal in model_signals.items():
                value = getattr(signal, dimension, None)
                if value:
                    values.append(value)
                    model_values[model_name] = value
            
            if len(set(values)) > 1:  # å­˜åœ¨åˆ†æ­§
                disagreement_desc = f"{dimension}åˆ†æ­§: "
                value_groups: Dict[str, List[str]] = {}
                for model, value in model_values.items():
                    if value not in value_groups:
                        value_groups[value] = []
                    value_groups[value].append(model)
                
                parts = []
                for value, models in value_groups.items():
                    parts.append(f"{value}({', '.join(models)})")
                
                disagreement_desc += " vs ".join(parts)
                disagreements.append(disagreement_desc)
        
        return disagreements
    
    def generate_consensus_summary(self, results: Dict[str, Any], consensus_score: float) -> Dict[str, Any]:
        """ç”Ÿæˆå…±è¯†æ‘˜è¦"""
        # æå–æ‰€æœ‰ä¿¡å·
        model_signals = {}
        for model_name, result in results.items():
            if result.get('success') and result.get('analysis'):
                signal = self._extract_vpa_signals(result['analysis'], model_name)
                model_signals[model_name] = signal
        
        # æ‰¾åˆ°å„ç»´åº¦çš„ä¸»æµè§‚ç‚¹
        consensus_view = {}
        for dimension in ['market_phase', 'vpa_signal', 'price_direction', 'confidence']:
            values = [getattr(signal, dimension) for signal in model_signals.values() 
                     if getattr(signal, dimension) is not None]
            
            if values:
                counter = Counter(values)
                most_common = counter.most_common(1)[0]
                consensus_view[dimension] = {
                    'value': most_common[0],
                    'support_count': most_common[1],
                    'total_count': len(values),
                    'confidence': most_common[1] / len(values)
                }
        
        # æ±‡æ€»å…³é”®ä»·ä½
        all_levels: List[float] = []
        for signal in model_signals.values():
            if signal.key_levels is not None:
                all_levels.extend(signal.key_levels)
        
        # èšç±»ä»·ä½
        if all_levels:
            consensus_levels = self._cluster_key_levels(all_levels)
        else:
            consensus_levels = []
        
        return {
            'consensus_score': consensus_score,
            'model_count': len(model_signals),
            'consensus_view': consensus_view,
            'consensus_levels': consensus_levels,
            'reliability': 'high' if consensus_score >= 0.8 else 'medium' if consensus_score >= 0.6 else 'low'
        }
    
    def _cluster_key_levels(self, levels: List[float], tolerance: float = 0.01) -> List[Dict[str, Any]]:
        """èšç±»å…³é”®ä»·ä½"""
        if not levels:
            return []
        
        sorted_levels = sorted(levels)
        clusters: List[Dict[str, Any]] = []
        
        for level in sorted_levels:
            matched = False
            for cluster in clusters:
                avg_level = sum(cluster['levels']) / len(cluster['levels'])
                if abs(level - avg_level) / avg_level <= tolerance:
                    cluster['levels'].append(level)
                    cluster['support_count'] += 1
                    matched = True
                    break
            
            if not matched:
                clusters.append({
                    'levels': [level],
                    'support_count': 1
                })
        
        # è®¡ç®—æ¯ä¸ªèšç±»çš„ä»£è¡¨ä»·ä½å’Œç½®ä¿¡åº¦
        result_clusters = []
        total_levels = len(levels)
        
        for cluster in clusters:
            avg_level = sum(cluster['levels']) / len(cluster['levels'])
            confidence = cluster['support_count'] / total_levels
            
            result_clusters.append({
                'level': round(avg_level, 2),
                'support_count': cluster['support_count'],
                'confidence': confidence,
                'type': self._classify_level_type(avg_level, sorted_levels)
            })
        
        # æŒ‰æ”¯æŒåº¦æ’åº
        return sorted(result_clusters, key=lambda x: x['support_count'], reverse=True)
    
    def _classify_level_type(self, level: float, all_levels: List[float]) -> str:
        """åˆ†ç±»ä»·ä½ç±»å‹ï¼ˆæ”¯æ’‘/é˜»åŠ›ï¼‰"""
        # ç®€å•çš„åˆ†ç±»é€»è¾‘ï¼šä½äºä¸­ä½æ•°çš„æ˜¯æ”¯æ’‘ï¼Œé«˜äºçš„æ˜¯é˜»åŠ›
        median = sorted(all_levels)[len(all_levels) // 2] if all_levels else level
        
        if level < median:
            return 'support'
        else:
            return 'resistance'