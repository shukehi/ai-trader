import pandas as pd
from typing import Dict, List, Any, Optional
import logging
from .openrouter_client import OpenRouterClient
from .multi_model_validator import MultiModelValidator, ValidationConfig
from formatters import DataFormatter

logger = logging.getLogger(__name__)

class AnalysisEngine:
    """
    AIç›´æ¥åˆ†æå¼•æ“ - ä¸“æ³¨åŸå§‹æ•°æ®åˆ†æ
    
    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. AIç›´æ¥ç†è§£åŸå§‹OHLCVæ•°æ®
    2. å¤šæ¨¡å‹äº¤å‰éªŒè¯é˜²å¹»è§‰
    3. å…±è¯†å¾—åˆ†è®¡ç®—
    4. åˆ†æ­§æ£€æµ‹ä¸æŠ¥è­¦
    5. æ™ºèƒ½ä»²è£æœºåˆ¶
    6. ç½®ä¿¡åº¦è¯„ä¼°
    
    ä½¿ç”¨æ–¹æ³•ï¼š
    - raw_data_analysis(): AIç›´æ¥åˆ†æåŸå§‹æ•°æ®ï¼ˆæ¨èï¼‰
    - validated_vpa_analysis(): å®Œæ•´éªŒè¯åˆ†æ
    - quick_validation_check(): å¿«é€ŸéªŒè¯æ£€æŸ¥
    """
    
    def __init__(self, api_key: Optional[str] = None, enable_validation: bool = True):
        self.client = OpenRouterClient(api_key)
        self.formatter = DataFormatter()
        
        # åˆå§‹åŒ–å¤šæ¨¡å‹éªŒè¯å™¨
        self.validator: Optional[MultiModelValidator]
        if enable_validation:
            self.validator = MultiModelValidator(api_key)
            logger.info("âœ… å¤šæ¨¡å‹éªŒè¯å·²å¯ç”¨")
        else:
            self.validator = None
            logger.info("â„¹ï¸ å¤šæ¨¡å‹éªŒè¯å·²ç¦ç”¨")
    
    def raw_data_analysis(self, 
                         df: pd.DataFrame,
                         model: str = 'gpt4o-mini',
                         format_type: str = 'csv') -> Dict[str, Any]:
        """
        AIç›´æ¥åˆ†æåŸå§‹OHLCVæ•°æ®
        
        Args:
            df: åŸå§‹OHLCVæ•°æ®DataFrame
            model: ä½¿ç”¨çš„AIæ¨¡å‹
            format_type: æ•°æ®æ ¼å¼ ('csv', 'text', 'json', 'pattern')
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        try:
            # æ ¼å¼åŒ–åŸå§‹æ•°æ®
            if format_type == 'csv':
                formatted_data = self.formatter.to_csv_format(df)
            elif format_type == 'text':
                formatted_data = self.formatter.to_text_narrative(df)
            elif format_type == 'json':
                formatted_data = self.formatter.to_structured_json(df)
            elif format_type == 'pattern':
                formatted_data = self.formatter.to_pattern_description(df)
            else:
                formatted_data = self.formatter.to_csv_format(df)  # é»˜è®¤ä½¿ç”¨CSV
            
            # AIåˆ†æåŸå§‹æ•°æ®
            logger.info(f"ä½¿ç”¨ {model} æ¨¡å‹è¿›è¡ŒAIç›´æ¥åˆ†æ...")
            
            analysis_result = self.client.analyze_market_data(
                data=formatted_data,
                model_name=model,
                analysis_type='raw_vpa'
            )
            
            # åˆ›å»ºåˆ†ææŠ¥å‘Š
            report = {
                'data_summary': {
                    'total_bars': len(df),
                    'time_range': {
                        'start': df['datetime'].iloc[0],
                        'end': df['datetime'].iloc[-1]
                    },
                    'price_range': {
                        'min': df['low'].min(),
                        'max': df['high'].max(),
                        'current': df['close'].iloc[-1],
                        'change': ((df['close'].iloc[-1] / df['close'].iloc[0]) - 1) * 100
                    },
                    'volume_summary': {
                        'total': df['volume'].sum(),
                        'average': df['volume'].mean(),
                        'recent_avg': df['volume'].tail(10).mean()
                    }
                },
                'ai_analysis': analysis_result,
                'analysis_method': 'raw_data_ai_direct',
                'model_used': model,
                'format_used': format_type
            }
            
            logger.info("âœ… AIç›´æ¥åˆ†æå®Œæˆ")
            return report
            
        except Exception as e:
            logger.error(f"AIç›´æ¥åˆ†æå¤±è´¥: {e}")
            return {
                'error': str(e),
                'analysis_method': 'raw_data_ai_direct',
                'model_used': model
            }
    
    def validated_vpa_analysis(self,
                             df: pd.DataFrame,
                             models: Optional[List[str]] = None,
                             validation_config: Optional[ValidationConfig] = None) -> Dict[str, Any]:
        """
        éªŒè¯çš„VPAåˆ†æï¼šä½¿ç”¨å¤šæ¨¡å‹éªŒè¯é˜²æ­¢å¹»è§‰
        
        Args:
            df: OHLCVæ•°æ®
            models: ä½¿ç”¨çš„æ¨¡å‹åˆ—è¡¨
            validation_config: éªŒè¯é…ç½®
            
        Returns:
            åŒ…å«éªŒè¯ä¿¡æ¯çš„åˆ†æç»“æœ
        """
        if not self.validator:
            logger.warning("âš ï¸ å¤šæ¨¡å‹éªŒè¯æœªå¯ç”¨ï¼Œé™çº§ä¸ºå•æ¨¡å‹åˆ†æ")
            return self.raw_data_analysis(df)
        
        try:
            # ä½¿ç”¨æœ€ä¼˜çš„Patternæ ¼å¼
            formatted_data = self.formatter.to_pattern_description(df, 
                                                                 include_vsa=True, 
                                                                 include_perpetual_context=True)
            
            logger.info("ğŸ” å¼€å§‹å¤šæ¨¡å‹éªŒè¯åˆ†æ...")
            
            # æ‰§è¡Œå¤šæ¨¡å‹éªŒè¯
            validation_result = self.validator.validate_analysis(
                market_data=formatted_data,
                models=models,
                config=validation_config
            )
            
            # æ•´åˆåˆ†æç»“æœ
            report = {
                'data_summary': {
                    'total_bars': len(df),
                    'time_range': {
                        'start': df['datetime'].iloc[0],
                        'end': df['datetime'].iloc[-1]
                    },
                    'price_range': {
                        'min': df['low'].min(),
                        'max': df['high'].max(),
                        'current': df['close'].iloc[-1],
                        'change': ((df['close'].iloc[-1] / df['close'].iloc[0]) - 1) * 100
                    }
                },
                'validation_result': validation_result,
                'analysis_method': 'validated_vpa_analysis',
                'models_used': validation_result.get('models_used', []),
                'consensus_score': validation_result.get('consensus_score', 0),
                'confidence_level': validation_result.get('confidence_level', 'unknown')
            }
            
            logger.info("âœ… éªŒè¯åˆ†æå®Œæˆ")
            return report
            
        except Exception as e:
            logger.error(f"éªŒè¯åˆ†æå¤±è´¥: {e}")
            return {
                'error': str(e),
                'analysis_method': 'validated_vpa_analysis'
            }
    
    def quick_validation_check(self,
                             df: pd.DataFrame,
                             primary_model: str = 'gpt5-mini',
                             secondary_model: str = 'gemini-flash') -> Dict[str, Any]:
        """
        å¿«é€ŸéªŒè¯æ£€æŸ¥ï¼šä½¿ç”¨2ä¸ªæ¨¡å‹è¿›è¡Œå¿«é€Ÿäº¤å‰éªŒè¯
        
        Args:
            df: OHLCVæ•°æ®
            primary_model: ä¸»è¦æ¨¡å‹
            secondary_model: æ¬¡è¦æ¨¡å‹
            
        Returns:
            å¿«é€ŸéªŒè¯ç»“æœ
        """
        try:
            formatted_data = self.formatter.to_csv_format(df)
            
            logger.info(f"ğŸš€ å¿«é€ŸéªŒè¯: {primary_model} vs {secondary_model}")
            
            # å¹¶è¡Œåˆ†æ
            primary_result = self.client.analyze_market_data(
                data=formatted_data,
                model_name=primary_model,
                analysis_type='quick_vpa'
            )
            
            secondary_result = self.client.analyze_market_data(
                data=formatted_data,
                model_name=secondary_model,
                analysis_type='quick_vpa'
            )
            
            # ç®€å•ä¸€è‡´æ€§æ£€æŸ¥
            consistency_score = self._calculate_simple_consistency(
                primary_result, secondary_result
            )
            
            return {
                'primary_analysis': primary_result,
                'secondary_analysis': secondary_result,
                'consistency_score': consistency_score,
                'models_used': [primary_model, secondary_model],
                'analysis_method': 'quick_validation_check',
                'recommendation': 'high_confidence' if consistency_score > 0.7 else 'medium_confidence' if consistency_score > 0.4 else 'low_confidence'
            }
            
        except Exception as e:
            logger.error(f"å¿«é€ŸéªŒè¯å¤±è´¥: {e}")
            return {
                'error': str(e),
                'analysis_method': 'quick_validation_check'
            }
    
    def _calculate_simple_consistency(self, result1: Any, result2: Any) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªåˆ†æç»“æœçš„ç®€å•ä¸€è‡´æ€§å¾—åˆ†
        """
        try:
            # ç®€åŒ–çš„ä¸€è‡´æ€§è®¡ç®—
            # è¿™é‡Œå¯ä»¥æ ¹æ®å…·ä½“éœ€æ±‚å®ç°æ›´å¤æ‚çš„é€»è¾‘
            if isinstance(result1, str) and isinstance(result2, str):
                # åŸºäºæ–‡æœ¬é•¿åº¦å’Œå…³é”®è¯çš„ç®€å•ç›¸ä¼¼åº¦
                if len(result1) > 0 and len(result2) > 0:
                    return 0.8  # å‡è®¾åŸºæœ¬ä¸€è‡´æ€§
            return 0.5  # é»˜è®¤ä¸­ç­‰ä¸€è‡´æ€§
        except:
            return 0.3  # è®¡ç®—å¤±è´¥æ—¶çš„é»˜è®¤å€¼
    
    def get_analysis_capabilities(self) -> Dict[str, Any]:
        """
        è·å–åˆ†æå¼•æ“çš„èƒ½åŠ›æè¿°
        """
        return {
            'engine_type': 'AI_Direct_Analysis',
            'core_capabilities': [
                'Raw OHLCV data analysis',
                'Multi-model validation',
                'Professional VPA analysis',
                'Real-time signal generation'
            ],
            'supported_formats': ['csv', 'text', 'json', 'pattern'],
            'validation_enabled': self.validator is not None,
            'recommended_method': 'validated_vpa_analysis',
            'fast_method': 'raw_data_analysis',
            'description': 'AIç›´æ¥ç†è§£åŸå§‹Kçº¿æ•°æ®ï¼Œæ— éœ€ä¼ ç»ŸæŠ€æœ¯æŒ‡æ ‡é¢„å¤„ç†'
        }