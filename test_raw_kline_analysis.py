#!/usr/bin/env python3
"""
åŸå§‹Kçº¿æ•°æ®åˆ†ææµ‹è¯•è„šæœ¬
æµ‹è¯•AIæ¨¡å‹ï¼ˆåŒ…æ‹¬Claude Opus 4.1ï¼‰ç›´æ¥åˆ†æåŸå§‹OHLCVæ•°æ®çš„èƒ½åŠ›
è¯„ä¼°åˆ†æç»“æœçš„æ­£ç¡®æ€§å’Œä¸“ä¸šæ€§
"""

import asyncio
import logging
import sys
import time
import json
from datetime import datetime
from typing import Dict, Any
from data.binance_fetcher import BinanceFetcher
from ai.openrouter_client import OpenRouterClient
from formatters.data_formatter import DataFormatter
from config import Settings

# è®¾ç½®é¡¹ç›®è·¯å¾„
sys.path.append('/opt/ai-trader')

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)



class KLineAnalysisEvaluator:
    """Kçº¿åˆ†æç»“æœè¯„ä¼°å™¨"""
    
    def __init__(self):
        self.evaluation_criteria = {
            # æŠ€æœ¯åˆ†ææ­£ç¡®æ€§ (40%)
            'technical_accuracy': {
                'weight': 0.40,
                'indicators': [
                    'trend_identification',      # è¶‹åŠ¿è¯†åˆ«
                    'support_resistance',        # æ”¯æ’‘é˜»åŠ›
                    'volume_analysis',           # æˆäº¤é‡åˆ†æ
                    'price_action'               # ä»·æ ¼è¡ŒåŠ¨
                ]
            },
            # VPAä¸“ä¸šæ€§ (30%)
            'vpa_professionalism': {
                'weight': 0.30,
                'indicators': [
                    'anna_coulling_terminology', # Anna Coullingæœ¯è¯­
                    'vsa_signals',              # VSAä¿¡å·è¯†åˆ«
                    'market_phases',            # å¸‚åœºé˜¶æ®µåˆ†æ
                    'smart_money_detection'     # èªæ˜é’±è¯†åˆ«
                ]
            },
            # æ•°æ®ç†è§£èƒ½åŠ› (20%)
            'data_comprehension': {
                'weight': 0.20,
                'indicators': [
                    'ohlcv_interpretation',     # OHLCVæ•°æ®è§£é‡Š
                    'pattern_recognition',      # æ¨¡å¼è¯†åˆ«
                    'numerical_accuracy',       # æ•°å€¼å‡†ç¡®æ€§
                    'timeframe_awareness'       # æ—¶é—´æ¡†æ¶æ„è¯†
                ]
            },
            # äº¤æ˜“å®ç”¨æ€§ (10%)
            'trading_practicality': {
                'weight': 0.10,
                'indicators': [
                    'actionable_signals',       # å¯æ“ä½œä¿¡å·
                    'risk_assessment',          # é£é™©è¯„ä¼°
                    'entry_exit_points',        # è¿›å‡ºåœºç‚¹ä½
                    'position_sizing'           # ä»“ä½å»ºè®®
                ]
            }
        }
    
    def evaluate_analysis(self, analysis_text: str, market_data: Dict) -> Dict[str, Any]:
        """è¯„ä¼°åˆ†æç»“æœ"""
        analysis_lower = analysis_text.lower()
        evaluation_result = {
            'total_score': 0,
            'category_scores': {},
            'detailed_feedback': {},
            'strengths': [],
            'weaknesses': []
        }
        
        total_weighted_score = 0
        
        for category, config in self.evaluation_criteria.items():
            category_score = self._evaluate_category(analysis_text, analysis_lower, category, config, market_data)
            evaluation_result['category_scores'][category] = category_score
            total_weighted_score += category_score * config['weight']
        
        evaluation_result['total_score'] = round(total_weighted_score, 2)
        evaluation_result['grade'] = self._get_grade(evaluation_result['total_score'])
        
        return evaluation_result
    
    def _evaluate_category(self, analysis_text: str, analysis_lower: str,
                          category: str, config: Dict, market_data: Dict) -> float:
        """è¯„ä¼°å•ä¸ªç±»åˆ«"""
        score = 0
        max_score = len(config['indicators']) * 25  # æ¯ä¸ªæŒ‡æ ‡æœ€é«˜25åˆ†
        
        if category == 'technical_accuracy':
            score = self._evaluate_technical_accuracy(analysis_lower, market_data)
        elif category == 'vpa_professionalism':
            score = self._evaluate_vpa_professionalism(analysis_lower)
        elif category == 'data_comprehension':
            score = self._evaluate_data_comprehension(analysis_text, market_data)
        elif category == 'trading_practicality':
            score = self._evaluate_trading_practicality(analysis_lower)
        
        return min(score, max_score)  # ç¡®ä¿ä¸è¶…è¿‡æœ€å¤§åˆ†æ•°
    
    def _evaluate_technical_accuracy(self, analysis_lower: str, market_data: Dict) -> float:
        """è¯„ä¼°æŠ€æœ¯åˆ†æå‡†ç¡®æ€§"""
        score = 0
        
        # è¶‹åŠ¿è¯†åˆ« (25åˆ†)
        trend_keywords = ['uptrend', 'downtrend', 'sideways', 'bullish', 'bearish', 
                         'ä¸Šå‡è¶‹åŠ¿', 'ä¸‹é™è¶‹åŠ¿', 'æ¨ªç›˜', 'çœ‹æ¶¨', 'çœ‹è·Œ']
        if any(keyword in analysis_lower for keyword in trend_keywords):
            score += 25
        
        # æ”¯æ’‘é˜»åŠ› (25åˆ†)
        sr_keywords = ['support', 'resistance', 'key level', 'breakout', 'breakdown',
                      'æ”¯æ’‘', 'é˜»åŠ›', 'å…³é”®ä½', 'çªç ´', 'è·Œç ´']
        if any(keyword in analysis_lower for keyword in sr_keywords):
            score += 25
        
        # æˆäº¤é‡åˆ†æ (25åˆ†)
        volume_keywords = ['volume', 'high volume', 'low volume', 'volume spike',
                          'æˆäº¤é‡', 'æ”¾é‡', 'ç¼©é‡', 'é‡ä»·']
        if any(keyword in analysis_lower for keyword in volume_keywords):
            score += 25
        
        # ä»·æ ¼è¡ŒåŠ¨ (25åˆ†)
        price_action_keywords = ['price action', 'candlestick', 'doji', 'hammer', 'engulfing',
                                'ä»·æ ¼è¡ŒåŠ¨', 'Kçº¿', 'åå­—æ˜Ÿ', 'é”¤å­çº¿', 'åŒ…ç»œ']
        if any(keyword in analysis_lower for keyword in price_action_keywords):
            score += 25
        
        return score
    
    def _evaluate_vpa_professionalism(self, analysis_lower: str) -> float:
        """è¯„ä¼°VPAä¸“ä¸šæ€§"""
        score = 0
        
        # Anna Coullingæœ¯è¯­ (25åˆ†) - æ‰©å±•ä¸“ä¸šè¯æ±‡
        anna_coulling_terms = [
            'no demand', 'no supply', 'climax volume', 'wide spread',
            'narrow spread', 'professional money', 'smart money', 'wyckoff',
            'vsa', 'composite operator', 'composite man', 'market maker',
            'weakness on strength', 'strength on weakness', 'effort vs result',
            'stopping volume', 'pseudo upthrust', 'bag holding',
            'selling climax', 'buying climax', 'churning', 'distribution day',
            'æ— éœ€æ±‚', 'æ— ä¾›åº”', 'é«˜æ½®æˆäº¤é‡', 'å®½å¹…', 'çª„å¹…',
            'ä¸“ä¸šèµ„é‡‘', 'èªæ˜é’±', 'å¤åˆæ“ä½œè€…', 'åšå¸‚å•†', 'å¼ºåŠ¿ä¸­çš„å¼±ç‚¹',
            'å¼±åŠ¿ä¸­çš„å¼ºåŠ¿', 'åŠªåŠ›ä¸ç»“æœ', 'æ­¢è·Œæˆäº¤é‡', 'ä¼ªå‡çªç ´'
        ]
        if any(term in analysis_lower for term in anna_coulling_terms):
            score += 25
        
        # VSAä¿¡å·è¯†åˆ« (25åˆ†) - æ‰©å±•VSAä¿¡å·è¯æ±‡
        vsa_signals = [
            'upthrust', 'spring', 'test', 'absorption', 'stopping volume',
            'shakeout', 'markdown', 'markup', 'last point of supply',
            'sign of strength', 'sign of weakness', 'end of rising market',
            'selling pressure', 'buying pressure', 'professional interest',
            'retail sentiment', 'volume dry up', 'no demand bar',
            'å‡çªç ´', 'å¼¹ç°§', 'æµ‹è¯•', 'å¸æ”¶', 'æ­¢è·Œæˆäº¤é‡',
            'éœ‡ä»“', 'æ ‡è®°ä¸‹è·Œ', 'æ ‡è®°ä¸Šæ¶¨', 'æœ€åä¾›åº”ç‚¹',
            'å¼ºåŠ¿ä¿¡å·', 'å¼±åŠ¿ä¿¡å·', 'ä¸Šå‡å¸‚åœºç»“æŸ', 'ä¸“ä¸šå…´è¶£'
        ]
        if any(signal in analysis_lower for signal in vsa_signals):
            score += 25
        
        # å¸‚åœºé˜¶æ®µåˆ†æ (25åˆ†)
        market_phases = [
            'accumulation', 'markup', 'distribution', 'markdown',
            'ç§¯ç´¯', 'æ‹‰å‡', 'åˆ†é…', 'ä¸‹è·Œ'
        ]
        if any(phase in analysis_lower for phase in market_phases):
            score += 25
        
        # èªæ˜é’±è¯†åˆ« (25åˆ†)
        smart_money_keywords = [
            'institutional', 'whale', 'composite man', 'market maker',
            'æœºæ„', 'å¤§æˆ·', 'å¤åˆäºº', 'åšå¸‚å•†'
        ]
        if any(keyword in analysis_lower for keyword in smart_money_keywords):
            score += 25
        
        return score
    
    def _evaluate_data_comprehension(self, analysis_text: str, market_data: Dict) -> float:
        """è¯„ä¼°æ•°æ®ç†è§£èƒ½åŠ›"""
        score = 0
        
        # OHLCVæ•°æ®è§£é‡Š (25åˆ†)
        ohlcv_keywords = [
            'open', 'high', 'low', 'close', 'volume', 'ohlc',
            'å¼€ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æ”¶ç›˜', 'æˆäº¤é‡', 'å››ä»·'
        ]
        analysis_lower = analysis_text.lower()
        if any(keyword in analysis_lower for keyword in ohlcv_keywords):
            score += 25
        
        # æ¨¡å¼è¯†åˆ« (25åˆ†)
        pattern_keywords = [
            'pattern', 'formation', 'triangle', 'flag', 'pennant',
            'head and shoulders', 'å½¢æ€', 'ä¸‰è§’å½¢', 'æ——å½¢',
            'æ¥”å½¢', 'å¤´è‚©'
        ]
        if any(keyword in analysis_lower for keyword in pattern_keywords):
            score += 25
        
        # æ•°å€¼å‡†ç¡®æ€§ (25åˆ†)
        # æ£€æŸ¥æ˜¯å¦æåˆ°å…·ä½“ä»·æ ¼æˆ–æ•°å€¼
        import re  # pylint: disable=import-outside-toplevel
        price_mentions = re.findall(r'\$?\d+[\.,]?\d*', analysis_text)
        if price_mentions:
            score += 25
        
        # æ—¶é—´æ¡†æ¶æ„è¯† (25åˆ†)
        timeframe_keywords = [
            'hourly', 'daily', '1h', '4h', '1d', 'timeframe',
            'å°æ—¶', 'æ—¥çº¿', 'æ—¶é—´æ¡†æ¶', 'å‘¨æœŸ'
        ]
        if any(keyword in analysis_lower for keyword in timeframe_keywords):
            score += 25
        
        return score
    
    def _evaluate_trading_practicality(self, analysis_lower: str) -> float:
        """è¯„ä¼°äº¤æ˜“å®ç”¨æ€§ - å¢å¼ºç‰ˆ"""
        score = 0
        
        # å¯æ“ä½œä¿¡å· (25åˆ†) - å¢å¼ºä¿¡å·è¯†åˆ«
        signal_keywords = [
            'buy', 'sell', 'long', 'short', 'entry', 'exit',
            'bullish signal', 'bearish signal', 'trade setup',
            'go long', 'go short', 'enter position', 'close position',
            'ä¹°å…¥', 'å–å‡º', 'åšå¤š', 'åšç©º', 'è¿›åœº', 'å‡ºåœº',
            'çœ‹æ¶¨ä¿¡å·', 'çœ‹è·Œä¿¡å·', 'äº¤æ˜“è®¾ç½®', 'å»ºä»“', 'å¹³ä»“'
        ]
        signal_count = sum(1 for keyword in signal_keywords 
                          if keyword in analysis_lower)
        if signal_count >= 2:  # éœ€è¦è‡³å°‘2ä¸ªç›¸å…³è¯æ±‡
            score += 25
        elif signal_count >= 1:
            score += 15
        
        # é£é™©è¯„ä¼° (25åˆ†) - å¢å¼ºé£é™©ç®¡ç†è¯„ä¼°
        risk_keywords = [
            'risk', 'stop loss', 'risk reward', 'position size',
            'risk management', 'drawdown', 'max loss', 'money management',
            'leverage', 'margin', 'conservative', 'aggressive',
            'é£é™©', 'æ­¢æŸ', 'é£é™©å›æŠ¥', 'ä»“ä½', 'é£é™©ç®¡ç†',
            'å›æ’¤', 'æœ€å¤§æŸå¤±', 'èµ„é‡‘ç®¡ç†', 'æ æ†', 'ä¿è¯é‡‘'
        ]
        risk_count = sum(1 for keyword in risk_keywords 
                        if keyword in analysis_lower)
        if risk_count >= 3:  # éœ€è¦è‡³å°‘3ä¸ªé£é™©ç›¸å…³è¯æ±‡
            score += 25
        elif risk_count >= 2:
            score += 15
        elif risk_count >= 1:
            score += 10
        
        # å…·ä½“ä»·ä½å’Œç‚¹ä½ (25åˆ†) - å¢å¼ºå…·ä½“æ€§è¦æ±‚
        import re  # pylint: disable=import-outside-toplevel
        
        # æ£€æŸ¥å…·ä½“ä»·æ ¼æåŠ
        price_patterns = [
            r'\$\d+[\.,]?\d*',  # $4600.50æ ¼å¼
            r'\d+[\.,]\d+',     # 4600.50æ ¼å¼  
            r'at \d+',          # at 4600æ ¼å¼
            r'above \d+',       # above 4600æ ¼å¼
            r'below \d+',       # below 4600æ ¼å¼
            r'target.*\d+',     # target 4700æ ¼å¼
            r'stop.*\d+',       # stop 4500æ ¼å¼
        ]
        
        price_mentions = 0
        for pattern in price_patterns:
            if re.search(pattern, analysis_lower):
                price_mentions += 1
        
        if price_mentions >= 3:  # éœ€è¦è‡³å°‘3ä¸ªå…·ä½“ä»·æ ¼æåŠ
            score += 25
        elif price_mentions >= 2:
            score += 15
        elif price_mentions >= 1:
            score += 10
        
        # äº¤æ˜“è®¡åˆ’å®Œæ•´æ€§ (25åˆ†) - æ–°å¢è¯„ä¼°ç»´åº¦
        plan_keywords = [
            'plan', 'strategy', 'approach', 'method',
            'timeframe', 'holding period', 'profit target', 'exit strategy',
            'portfolio', 'allocation', 'diversification',
            'è®¡åˆ’', 'ç­–ç•¥', 'æ–¹æ³•', 'æ—¶é—´æ¡†æ¶', 'æŒæœ‰æœŸ',
            'ç›ˆåˆ©ç›®æ ‡', 'é€€å‡ºç­–ç•¥', 'æŠ•èµ„ç»„åˆ', 'é…ç½®'
        ]
        plan_count = sum(1 for keyword in plan_keywords 
                        if keyword in analysis_lower)
        if plan_count >= 2:  # éœ€è¦è‡³å°‘2ä¸ªè®¡åˆ’ç›¸å…³è¯æ±‡
            score += 25
        elif plan_count >= 1:
            score += 15
        
        return min(score, 100)  # ç¡®ä¿ä¸è¶…è¿‡100åˆ†
    
    def _get_grade(self, score: float) -> str:
        """æ ¹æ®åˆ†æ•°è·å–ç­‰çº§"""
        if score >= 90:
            return 'A+ (ä¼˜ç§€)'
        elif score >= 80:
            return 'A (è‰¯å¥½)'
        elif score >= 70:
            return 'B+ (ä¸­ä¸Š)'
        elif score >= 60:
            return 'B (ä¸­ç­‰)'
        elif score >= 50:
            return 'C+ (ä¸­ä¸‹)'
        elif score >= 40:
            return 'C (è¾ƒå·®)'
        else:
            return 'D (ä¸åˆæ ¼)'

async def test_raw_kline_analysis():
    """æµ‹è¯•åŸå§‹Kçº¿æ•°æ®åˆ†æ"""
    print("ğŸ§ª å¼€å§‹åŸå§‹Kçº¿æ•°æ®åˆ†ææµ‹è¯•")
    print("="*60)
    
    try:
        # 1. éªŒè¯APIé…ç½®
        Settings.validate()
        print("âœ… OpenRouter APIé…ç½®éªŒè¯é€šè¿‡")
        
        # 2. åˆå§‹åŒ–ç»„ä»¶
        fetcher = BinanceFetcher()
        client = OpenRouterClient()
        formatter = DataFormatter()
        evaluator = KLineAnalysisEvaluator()
        
        print("âœ… æµ‹è¯•ç»„ä»¶åˆå§‹åŒ–å®Œæˆ")
        
        # 3. è·å–ETH/USDTåŸå§‹æ•°æ®
        print("\nğŸ“Š è·å–ETH/USDTæ°¸ç»­åˆçº¦åŸå§‹æ•°æ®...")
        df = fetcher.get_ohlcv('ETH/USDT', '1h', 100)  # è·å–æ›´å¤šæ•°æ®ç”¨äºåˆ†æ
        
        if df.empty:
            print("âŒ è·å–æ•°æ®å¤±è´¥")
            return False
        
        # æ•°æ®ç»Ÿè®¡
        current_price = df['close'].iloc[-1]
        price_change = ((df['close'].iloc[-1] / df['close'].iloc[0]) - 1) * 100
        avg_volume = df['volume'].mean()
        
        print(f"âœ… æˆåŠŸè·å–{len(df)}æ¡åŸå§‹OHLCVæ•°æ®")
        print(f"ğŸ’° å½“å‰ä»·æ ¼: ${current_price:.2f}")
        print(f"ğŸ“ˆ åŒºé—´æ¶¨è·Œå¹…: {price_change:+.2f}%")
        print(f"ğŸ“Š å¹³å‡æˆäº¤é‡: {avg_volume:.0f}")
        
        # 4. å‡†å¤‡æµ‹è¯•æ¨¡å‹
        test_models = [
            ('claude-opus-41', 'ğŸ§  Claude Opus 4.1 (æœ€æ–°æ——èˆ°)'),
            ('gpt5-mini', 'âš¡ GPT-5 Mini (é«˜æ€§ä»·æ¯”)'),
            ('gemini-25-pro', 'ğŸš€ Gemini 2.5 Pro (å¤§å®¹é‡)'),
            ('gpt4o', 'ğŸ¯ GPT-4o (å‡è¡¡å‹)')
        ]
        
        # 5. åŸå§‹æ•°æ®åˆ†ææç¤ºè¯
        raw_analysis_prompt = f"""
ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„é‡ä»·åˆ†æ(VPA)ä¸“å®¶ï¼Œè¯·ç›´æ¥åˆ†æä»¥ä¸‹åŸå§‹Kçº¿æ•°æ®ï¼š

æ•°æ®æ ¼å¼ï¼šæ¯è¡ŒåŒ…å« [æ—¶é—´, å¼€ç›˜ä»·, æœ€é«˜ä»·, æœ€ä½ä»·, æ”¶ç›˜ä»·, æˆäº¤é‡]

åŸå§‹OHLCVæ•°æ®ï¼š
{formatter.to_csv_format(df.tail(50))}  # ä½¿ç”¨æœ€è¿‘50æ¡æ•°æ®

è¯·åŸºäºä»¥ä¸ŠåŸå§‹æ•°æ®è¿›è¡Œä¸“ä¸šçš„VPAåˆ†æï¼ŒåŒ…æ‹¬ï¼š
1. å¸‚åœºè¶‹åŠ¿è¯†åˆ«å’Œé˜¶æ®µåˆ†æ
2. å…³é”®æ”¯æ’‘é˜»åŠ›ä½è¯†åˆ«
3. æˆäº¤é‡ä¸ä»·æ ¼å…³ç³»åˆ†æ
4. Anna Coulling VSAä¿¡å·è¯†åˆ«
5. äº¤æ˜“ä¿¡å·å’Œé£é™©è¯„ä¼°

è¦æ±‚ï¼š
- ç›´æ¥å¼•ç”¨å…·ä½“çš„ä»·æ ¼å’Œæˆäº¤é‡æ•°æ®
- ä½¿ç”¨ä¸“ä¸šçš„VPA/VSAæœ¯è¯­
- æä¾›å…·ä½“çš„äº¤æ˜“å»ºè®®å’Œé£é™©æ§åˆ¶
- åˆ†æåº”åŸºäºæ•°æ®äº‹å®ï¼Œé¿å…ä¸»è§‚è‡†æµ‹
"""
        
        results = []
        
        # 6. æ‰§è¡Œå¤šæ¨¡å‹åˆ†æ
        for model, description in test_models:
            print(f"\nğŸ” {description} åˆ†æä¸­...")
            
            start_time = time.time()
            
            try:
                # æ£€æŸ¥æ¨¡å‹æ˜¯å¦å¯ç”¨
                if model not in Settings.MODELS:
                    print(f"âŒ æ¨¡å‹ {model} ä¸å¯ç”¨ï¼Œè·³è¿‡")
                    continue
                
                result = client.generate_response(raw_analysis_prompt, model)
                analysis_time = time.time() - start_time
                
                if result.get('success'):
                    # ä¼°ç®—æˆæœ¬
                    cost_info = client.estimate_cost(
                        model, 
                        result['usage']['prompt_tokens'],
                        result['usage']['completion_tokens']
                    )
                    
                    # è¯„ä¼°åˆ†æè´¨é‡
                    market_data = {
                        'current_price': current_price,
                        'price_change': price_change,
                        'avg_volume': avg_volume,
                        'data_points': len(df)
                    }
                    
                    evaluation = evaluator.evaluate_analysis(result['analysis'], market_data)
                    
                    print(f"âœ… åˆ†æå®Œæˆ:")
                    print(f"   â±ï¸ è€—æ—¶: {analysis_time:.1f}ç§’")
                    print(f"   ğŸ’° æˆæœ¬: ${cost_info['estimated_cost']:.6f}")
                    print(f"   ğŸ”¢ Tokens: {result['usage']['total_tokens']}")
                    print(f"   ğŸ¯ è´¨é‡è¯„åˆ†: {evaluation['total_score']}/100 ({evaluation['grade']})")
                    
                    # æ˜¾ç¤ºåˆ†ç±»å¾—åˆ†
                    print(f"   ğŸ“Š åˆ†ç±»å¾—åˆ†:")
                    for category, score in evaluation['category_scores'].items():
                        category_name = {
                            'technical_accuracy': 'æŠ€æœ¯åˆ†æå‡†ç¡®æ€§',
                            'vpa_professionalism': 'VPAä¸“ä¸šæ€§',
                            'data_comprehension': 'æ•°æ®ç†è§£èƒ½åŠ›',
                            'trading_practicality': 'äº¤æ˜“å®ç”¨æ€§'
                        }.get(category, category)
                        print(f"      {category_name}: {score:.0f}/100")
                    
                    # æ˜¾ç¤ºåˆ†ææ‘˜è¦
                    summary = result['analysis'][:300] + "..." if len(result['analysis']) > 300 else result['analysis']
                    print(f"   ğŸ“ åˆ†ææ‘˜è¦: {summary}")
                    
                    results.append({
                        'model': model,
                        'description': description,
                        'success': True,
                        'cost': cost_info['estimated_cost'],
                        'time': analysis_time,
                        'tokens': result['usage']['total_tokens'],
                        'evaluation': evaluation,
                        'analysis': result['analysis']
                    })
                    
                else:
                    print(f"âŒ åˆ†æå¤±è´¥: {result.get('error', 'Unknown error')}")
                    results.append({
                        'model': model,
                        'description': description,
                        'success': False,
                        'error': result.get('error')
                    })
            
            except Exception as e:
                print(f"âŒ åˆ†æå¼‚å¸¸: {e}")
                results.append({
                    'model': model,
                    'description': description,
                    'success': False,
                    'error': str(e)
                })
            
            # é¿å…APIé¢‘ç‡é™åˆ¶
            if model != test_models[-1][0]:
                print("   â³ ç­‰å¾…2ç§’é¿å…é¢‘ç‡é™åˆ¶...")
                await asyncio.sleep(2)
        
        # 7. ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š
        print("\n" + "="*80)
        print("ğŸ“Š åŸå§‹Kçº¿æ•°æ®åˆ†ææµ‹è¯•æŠ¥å‘Š")
        print("="*80)
        
        successful_tests = [r for r in results if r.get('success', False)]
        
        if not successful_tests:
            print("âŒ æ‰€æœ‰æµ‹è¯•éƒ½å¤±è´¥äº†")
            return False
        
        # æ€»ä½“ç»Ÿè®¡
        total_cost = sum(r.get('cost', 0) for r in successful_tests)
        avg_time = sum(r.get('time', 0) for r in successful_tests) / len(successful_tests)
        avg_score = sum(r['evaluation']['total_score'] for r in successful_tests) / len(successful_tests)
        
        print(f"âœ… æˆåŠŸæµ‹è¯•: {len(successful_tests)}/{len(results)}")
        print(f"ğŸ’° æ€»æˆæœ¬: ${total_cost:.6f}")
        print(f"â±ï¸ å¹³å‡è€—æ—¶: {avg_time:.1f}ç§’")
        print(f"ğŸ¯ å¹³å‡è´¨é‡å¾—åˆ†: {avg_score:.1f}/100")
        
        # æ’è¡Œæ¦œ
        print(f"\nğŸ† æ¨¡å‹æ€§èƒ½æ’è¡Œæ¦œ:")
        sorted_results = sorted(successful_tests, key=lambda x: x['evaluation']['total_score'], reverse=True)
        
        for i, result in enumerate(sorted_results, 1):
            evaluation = result['evaluation']
            print(f"{i}. {result['description']}")
            print(f"   è´¨é‡å¾—åˆ†: {evaluation['total_score']}/100 ({evaluation['grade']})")
            print(f"   æˆæœ¬: ${result['cost']:.6f}, è€—æ—¶: {result['time']:.1f}ç§’")
        
        # æœ€ä½³åˆ†æå±•ç¤º
        if sorted_results:
            best_result = sorted_results[0]
            print(f"\nğŸ¥‡ æœ€ä½³åˆ†æç»“æœ ({best_result['description']}):")
            print("-" * 60)
            print(best_result['analysis'][:1000] + "..." if len(best_result['analysis']) > 1000 else best_result['analysis'])
            print("-" * 60)
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        report_file = f"/opt/ai-trader/results/raw_kline_analysis_report_{timestamp}.json"
        
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump({
                'test_time': timestamp,
                'market_data': market_data,
                'results': results,
                'summary': {
                    'success_rate': len(successful_tests) / len(results),
                    'total_cost': total_cost,
                    'average_time': avg_time,
                    'average_score': avg_score
                }
            }, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        print("="*80)
        
        return len(successful_tests) > 0
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¿‡ç¨‹å¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()
        return False

async def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ åŸå§‹Kçº¿æ•°æ®åˆ†ææµ‹è¯•")
    print("æµ‹è¯•AIæ¨¡å‹ç›´æ¥ç†è§£å’Œåˆ†æåŸå§‹OHLCVæ•°æ®çš„èƒ½åŠ›")
    print("è¯„ä¼°åˆ†æç»“æœçš„æŠ€æœ¯å‡†ç¡®æ€§å’ŒVPAä¸“ä¸šæ€§")
    print()
    
    success = await test_raw_kline_analysis()
    
    if success:
        print("\nğŸ‰ åŸå§‹Kçº¿æ•°æ®åˆ†ææµ‹è¯•å®Œæˆï¼")
        print("ğŸ’¡ AIæ¨¡å‹å±•ç°äº†ç›´æ¥ç†è§£åŸå§‹æ•°æ®çš„èƒ½åŠ›")
    else:
        print("\nâŒ åŸå§‹Kçº¿æ•°æ®åˆ†ææµ‹è¯•å¤±è´¥")
        print("ğŸ” è¯·æ£€æŸ¥APIé…ç½®å’Œç½‘ç»œè¿æ¥")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nâ¹ï¸ æµ‹è¯•è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        logger.error("âŒ æµ‹è¯•ç¨‹åºå¼‚å¸¸: %s", e)
        import traceback  # pylint: disable=import-outside-toplevel
        traceback.print_exc()