import pandas as pd
import json
from typing import Dict, List, Any, Optional
import numpy as np

class DataFormatter:
    """
    æ•°æ®æ ¼å¼åŒ–å™¨ï¼Œæä¾›4ç§ä¸åŒçš„LLMè¾“å…¥æ ¼å¼
    """
    
    @staticmethod
    def to_csv_format(df: pd.DataFrame, include_volume: bool = True) -> str:
        """
        æ ¼å¼A: åŸå§‹CSVæ•°å€¼æ ¼å¼
        æœ€ç®€æ´ï¼Œtokenä½¿ç”¨æœ€å°‘
        """
        # é€‰æ‹©éœ€è¦çš„åˆ—
        columns = ['datetime', 'open', 'high', 'low', 'close']
        if include_volume:
            columns.append('volume')
        
        # è½¬æ¢ä¸ºCSVå­—ç¬¦ä¸²
        selected_df = df[columns].copy()
        
        # æ ¼å¼åŒ–æ•°å€¼ï¼Œå‡å°‘å°æ•°ä½ä»¥èŠ‚çœtoken
        numeric_cols = ['open', 'high', 'low', 'close']
        if include_volume:
            numeric_cols.append('volume')
        
        for col in numeric_cols:
            if col == 'volume':
                selected_df[col] = selected_df[col].astype(int)  # æˆäº¤é‡å–æ•´
            else:
                selected_df[col] = selected_df[col].round(2)  # ä»·æ ¼ä¿ç•™2ä½å°æ•°
        
        return selected_df.to_csv(index=False, lineterminator='\\n')
    
    @staticmethod
    def to_text_narrative(df: pd.DataFrame, window_size: int = 5) -> str:
        """
        æ ¼å¼B: æ–‡æœ¬åŒ–æè¿°æ ¼å¼
        å°†æ•°å€¼è½¬åŒ–ä¸ºè‡ªç„¶è¯­è¨€æè¿°
        """
        lines = ["# ETH/USDT æ°¸ç»­åˆçº¦å¸‚åœºåˆ†ææ•°æ®\\n"]
        
        # å¸‚åœºæ¦‚å†µ
        start_price = df['close'].iloc[0]
        end_price = df['close'].iloc[-1]
        high_price = df['high'].max()
        low_price = df['low'].min()
        total_volume = df['volume'].sum()
        
        change_pct = ((end_price / start_price) - 1) * 100
        
        lines.append(f"## å¸‚åœºæ¦‚å†µ")
        lines.append(f"æ—¶é—´èŒƒå›´: {df['datetime'].iloc[0]} è‡³ {df['datetime'].iloc[-1]}")
        lines.append(f"ä»·æ ¼å˜åŒ–: ä» ${start_price:.2f} è‡³ ${end_price:.2f} ({change_pct:+.2f}%)")
        lines.append(f"åŒºé—´é«˜ä½: ${high_price:.2f} / ${low_price:.2f}")
        lines.append(f"æ€»æˆäº¤é‡: {total_volume:,.0f}")
        lines.append("")
        
        # å…³é”®ä»·æ ¼è¡Œä¸ºæè¿°
        lines.append("## å…³é”®ä»·æ ¼è¡Œä¸º")
        
        for i in range(1, len(df)):
            current = df.iloc[i]
            previous = df.iloc[i-1]
            
            # ä»·æ ¼å˜åŒ–
            price_change = current['close'] - previous['close']
            price_change_pct = (price_change / previous['close']) * 100
            
            # æˆäº¤é‡å˜åŒ–
            volume_change = current['volume'] - previous['volume']
            volume_change_pct = (volume_change / previous['volume']) * 100 if previous['volume'] > 0 else 0
            
            # æ³¢åŠ¨å¹…åº¦
            range_size = current['high'] - current['low']
            range_pct = (range_size / current['low']) * 100 if current['low'] > 0 else 0
            
            # ç”Ÿæˆæè¿°
            direction = "ä¸Šæ¶¨" if price_change > 0 else "ä¸‹è·Œ" if price_change < 0 else "å¹³ç›˜"
            intensity = "å¤§å¹…" if abs(price_change_pct) > 2 else "æ¸©å’Œ" if abs(price_change_pct) > 0.5 else "å¾®"
            
            volume_desc = "æˆäº¤é‡æ¿€å¢" if volume_change_pct > 50 else "æˆäº¤é‡å¢åŠ " if volume_change_pct > 20 else "æˆäº¤é‡èç¼©" if volume_change_pct < -20 else "æˆäº¤é‡å¹³ç¨³"
            
            if abs(price_change_pct) > 0.5 or abs(volume_change_pct) > 30:  # åªæè¿°é‡è¦çš„å˜åŒ–
                lines.append(f"{current['datetime']}: {intensity}{direction} {price_change_pct:+.2f}%, {volume_desc} {volume_change_pct:+.1f}%, æ³¢å¹… {range_pct:.2f}%")
        
        return "\\n".join(lines)
    
    @staticmethod 
    def to_structured_json(df: pd.DataFrame, include_analysis: bool = True) -> str:
        """
        æ ¼å¼C: ç»“æ„åŒ–JSON + å…³é”®æŒ‡æ ‡é¢„è®¡ç®—
        åŒ…å«åŸå§‹æ•°æ®å’Œé¢„å¤„ç†åˆ†æ
        """
        # åŸºç¡€æ•°æ®ç»“æ„
        data = {
            "metadata": {
                "symbol": "ETH/USDT",
                "contract_type": "perpetual",
                "timeframe": "1h",
                "total_bars": len(df),
                "time_range": {
                    "start": str(df['datetime'].iloc[0]),
                    "end": str(df['datetime'].iloc[-1])
                }
            },
            "market_summary": {
                "price_action": {
                    "open": float(df['open'].iloc[0]),
                    "close": float(df['close'].iloc[-1]),
                    "high": float(df['high'].max()),
                    "low": float(df['low'].min()),
                    "change_percent": float(((df['close'].iloc[-1] / df['open'].iloc[0]) - 1) * 100)
                },
                "volume_profile": {
                    "total_volume": float(df['volume'].sum()),
                    "average_volume": float(df['volume'].mean()),
                    "max_volume_bar": float(df['volume'].max()),
                    "volume_trend": "increasing" if df['volume'].tail(10).mean() > df['volume'].head(10).mean() else "decreasing"
                }
            },
            "candlestick_data": []
        }
        
        # æ·»åŠ èœ¡çƒ›å›¾æ•°æ®
        for _, row in df.iterrows():
            candle = {
                "timestamp": str(row['datetime']),
                "ohlcv": {
                    "open": float(row['open']),
                    "high": float(row['high']),
                    "low": float(row['low']),
                    "close": float(row['close']),
                    "volume": float(row['volume'])
                }
            }
            
            # æ·»åŠ è®¡ç®—å­—æ®µ
            body_size = abs(row['close'] - row['open'])
            total_range = row['high'] - row['low']
            
            candle["analysis"] = {
                "candle_type": "bullish" if row['close'] > row['open'] else "bearish" if row['close'] < row['open'] else "doji",
                "body_size_percent": float((body_size / total_range * 100) if total_range > 0 else 0),
                "upper_shadow": float(row['high'] - max(row['open'], row['close'])),
                "lower_shadow": float(min(row['open'], row['close']) - row['low'])
            }
            
            data["candlestick_data"].append(candle)
        
        # æ·»åŠ æŠ€æœ¯æŒ‡æ ‡ï¼ˆå¦‚æœæ•°æ®ä¸­å­˜åœ¨ï¼‰
        if include_analysis and 'rsi' in df.columns:
            data["technical_indicators"] = {
                "rsi_current": float(df['rsi'].iloc[-1]) if not pd.isna(df['rsi'].iloc[-1]) else None,
                "rsi_overbought": (df['rsi'] > 70).sum(),
                "rsi_oversold": (df['rsi'] < 30).sum()
            }
        
        if include_analysis and 'macd' in df.columns:
            data["technical_indicators"]["macd"] = {
                "current": float(df['macd'].iloc[-1]) if not pd.isna(df['macd'].iloc[-1]) else None,
                "signal": float(df['macd_signal'].iloc[-1]) if 'macd_signal' in df.columns and not pd.isna(df['macd_signal'].iloc[-1]) else None
            }
        
        return json.dumps(data, indent=2, ensure_ascii=False)
    
    @staticmethod
    def to_pattern_description(df: pd.DataFrame, include_vsa: bool = True, 
                             include_perpetual_context: bool = True) -> str:
        """
        æ ¼å¼D: å¢å¼ºçš„VPAä¸“ä¸šåˆ†ææ ¼å¼
        æ•´åˆVSAåˆ†æå’Œæ°¸ç»­åˆçº¦ç‰¹è‰²ï¼ŒåŸºäºAnna Coullingç†è®º
        
        Args:
            df: OHLCVæ•°æ®
            include_vsa: æ˜¯å¦åŒ…å«VSAåˆ†æ
            include_perpetual_context: æ˜¯å¦åŒ…å«æ°¸ç»­åˆçº¦èƒŒæ™¯
        """
        lines = ["# ETH/USDT æ°¸ç»­åˆçº¦VPAä¸“ä¸šåˆ†æ\\n"]
        
        # å¸‚åœºæ¦‚å†µ
        lines.append("## ğŸ¯ å¸‚åœºæ¦‚å†µ")
        start_price = df['close'].iloc[0]
        end_price = df['close'].iloc[-1]
        high_price = df['high'].max()
        low_price = df['low'].min()
        total_volume = df['volume'].sum()
        avg_volume = df['volume'].mean()
        
        price_change = (end_price - start_price) / start_price * 100
        lines.append(f"- ä»·æ ¼åŒºé—´: {low_price:.2f} - {high_price:.2f} USDT")
        lines.append(f"- æœŸé—´å˜åŠ¨: {start_price:.2f} â†’ {end_price:.2f} ({price_change:+.2f}%)")
        lines.append(f"- æ€»æˆäº¤é‡: {total_volume:,.0f}, å¹³å‡: {avg_volume:,.0f}")
        lines.append("")
        
        # VSAæ ¸å¿ƒåˆ†æ (å¦‚æœå¯ç”¨)
        if include_vsa:
            lines.extend(DataFormatter._format_vsa_analysis(df))
        
        # æ°¸ç»­åˆçº¦èƒŒæ™¯ (å¦‚æœå¯ç”¨)
        if include_perpetual_context:
            lines.extend(DataFormatter._format_perpetual_context())
        
        # å…³é”®Kçº¿å½¢æ€è¯†åˆ«
        patterns_found = DataFormatter._identify_key_patterns(df)
        
        if patterns_found:
            lines.append("## ğŸ“Š å…³é”®Kçº¿å½¢æ€")
            lines.extend(patterns_found)
        
        # Wyckoffå¸‚åœºé˜¶æ®µåˆ†ææç¤º
        lines.append("## ğŸ“ Wyckoffå¸‚åœºé˜¶æ®µåˆ†ææ¡†æ¶")
        lines.append("è¯·åŸºäºä»¥ä¸Šæ•°æ®åˆ¤æ–­å½“å‰å¸‚åœºé˜¶æ®µ:")
        lines.append("- **Accumulation(å¸ç­¹)**: Smart Moneyåœ¨ä½ä½å»ºä»“")
        lines.append("- **Markup(æ‹‰å‡)**: ä»·æ ¼ä¸Šå‡é˜¶æ®µï¼Œæˆäº¤é‡åº”é…åˆ")
        lines.append("- **Distribution(æ´¾å‘)**: Smart Moneyåœ¨é«˜ä½å‡ºè´§")  
        lines.append("- **Markdown(ä¸‹è·Œ)**: ä»·æ ¼ä¸‹é™é˜¶æ®µï¼Œå…³æ³¨Volume Climax")
        lines.append("")
        
        return "\\n".join(lines)
    
    @staticmethod
    def _format_vsa_analysis(df: pd.DataFrame) -> List[str]:
        """æ ¼å¼åŒ–VSAåˆ†æå†…å®¹"""
        lines = []
        lines.append("## ğŸ” VSA (Volume Spread Analysis) æ ¸å¿ƒæŒ‡æ ‡")
        
        # æœ€è¿‘å‡ æ ¹Kçº¿çš„VSAåˆ†æ
        recent_bars = df.tail(10)
        vsa_highlights = []
        
        for i, (_, row) in enumerate(recent_bars.iterrows()):
            bar_analysis = []
            
            # è®¡ç®—VSAæŒ‡æ ‡
            open_price = row['open']
            high_price = row['high'] 
            low_price = row['low']
            close_price = row['close']
            volume = row['volume']
            
            spread = high_price - low_price
            body_size = abs(close_price - open_price)
            close_position = (close_price - low_price) / spread if spread > 0 else 0.5
            
            # Volumeæ¯”è¾ƒ (ä¸å¹³å‡å€¼)
            if i >= 5:  # æœ‰è¶³å¤Ÿå†å²æ•°æ®
                recent_avg_vol = recent_bars['volume'].iloc[max(0, i-5):i].mean()
                vol_ratio = volume / recent_avg_vol if recent_avg_vol > 0 else 1.0
            else:
                vol_ratio = 1.0
            
            # VSAä¿¡å·è¯†åˆ«
            datetime_str = row['datetime']
            is_up = close_price > open_price
            
            # Wide Spread + High Volume
            if spread > recent_bars['high'].subtract(recent_bars['low']).quantile(0.7) and vol_ratio > 1.5:
                if close_position > 0.7:
                    bar_analysis.append(f"âœ… **{datetime_str}**: Wide Spread + é«˜é‡æ”¶é«˜ä½ â†’ Professional Buying")
                elif close_position < 0.3:
                    bar_analysis.append(f"âš ï¸ **{datetime_str}**: Wide Spread + é«˜é‡æ”¶ä½ä½ â†’ Selling Pressure")
            
            # Narrow Spread + Low Volume  
            elif spread < recent_bars['high'].subtract(recent_bars['low']).quantile(0.3) and vol_ratio < 0.8:
                if is_up:
                    bar_analysis.append(f"ğŸ”´ **{datetime_str}**: No Demand â†’ ä¸Šæ¶¨ç¼ºä¹æˆäº¤é‡æ”¯æŒ")
                else:
                    bar_analysis.append(f"ğŸŸ¢ **{datetime_str}**: No Supply â†’ ä¸‹è·Œç¼ºä¹çœŸå®å–å‹")
            
            # Climax Volume
            elif vol_ratio > 2.0:
                bar_analysis.append(f"ğŸ”¥ **{datetime_str}**: Climax Volume (é‡æ¯”{vol_ratio:.1f}) â†’ å¯èƒ½çš„è½¬æŠ˜ç‚¹")
            
            vsa_highlights.extend(bar_analysis)
        
        if vsa_highlights:
            lines.extend(vsa_highlights)
        else:
            lines.append("- è¿‘æœŸæœªå‘ç°æ˜æ˜¾VSAä¿¡å·ï¼Œå¸‚åœºå¤„äºç›¸å¯¹å¹³è¡¡çŠ¶æ€")
        
        lines.append("")
        return lines
    
    @staticmethod
    def _format_perpetual_context() -> List[str]:
        """æ ¼å¼åŒ–æ°¸ç»­åˆçº¦èƒŒæ™¯ä¿¡æ¯"""
        lines = []
        lines.append("## âš¡ æ°¸ç»­åˆçº¦VPAåˆ†æè¦ç‚¹")
        lines.append("**è¯·ç‰¹åˆ«å…³æ³¨ä»¥ä¸‹æ°¸ç»­åˆçº¦ç‰¹æœ‰å› ç´ :**")
        lines.append("- ğŸ“ˆ **èµ„é‡‘è´¹ç‡å½±å“**: æ­£è´¹ç‡=å¤šå¤´æ”¯ä»˜(çœ‹æ¶¨æƒ…ç»ª)ï¼Œè´Ÿè´¹ç‡=ç©ºå¤´æ”¯ä»˜(çœ‹è·Œæƒ…ç»ª)")
        lines.append("- ğŸ¯ **æŒä»“é‡(OI)å˜åŒ–**: OIå¢åŠ +ä»·æ ¼ä¸Šæ¶¨=æ–°å¤šå¤´å¼€ä»“ï¼ŒOIå‡å°‘+ä»·æ ¼ä¸‹è·Œ=å¤šå¤´å¹³ä»“")
        lines.append("- âš¡ **æ æ†æ•ˆåº”æ”¾å¤§**: æ•£æˆ·æƒ…ç»ªè¢«æ æ†æ”¾å¤§ï¼Œå¼ºå¹³cascadeåˆ›é€ é¢å¤–Supply/Demand")
        lines.append("- ğŸª **Smart Moneyæ“æ§**: åˆ©ç”¨èµ„é‡‘è´¹ç‡å’Œæ æ†è¯±å¯¼æ•£æˆ·å¼€ä»“ï¼Œç„¶ååå‘æ“ä½œ")
        lines.append("- ğŸŒŠ **å¤šç©ºè½¬æ¢**: èµ„é‡‘è´¹ç‡å˜åŒ–å¯¼è‡´æŒä»“ç»“æ„å¿«é€Ÿè½¬æ¢ï¼Œåˆ›é€ æ–°çš„VPAä¿¡å·")
        lines.append("")
        return lines
    
    @staticmethod  
    def _identify_key_patterns(df: pd.DataFrame) -> List[str]:
        """è¯†åˆ«å…³é”®Kçº¿å½¢æ€"""
        patterns_found = []
        
        for i in range(len(df)):
            row = df.iloc[i]
            patterns = []
            
            # åŸºç¡€å½¢æ€è¯†åˆ«
            open_price = row['open']
            high_price = row['high']
            low_price = row['low']
            close_price = row['close']
            volume = row['volume']
            
            body_size = abs(close_price - open_price)
            upper_shadow = high_price - max(open_price, close_price)
            lower_shadow = min(open_price, close_price) - low_price
            total_range = high_price - low_price
            
            # èœ¡çƒ›çº¿ç±»å‹
            if close_price > open_price:
                candle_type = "é˜³çº¿"
            elif close_price < open_price:
                candle_type = "é˜´çº¿"
            else:
                candle_type = "åå­—çº¿"
            
            # VPAç›¸å…³å½¢æ€è¯†åˆ« (ç»“åˆæˆäº¤é‡)
            if total_range > 0:
                body_ratio = body_size / total_range
                upper_shadow_ratio = upper_shadow / total_range
                lower_shadow_ratio = lower_shadow / total_range
                
                # è®¡ç®—æˆäº¤é‡æ¯”ç‡ (ä¸å‰10æ ¹å¹³å‡æ¯”è¾ƒ)
                if i >= 10:
                    avg_volume = df['volume'].iloc[max(0, i-10):i].mean()
                    vol_ratio = volume / avg_volume if avg_volume > 0 else 1.0
                else:
                    vol_ratio = 1.0
                
                # VPAå…³é”®å½¢æ€è¯†åˆ«
                
                # 1. Climax Bar (Volume Climax)
                if vol_ratio > 2.0 and total_range > df['high'].subtract(df['low']).iloc[max(0, i-20):i].quantile(0.8):
                    if close_price > open_price:
                        patterns.append(f"ğŸ“ˆ Buying Climax (é‡æ¯”{vol_ratio:.1f})")
                    else:
                        patterns.append(f"ğŸ“‰ Selling Climax (é‡æ¯”{vol_ratio:.1f})")
                
                # 2. No Demand (ä¸Šæ¶¨ä½†æˆäº¤é‡ä½)
                elif close_price > open_price and vol_ratio < 0.7 and body_ratio > 0.3:
                    patterns.append("ğŸ”´ No Demand (æ— é‡ä¸Šæ¶¨)")
                
                # 3. No Supply (ä¸‹è·Œä½†æˆäº¤é‡ä½)  
                elif close_price < open_price and vol_ratio < 0.7 and body_ratio > 0.3:
                    patterns.append("ğŸŸ¢ No Supply (æ— é‡ä¸‹è·Œ)")
                
                # 4. Upthrust (é«˜ä½é•¿ä¸Šå½±å¤§é‡)
                elif (upper_shadow_ratio > 0.6 and vol_ratio > 1.5 and 
                      close_price < (high_price + low_price) / 2):
                    patterns.append("âš ï¸ Upthrust (é«˜ä½å‡çªç ´)")
                
                # 5. Spring (ä½ä½é•¿ä¸‹å½±åæ”¶å›)  
                elif (lower_shadow_ratio > 0.6 and vol_ratio > 1.2 and
                      close_price > (high_price + low_price) / 2):
                    patterns.append("âœ… Spring (ä½ä½æµ‹è¯•æˆåŠŸ)")
                
                # 6. Wide Spread + Close Positionåˆ†æ
                elif total_range > df['high'].subtract(df['low']).iloc[max(0, i-20):i].quantile(0.7):
                    close_position = (close_price - low_price) / total_range
                    if close_position > 0.8 and vol_ratio > 1.2:
                        patterns.append("ğŸ’ª Wide Spreadæ”¶é«˜ä½ (Professional Buying)")
                    elif close_position < 0.2 and vol_ratio > 1.2:
                        patterns.append("ğŸ˜° Wide Spreadæ”¶ä½ä½ (Selling Pressure)")
                
                # 7. Narrow Spreadåˆ†æ
                elif total_range < df['high'].subtract(df['low']).iloc[max(0, i-20):i].quantile(0.3):
                    if vol_ratio < 0.8:
                        patterns.append("ğŸ˜´ Narrow Spreadä½é‡ (ç¼ºä¹å…´è¶£)")
            
            # å¤šæ ¹Kçº¿VPAç»„åˆå½¢æ€
            if i > 0:
                prev_row = df.iloc[i-1]
                prev_close = prev_row['close']
                prev_volume = prev_row['volume']
                
                # Test Bar (æµ‹è¯•å‰æœŸä½ç‚¹/é«˜ç‚¹)
                if abs(low_price - df['low'].iloc[max(0, i-20):i].min()) / low_price < 0.01:
                    if vol_ratio < 0.8:
                        patterns.append("ğŸ§ª Test (ä½é‡æµ‹è¯•ä½ç‚¹)")
                
                # Stopping Volume (é˜»æ­¢æ€§æˆäº¤é‡)
                if (close_price > prev_close and vol_ratio > 2.0 and 
                    body_ratio < 0.3):  # é«˜é‡ä½†å®ä½“å°
                    patterns.append("ğŸ›‘ Stopping Volume (é˜»æ­¢æ€§æˆäº¤é‡)")
            
            # åªè®°å½•æœ‰VPAæ„ä¹‰çš„å½¢æ€
            if patterns:
                datetime_str = row['datetime']
                pattern_desc = f"**{datetime_str}**: {candle_type} - {', '.join(patterns)}"
                pattern_desc += f" (ä»·æ ¼:{close_price:.2f}, é‡:{volume:,.0f})"
                patterns_found.append(pattern_desc)
        
        return patterns_found
    
    @staticmethod
    def estimate_tokens_by_format(df: pd.DataFrame) -> Dict[str, int]:
        """
        ä¼°ç®—ä¸åŒæ ¼å¼çš„tokenä½¿ç”¨é‡
        """
        formatter = DataFormatter()
        
        estimates = {}
        
        # CSVæ ¼å¼
        csv_data = formatter.to_csv_format(df)
        estimates['csv'] = len(csv_data.split()) + len(csv_data) // 4  # ç²—ç•¥ä¼°ç®—
        
        # æ–‡æœ¬æ ¼å¼
        text_data = formatter.to_text_narrative(df)
        estimates['text'] = len(text_data.split())
        
        # JSONæ ¼å¼
        json_data = formatter.to_structured_json(df)
        estimates['json'] = len(json_data.split()) + len(json_data) // 3  # JSONçš„tokenå¯†åº¦æ›´é«˜
        
        # æ¨¡å¼æè¿°æ ¼å¼
        pattern_data = formatter.to_pattern_description(df)
        estimates['pattern'] = len(pattern_data.split())
        
        return estimates