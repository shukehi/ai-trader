#!/usr/bin/env python3
"""
æç¤ºè¯ç®¡ç†å™¨ - æ”¯æŒå¤šç§äº¤æ˜“åˆ†ææ–¹æ³•çš„æç¤ºè¯ç®¡ç†
"""

import os
import logging
from typing import Dict, List, Any, Callable, Optional
from pathlib import Path
import json

logger = logging.getLogger(__name__)

# Al Brooksæœ¯è¯­æ˜ å°„ç³»ç»Ÿ - è§£å†³æç¤ºè¯ä¸è¯„ä¼°å™¨æœ¯è¯­ä¸åŒ¹é…é—®é¢˜
BROOKS_TERM_MAPPING = {
    # æ ¸å¿ƒBrooksæ¦‚å¿µåŠå…¶åŒä¹‰è¯
    'always_in_concepts': [
        'always in', 'always in long', 'always in short', 'transitioning',
        'market state', 'å¸‚åœºçŠ¶æ€'
    ],
    
    'bar_patterns': [
        # æç¤ºè¯ä½¿ç”¨çš„æœ¯è¯­ â†’ è¯„ä¼°å™¨å¯æ¥å—çš„æœ¯è¯­
        'reversal bar with long tail', 'pin bar', 'reversal bar',
        'outside bar', 'engulfing bar', 
        'inside bar', 'ii', 'ioi',
        'trend bar', 'follow through', 'follow-through'
    ],
    
    'structure_analysis': [
        'H1', 'H2', 'L1', 'L2', 'high 1', 'high 2', 'low 1', 'low 2',
        'first entry', 'second entry',
        'swing point', 'swing high', 'swing low',
        'pullback', 'two-legged', 'two-legged pullback'
    ],
    
    'brooks_concepts': [
        'breakout mode', 'tight trading range', 'TTR',
        'measured move', 'magnet', 'micro channel',
        'spike and channel', 'wedge', 'flag',
        'trend strength', 'strong', 'medium', 'weak'
    ],
    
    'risk_management': [
        'stop', 'stop loss', 'target', 'entry', 'exit',
        'structural stop', 'position size', 'risk management'
    ]
}

class PromptManager:
    """
    æç¤ºè¯ç®¡ç†å™¨ - Al BrookséªŒè¯æœŸç‰ˆæœ¬
    
    å½“å‰æ”¯æŒçš„åˆ†ææ–¹æ³•ï¼ˆéªŒè¯æœŸï¼‰ï¼š
    - Al Brooks ä»·æ ¼è¡Œä¸ºåˆ†æ (ä¸“ä¸šéªŒè¯ä¸­)
    
    æ³¨æ„ï¼šä¸ºç¡®ä¿åˆ†æè´¨é‡ï¼Œå½“å‰ä»…æ”¯æŒAl Brooksæ–¹æ³•ã€‚
    å…¶ä»–æ–¹æ³•å°†åœ¨éªŒè¯å®Œæˆåé€æ­¥æ¢å¤ã€‚
    """
    
    def __init__(self, prompts_dir: str = None):
        """åˆå§‹åŒ–æç¤ºè¯ç®¡ç†å™¨"""
        if prompts_dir is None:
            # é»˜è®¤ä½¿ç”¨å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•
            self.prompts_dir = Path(__file__).parent
        else:
            self.prompts_dir = Path(prompts_dir)
        
        self._prompt_cache = {}
        self._available_methods = None
        
        logger.info(f"âœ… æç¤ºè¯ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆï¼Œç›®å½•: {self.prompts_dir}")
    
    def load_prompt(self, category: str, method: str) -> str:
        """
        åŠ è½½æŒ‡å®šåˆ†ææ–¹æ³•çš„æç¤ºè¯
        
        Args:
            category: åˆ†æç±»åˆ« (volume_analysis, price_action, ict_concepts, composite)
            method: å…·ä½“æ–¹æ³•å (vpa_classic, liquidity_zones, etc.)
            
        Returns:
            æç¤ºè¯å†…å®¹
        """
        cache_key = f"{category}/{method}"
        
        # æ£€æŸ¥ç¼“å­˜
        if cache_key in self._prompt_cache:
            return self._prompt_cache[cache_key]
        
        # æ„å»ºæ–‡ä»¶è·¯å¾„
        prompt_file = self.prompts_dir / category / f"{method}.txt"
        
        if not prompt_file.exists():
            raise FileNotFoundError(f"æç¤ºè¯æ–‡ä»¶ä¸å­˜åœ¨: {prompt_file}")
        
        try:
            with open(prompt_file, 'r', encoding='utf-8') as f:
                content = f.read().strip()
            
            # ç¼“å­˜æç¤ºè¯
            self._prompt_cache[cache_key] = content
            logger.info(f"ğŸ“„ åŠ è½½æç¤ºè¯: {cache_key}")
            
            return content
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½æç¤ºè¯å¤±è´¥: {cache_key}, é”™è¯¯: {e}")
            raise
    
    def list_available_methods(self) -> Dict[str, List[str]]:
        """
        è·å–æ‰€æœ‰å¯ç”¨çš„åˆ†ææ–¹æ³•
        
        Returns:
            {category: [method1, method2, ...]}
        """
        if self._available_methods is not None:
            return self._available_methods
        
        methods = {}
        
        # æ‰«ææ‰€æœ‰åˆ†ç±»ç›®å½•
        for category_dir in self.prompts_dir.iterdir():
            if category_dir.is_dir() and not category_dir.name.startswith('.'):
                category_name = category_dir.name
                category_methods = []
                
                # æ‰«ææ¯ä¸ªåˆ†ç±»ä¸‹çš„æç¤ºè¯æ–‡ä»¶
                for prompt_file in category_dir.glob('*.txt'):
                    method_name = prompt_file.stem
                    category_methods.append(method_name)
                
                if category_methods:
                    methods[category_name] = sorted(category_methods)
        
        self._available_methods = methods
        logger.info(f"ğŸ” å‘ç°åˆ†ææ–¹æ³•: {dict(methods)}")
        
        return methods
    
    def get_method_info(self, full_method: str) -> Dict[str, str]:
        """
        è§£æå®Œæ•´æ–¹æ³•åå¹¶è¿”å›ä¿¡æ¯
        
        Args:
            full_method: æ ¼å¼å¦‚ "vpa-classic" æˆ– "ict-liquidity"
            
        Returns:
            {'category': 'volume_analysis', 'method': 'vpa_classic', 'display_name': 'VPAç»å…¸åˆ†æ'}
        """
        # ==== Al Brooks éªŒè¯æœŸæ–¹æ³•æ˜ å°„ ====
        # æ³¨æ„ï¼šä¸ºç¡®ä¿åˆ†æè´¨é‡ï¼Œå½“å‰ä»…æ”¯æŒAl Brooksä»·æ ¼è¡Œä¸ºåˆ†ææ–¹æ³•
        # å…¶ä»–æ–¹æ³•å·²æš‚æ—¶ç¦ç”¨ï¼Œå°†åœ¨éªŒè¯å®Œæˆåé€æ­¥æ¢å¤
        # å®Œæ•´æ–¹æ³•åˆ—è¡¨å¤‡ä»½ä½äº: prompt_manager_full.py.backup
        
        method_mapping = {
            # Al Brooks ä»·æ ¼è¡Œä¸ºåˆ†ææ–¹æ³•ï¼ˆéªŒè¯æœŸå”¯ä¸€æ”¯æŒï¼‰
            'al-brooks': {'category': 'price_action', 'method': 'al_brooks_analysis', 'display_name': 'Al Brooksä»·æ ¼è¡Œä¸ºåˆ†æ'},
            'price-action-al-brooks-analysis': {'category': 'price_action', 'method': 'al_brooks_analysis', 'display_name': 'Al Brooksä»·æ ¼è¡Œä¸ºåˆ†æ'},
            
            # ==== æš‚æ—¶ç¦ç”¨çš„æ–¹æ³• ====
            # å°†åœ¨Al BrookséªŒè¯å®ŒæˆåæŒ‰ä»¥ä¸‹é¡ºåºæ¢å¤ï¼š
            # 1. VPAç»å…¸åˆ†æ (åŸºç¡€é‡è¦)
            # 2. ICTå…¬å…ä»·å€¼ç¼ºå£ (æµè¡Œæ–¹æ³•) 
            # 3. å…¶ä»–ICTå’Œä»·æ ¼è¡Œä¸ºæ–¹æ³•
            # 4. é«˜çº§ç»¼åˆåˆ†ææ–¹æ³•
            
            # VPAåˆ†ææ–¹æ³• (æš‚æ—¶ç¦ç”¨)
            # 'vpa-classic': {'category': 'volume_analysis', 'method': 'vpa_classic', 'display_name': 'VPAç»å…¸åˆ†æ'},
            # 'vsa-coulling': {'category': 'volume_analysis', 'method': 'vsa_coulling', 'display_name': 'Anna Coulling VSA'},
            # 'volume-profile': {'category': 'volume_analysis', 'method': 'volume_profile', 'display_name': 'æˆäº¤é‡åˆ†å¸ƒåˆ†æ'},
            
            # ICTæ¦‚å¿µæ–¹æ³• (æš‚æ—¶ç¦ç”¨)
            # 'ict-liquidity': {'category': 'ict_concepts', 'method': 'liquidity_zones', 'display_name': 'ICTæµåŠ¨æ€§åˆ†æ'},
            # 'ict-orderblocks': {'category': 'ict_concepts', 'method': 'order_blocks', 'display_name': 'ICTè®¢å•å—åˆ†æ'},
            # 'ict-fvg': {'category': 'ict_concepts', 'method': 'fair_value_gaps', 'display_name': 'ICTå…¬å…ä»·å€¼ç¼ºå£'},
            
            # å…¶ä»–ä»·æ ¼è¡Œä¸ºåˆ†æ (æš‚æ—¶ç¦ç”¨)
            # 'pa-support-resistance': {'category': 'price_action', 'method': 'support_resistance', 'display_name': 'æ”¯æ’‘é˜»åŠ›åˆ†æ'},
            # 'pa-trend': {'category': 'price_action', 'method': 'trend_analysis', 'display_name': 'è¶‹åŠ¿åˆ†æ'},
            
            # ç»¼åˆåˆ†æ (æš‚æ—¶ç¦ç”¨)
            # 'multi-timeframe': {'category': 'composite', 'method': 'multi_timeframe', 'display_name': 'å¤šæ—¶é—´æ¡†æ¶åˆ†æ'},
            # 'perpetual-specific': {'category': 'composite', 'method': 'perpetual_specific', 'display_name': 'æ°¸ç»­åˆçº¦ä¸“é¡¹åˆ†æ'}
        }
        
        if full_method not in method_mapping:
            # Al BrookséªŒè¯æœŸå‹å¥½é”™è¯¯æç¤º
            available_methods = list(method_mapping.keys())
            raise ValueError(f"\nâŒ å½“å‰éªŒè¯æœŸä»…æ”¯æŒAl Brooksåˆ†ææ–¹æ³•ã€‚\n" +
                           f"ğŸ” å¯ç”¨æ–¹æ³•: {available_methods}\n" +
                           f"ğŸ“ è¯·ä½¿ç”¨: --method price-action-al-brooks-analysis\n" +
                           f"â„¹ï¸  å…¶ä»–æ–¹æ³•å°†åœ¨Al BrookséªŒè¯å®Œæˆåé€æ­¥æ¢å¤ã€‚")
        
        return method_mapping[full_method]
    
    def get_quality_evaluator(self, full_method: str) -> Callable:
        """
        è·å–æŒ‡å®šåˆ†ææ–¹æ³•çš„è´¨é‡è¯„ä¼°å‡½æ•°
        
        Args:
            full_method: å®Œæ•´æ–¹æ³•å
            
        Returns:
            è´¨é‡è¯„ä¼°å‡½æ•°
        """
        method_info = self.get_method_info(full_method)
        category = method_info['category']
        
        # æ ¹æ®åˆ†æç±»åˆ«è¿”å›å¯¹åº”çš„è´¨é‡è¯„ä¼°å™¨
        if category == 'volume_analysis':
            return self._evaluate_vpa_quality
        elif category == 'ict_concepts':
            return self._evaluate_ict_quality  
        elif category == 'price_action':
            return self._evaluate_pa_quality
        elif category == 'composite':
            return self._evaluate_composite_quality
        else:
            return self._evaluate_general_quality
    
    def _evaluate_vpa_quality(self, analysis_text: str, df: Any) -> int:
        """VPAåˆ†æè´¨é‡è¯„ä¼° (åŸºäºVSA/VPAç†è®º)"""
        score = 0
        
        # 1. VPAä¸“ä¸šæœ¯è¯­ (25åˆ†)
        vpa_terms = ['VSA', 'VPA', 'Smart Money', 'Dumb Money', 'Accumulation', 'Distribution', 
                    'Markup', 'Markdown', 'Wide Spread', 'Narrow Spread', 'Volume Climax',
                    'No Demand', 'No Supply', 'Upthrust', 'Spring', 'Effort', 'Result']
        term_count = sum(1 for term in vpa_terms if term.lower() in analysis_text.lower())
        score += min(25, term_count * 3)
        
        # 2. é‡ä»·å…³ç³»åˆ†æ (25åˆ†)
        volume_price_keywords = ['é‡ä»·å…³ç³»', 'æˆäº¤é‡é…åˆ', 'æ”¾é‡', 'ç¼©é‡', 'é‡ä»·èƒŒç¦»', 'é‡ä»·åŒæ­¥']
        if any(keyword in analysis_text for keyword in volume_price_keywords):
            score += 25
        
        # 3. å¸‚åœºé˜¶æ®µè¯†åˆ« (25åˆ†) 
        stage_keywords = ['accumulation', 'distribution', 'markup', 'markdown', 'å¸ç­¹', 'æ´¾å‘', 'æ‹‰å‡', 'ä¸‹è·Œ']
        if any(keyword.lower() in analysis_text.lower() for keyword in stage_keywords):
            score += 25
        
        # 4. å…·ä½“æ•°æ®å¼•ç”¨ (15åˆ†)
        if any(str(round(price, 2)) in analysis_text for price in df['close'].values[-5:]):
            score += 15
        
        # 5. äº¤æ˜“å»ºè®® (10åˆ†)
        trading_keywords = ['å»ºè®®', 'å…¥åœº', 'å‡ºåœº', 'æ­¢æŸ', 'ç›®æ ‡']
        if any(keyword in analysis_text for keyword in trading_keywords):
            score += 10
        
        return min(100, score)
    
    def _evaluate_ict_quality(self, analysis_text: str, df: Any) -> int:
        """ICTæ¦‚å¿µåˆ†æè´¨é‡è¯„ä¼°"""
        score = 0
        
        # 1. ICTä¸“ä¸šæœ¯è¯­ (30åˆ†)
        ict_terms = ['Liquidity', 'Order Block', 'Fair Value Gap', 'FVG', 'Market Structure', 
                    'BOS', 'CHoCH', 'Displacement', 'Imbalance', 'Smart Money', 'Institutional',
                    'Manipulation', 'Accumulation', 'Distribution', 'PD Arrays', 'Optimal Trade Entry']
        term_count = sum(1 for term in ict_terms if term.lower() in analysis_text.lower())
        score += min(30, term_count * 4)
        
        # 2. æµåŠ¨æ€§åˆ†æ (20åˆ†)
        liquidity_keywords = ['æµåŠ¨æ€§', 'liquidity', 'æ­¢æŸçŒå–', 'stop hunt', 'æµåŠ¨æ€§åŒºåŸŸ']
        if any(keyword.lower() in analysis_text.lower() for keyword in liquidity_keywords):
            score += 20
        
        # 3. å¸‚åœºç»“æ„åˆ†æ (20åˆ†)
        structure_keywords = ['å¸‚åœºç»“æ„', 'market structure', 'BOS', 'break of structure', 'CHoCH']
        if any(keyword.lower() in analysis_text.lower() for keyword in structure_keywords):
            score += 20
        
        # 4. å…·ä½“ä»·ä½åˆ†æ (20åˆ†)
        if any(str(round(price, 2)) in analysis_text for price in df['close'].values[-5:]):
            score += 20
        
        # 5. å…¥åœºç­–ç•¥ (10åˆ†)
        entry_keywords = ['å…¥åœº', 'entry', 'OTE', 'optimal trade entry', 'æœ€ä¼˜å…¥åœº']
        if any(keyword.lower() in analysis_text.lower() for keyword in entry_keywords):
            score += 10
        
        return min(100, score)
    
    def _evaluate_pa_quality(self, analysis_text: str, df: Any) -> int:
        """ä»·æ ¼è¡Œä¸ºåˆ†æè´¨é‡è¯„ä¼°ï¼ˆä¼˜åŒ–Al Brooksæ”¯æŒï¼‰- æ–°æƒé‡åˆ†é…"""
        score = 0
        text_lower = analysis_text.lower()
        
        # === ä¼˜åŒ–æƒé‡åˆ†é…ï¼šåˆ†æè´¨é‡60åˆ† + æœ¯è¯­å‡†ç¡®40åˆ† ===
        
        # 1. ç»“æ„åˆ†ææ·±åº¦ (30åˆ†) - æé«˜æƒé‡
        structure_score = 0
        # Always InçŠ¶æ€åˆ†æ
        always_in_terms = BROOKS_TERM_MAPPING['always_in_concepts']
        if any(term.lower() in text_lower for term in always_in_terms):
            structure_score += 15
        
        # ç»“æ„è¯†åˆ« (swing points, H1/H2ç­‰)
        structure_terms = BROOKS_TERM_MAPPING['structure_analysis']
        structure_count = sum(1 for term in structure_terms if term.lower() in text_lower)
        structure_score += min(15, structure_count * 3)
        score += min(30, structure_score)
        
        # 2. äº¤æ˜“è®¡åˆ’å®Œæ•´æ€§ (20åˆ†) - æé«˜æƒé‡
        plan_score = 0
        risk_terms = BROOKS_TERM_MAPPING['risk_management']
        plan_count = sum(1 for term in risk_terms if term.lower() in text_lower)
        plan_score = min(20, plan_count * 4)
        score += plan_score
        
        # 3. Brooksæ¦‚å¿µåº”ç”¨ (10åˆ†) - æ¦‚å¿µæ·±åº¦
        concept_terms = BROOKS_TERM_MAPPING['brooks_concepts']
        concept_count = sum(1 for term in concept_terms if term.lower() in text_lower)
        score += min(10, concept_count * 2)
        
        # 4. Brooksæœ¯è¯­å‡†ç¡®æ€§ (25åˆ†) - ä½¿ç”¨æ˜ å°„è¡¨
        term_score = 0
        bar_patterns = BROOKS_TERM_MAPPING['bar_patterns']
        pattern_count = sum(1 for pattern in bar_patterns if pattern.lower() in text_lower)
        term_score = min(25, pattern_count * 3)
        score += term_score
        
        # 5. å…·ä½“ä»·ä½å¼•ç”¨ (15åˆ†) - æé«˜æƒé‡ï¼Œä½“ç°æ•°æ®ç»“åˆ
        price_score = 0
        # æ£€æŸ¥æœ€è¿‘5ä¸ªä»·ä½çš„å¼•ç”¨
        recent_prices = df['close'].values[-5:]
        price_matches = sum(1 for price in recent_prices 
                          if str(round(float(price), 2)) in analysis_text)
        price_score += price_matches * 5
        
        # æ£€æŸ¥å…³é”®ä»·ä½ï¼ˆæ”¯æ’‘é˜»åŠ›ï¼‰çš„æ•°å€¼å¼•ç”¨
        if any(keyword in text_lower for keyword in ['support', 'æ”¯æ’‘', 'resistance', 'é˜»åŠ›']):
            price_score += 5
        
        score += min(15, price_score)
        
        # === è´¨é‡åŠ åˆ†é¡¹ ===
        # JSONæ ¼å¼å®Œæ•´æ€§å¥–åŠ± (é¢å¤–5åˆ†)
        if 'schema_version' in text_lower and 'always_in_state' in text_lower:
            score += 5
            
        # é£é™©ç®¡ç†ç»†èŠ‚å¥–åŠ± (é¢å¤–5åˆ†)
        if any(term in text_lower for term in ['structural stop', 'measured move', 'magnet']):
            score += 5
        
        return min(100, score)
    
    def _evaluate_composite_quality(self, analysis_text: str, df: Any) -> int:
        """ç»¼åˆåˆ†æè´¨é‡è¯„ä¼°"""
        score = 0
        
        # 1. å¤šç»´åº¦åˆ†æ (30åˆ†)
        dimensions = ['æŠ€æœ¯åˆ†æ', 'åŸºæœ¬é¢', 'æƒ…ç»ªé¢', 'èµ„é‡‘é¢', 'technical', 'fundamental', 'sentiment']
        dimension_count = sum(1 for dim in dimensions if dim.lower() in analysis_text.lower())
        score += min(30, dimension_count * 6)
        
        # 2. æ—¶é—´æ¡†æ¶åˆ†æ (25åˆ†)
        timeframe_keywords = ['çŸ­æœŸ', 'ä¸­æœŸ', 'é•¿æœŸ', 'å¤šæ—¶é—´æ¡†æ¶', 'short term', 'medium term', 'long term']
        if any(keyword.lower() in analysis_text.lower() for keyword in timeframe_keywords):
            score += 25
        
        # 3. é£é™©ç®¡ç† (25åˆ†)
        risk_keywords = ['é£é™©ç®¡ç†', 'æ­¢æŸ', 'èµ„é‡‘ç®¡ç†', 'ä»“ä½æ§åˆ¶', 'risk management', 'position sizing']
        if any(keyword.lower() in analysis_text.lower() for keyword in risk_keywords):
            score += 25
        
        # 4. æ•°æ®å¼•ç”¨ (20åˆ†)
        if any(str(round(price, 2)) in analysis_text for price in df['close'].values[-5:]):
            score += 20
        
        return min(100, score)
    
    def _evaluate_general_quality(self, analysis_text: str, df: Any) -> int:
        """é€šç”¨è´¨é‡è¯„ä¼° (åå¤‡æ–¹æ¡ˆ)"""
        score = 0
        
        # åŸºç¡€è¯„ä¼°æ ‡å‡†
        if len(analysis_text) > 200:
            score += 20
        if any(str(round(price, 2)) in analysis_text for price in df['close'].values[-5:]):
            score += 30
        
        general_keywords = ['åˆ†æ', 'å»ºè®®', 'è¶‹åŠ¿', 'æ”¯æ’‘', 'é˜»åŠ›', 'æˆäº¤é‡']
        keyword_count = sum(1 for kw in general_keywords if kw in analysis_text)
        score += min(50, keyword_count * 10)
        
        return min(100, score)
    
    def clear_cache(self):
        """æ¸…ç©ºæç¤ºè¯ç¼“å­˜"""
        self._prompt_cache.clear()
        self._available_methods = None
        logger.info("ğŸ—‘ï¸ æç¤ºè¯ç¼“å­˜å·²æ¸…ç©º")
    
    def reload_prompts(self):
        """é‡æ–°åŠ è½½æ‰€æœ‰æç¤ºè¯"""
        self.clear_cache()
        self.list_available_methods()
        logger.info("ğŸ”„ æç¤ºè¯å·²é‡æ–°åŠ è½½")