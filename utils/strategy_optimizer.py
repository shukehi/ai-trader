#!/usr/bin/env python3
"""
ç­–ç•¥ä¼˜åŒ–å™¨ - åŸºäºå†å²æ•°æ®çš„äº¤æ˜“ç­–ç•¥å’ŒAIæ¨¡å‹ä¼˜åŒ–
å®ç°å›æµ‹åˆ†æã€å‚æ•°è°ƒä¼˜ã€æ¨¡å‹å­¦ä¹ ç­‰é«˜çº§åŠŸèƒ½
"""

import sqlite3
import json
import pandas as pd
import numpy as np
from datetime import datetime, timezone, timedelta
from typing import Dict, List, Optional, Any, Tuple
from pathlib import Path
import logging
import re
from collections import defaultdict, Counter
# import matplotlib.pyplot as plt  # Optional visualization
# import seaborn as sns  # Optional for advanced plots

logger = logging.getLogger(__name__)

class StrategyOptimizer:
    """
    ç­–ç•¥ä¼˜åŒ–å™¨
    
    åŠŸèƒ½ç‰¹æ€§:
    - AIæç¤ºè¯ä¼˜åŒ–å»ºè®®
    - ä¿¡å·æå–è§„åˆ™æ”¹è¿›
    - é£é™©å‚æ•°è°ƒä¼˜
    - äº¤æ˜“æ—¶é—´çª—å£åˆ†æ
    """
    
    def __init__(self, db_path: str = "logs/trading_database.db"):
        """åˆå§‹åŒ–ç­–ç•¥ä¼˜åŒ–å™¨"""
        self.db_path = Path(db_path)
        if not self.db_path.exists():
            raise FileNotFoundError(f"æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {db_path}")
            
        logger.info(f"ç­–ç•¥ä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def analyze_prompt_effectiveness(self) -> Dict[str, Any]:
        """
        åˆ†æä¸åŒAIæç¤ºè¯çš„æœ‰æ•ˆæ€§
        ä»åˆ†ææ–‡æœ¬ä¸­æå–å…³é”®è¯å’Œæ¨¡å¼
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                query = """
                SELECT 
                    a.model_used,
                    a.raw_analysis,
                    a.confidence_score,
                    t.realized_pnl,
                    t.side
                FROM ai_decisions a
                LEFT JOIN trades t ON a.decision_id = t.ai_decision_id
                WHERE a.raw_analysis IS NOT NULL
                """
                
                cursor = conn.cursor()
                cursor.execute(query)
                rows = cursor.fetchall()
                
                # åˆ†ææˆåŠŸå’Œå¤±è´¥çš„åˆ†ææ–‡æœ¬ç‰¹å¾
                success_keywords = Counter()
                failure_keywords = Counter()
                
                vpa_terms = [
                    'distribution', 'accumulation', 'markup', 'markdown',
                    'no supply', 'no demand', 'climax volume', 'upthrust', 'spring',
                    'wide spread', 'narrow spread', 'selling pressure', 'buying pressure',
                    'professional money', 'smart money', 'dumb money'
                ]
                
                analysis_results = {
                    'successful_patterns': defaultdict(int),
                    'failed_patterns': defaultdict(int),
                    'model_vpa_usage': defaultdict(lambda: {'total': 0, 'vpa_terms': 0}),
                    'confidence_correlation': []
                }
                
                for row in rows:
                    model, analysis, confidence, pnl, side = row
                    if not analysis:
                        continue
                        
                    analysis_lower = analysis.lower()
                    is_successful = pnl and pnl > 0
                    
                    # ç»Ÿè®¡VPAæœ¯è¯­ä½¿ç”¨
                    vpa_count = sum(1 for term in vpa_terms if term in analysis_lower)
                    analysis_results['model_vpa_usage'][model]['total'] += 1
                    analysis_results['model_vpa_usage'][model]['vpa_terms'] += vpa_count
                    
                    # æå–å…³é”®æ¨¡å¼
                    words = re.findall(r'\b[a-zA-Z]{4,}\b', analysis_lower)
                    for word in words:
                        if is_successful:
                            analysis_results['successful_patterns'][word] += 1
                        else:
                            analysis_results['failed_patterns'][word] += 1
                    
                    # ç½®ä¿¡åº¦ç›¸å…³æ€§
                    if confidence:
                        analysis_results['confidence_correlation'].append({
                            'confidence': confidence,
                            'success': is_successful,
                            'vpa_terms': vpa_count
                        })
                
                # è®¡ç®—VPAæœ¯è¯­ä½¿ç”¨ç‡
                vpa_usage_summary = {}
                for model, data in analysis_results['model_vpa_usage'].items():
                    if data['total'] > 0:
                        vpa_usage_summary[model] = {
                            'vpa_usage_rate': data['vpa_terms'] / data['total'],
                            'total_analyses': data['total']
                        }
                
                return {
                    'vpa_usage_by_model': vpa_usage_summary,
                    'top_success_words': dict(Counter(analysis_results['successful_patterns']).most_common(10)),
                    'top_failure_words': dict(Counter(analysis_results['failed_patterns']).most_common(10)),
                    'confidence_data': analysis_results['confidence_correlation']
                }
                
        except Exception as e:
            logger.error(f"æç¤ºè¯æ•ˆæœåˆ†æå¤±è´¥: {e}")
            return {'error': str(e)}
    
    def optimize_signal_extraction_rules(self) -> Dict[str, Any]:
        """
        ä¼˜åŒ–ä¿¡å·æå–çš„æ­£åˆ™è¡¨è¾¾å¼è§„åˆ™
        åŸºäºæˆåŠŸå’Œå¤±è´¥æ¡ˆä¾‹æ”¹è¿›è§£æé€»è¾‘
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                query = """
                SELECT 
                    a.raw_analysis,
                    a.extracted_signals,
                    t.realized_pnl,
                    t.side,
                    t.entry_price,
                    t.exit_price
                FROM ai_decisions a
                LEFT JOIN trades t ON a.decision_id = t.ai_decision_id
                WHERE a.raw_analysis IS NOT NULL AND a.extracted_signals IS NOT NULL
                """
                
                cursor = conn.cursor()
                cursor.execute(query)
                rows = cursor.fetchall()
                
                # åˆ†æä¿¡å·æå–çš„å‡†ç¡®æ€§
                extraction_analysis = {
                    'missed_signals': [],  # AIæåˆ°äº†ä½†æ²¡æå–åˆ°çš„ä¿¡å·
                    'incorrect_extractions': [],  # æå–é”™è¯¯çš„ä¿¡å·
                    'successful_extractions': [],  # æˆåŠŸçš„æå–
                    'suggested_patterns': []  # å»ºè®®çš„æ–°æ­£åˆ™è¡¨è¾¾å¼
                }
                
                # å®šä¹‰ä¸€äº›åº”è¯¥è¢«æ•è·çš„ä¿¡å·æ¨¡å¼
                signal_patterns = {
                    'entry_price': [
                        r'å…¥åœºä»·æ ¼?\s*[:ï¼š]\s*\$?(\d+\.?\d*)',
                        r'å»ºè®®.*?(\d+\.?\d*)\s*é™„è¿‘.*?å…¥åœº',
                        r'ä»·æ ¼.*?(\d+\.?\d*)\s*åš[å¤šç©º]'
                    ],
                    'stop_loss': [
                        r'æ­¢æŸä»·æ ¼?\s*[:ï¼š]\s*\$?(\d+\.?\d*)',
                        r'æ­¢æŸ.*?(\d+\.?\d*)',
                        r'åœæŸ.*?(\d+\.?\d*)'
                    ],
                    'take_profit': [
                        r'æ­¢ç›ˆä»·æ ¼?\s*[:ï¼š]\s*\$?(\d+\.?\d*)',
                        r'ç›®æ ‡ä»·æ ¼?\s*[:ï¼š]\s*\$?(\d+\.?\d*)',
                        r'è·åˆ©äº†ç»“.*?(\d+\.?\d*)'
                    ],
                    'direction': [
                        r'å»ºè®®\s*(åšå¤š|åšç©º|ä¹°å…¥|å–å‡º)',
                        r'(çœ‹å¤š|çœ‹ç©º|çœ‹æ¶¨|çœ‹è·Œ)',
                        r'(bullish|bearish|ä¹°|å–)'
                    ]
                }
                
                for row in rows:
                    analysis, extracted_str, pnl, side, entry, exit = row
                    if not analysis:
                        continue
                        
                    try:
                        extracted = json.loads(extracted_str) if extracted_str else {}
                    except:
                        extracted = {}
                    
                    is_successful = pnl and pnl > 0
                    
                    # æ£€æŸ¥æ¯ç§ä¿¡å·ç±»å‹çš„æå–æƒ…å†µ
                    for signal_type, patterns in signal_patterns.items():
                        found_in_text = False
                        extracted_value = extracted.get(signal_type)
                        
                        # æ£€æŸ¥æ–‡æœ¬ä¸­æ˜¯å¦æœ‰è¿™ç±»ä¿¡å·
                        for pattern in patterns:
                            if re.search(pattern, analysis, re.IGNORECASE):
                                found_in_text = True
                                break
                        
                        # åˆ†ææå–ç»“æœ
                        if found_in_text and not extracted_value:
                            extraction_analysis['missed_signals'].append({
                                'signal_type': signal_type,
                                'analysis_text': analysis[:200] + '...',
                                'success': is_successful
                            })
                        elif found_in_text and extracted_value and is_successful:
                            extraction_analysis['successful_extractions'].append({
                                'signal_type': signal_type,
                                'extracted_value': extracted_value,
                                'analysis_text': analysis[:100] + '...'
                            })
                
                # ç”Ÿæˆæ”¹è¿›å»ºè®®
                suggestions = []
                if extraction_analysis['missed_signals']:
                    suggestions.append({
                        'type': 'pattern_improvement',
                        'issue': f"å‘ç° {len(extraction_analysis['missed_signals'])} ä¸ªæ¼æå–ä¿¡å·",
                        'suggestion': 'éœ€è¦æ”¹è¿›æ­£åˆ™è¡¨è¾¾å¼åŒ¹é…æ¨¡å¼',
                        'implementation': 'signal_executor.pyä¸­çš„_extract_signals_from_textæ–¹æ³•'
                    })
                
                return {
                    'extraction_analysis': extraction_analysis,
                    'optimization_suggestions': suggestions
                }
                
        except Exception as e:
            logger.error(f"ä¿¡å·æå–è§„åˆ™ä¼˜åŒ–å¤±è´¥: {e}")
            return {'error': str(e)}
    
    def analyze_optimal_parameters(self) -> Dict[str, Any]:
        """
        åˆ†ææœ€ä¼˜çš„äº¤æ˜“å‚æ•°è®¾ç½®
        åŒ…æ‹¬é£é™©æ¯”ä¾‹ã€æ æ†ã€æŒä»“æ—¶é—´ç­‰
        """
        try:
            with sqlite3.connect(self.db_path) as conn:
                query = """
                SELECT 
                    t.leverage,
                    t.margin_used,
                    t.holding_duration,
                    t.realized_pnl,
                    t.quantity,
                    t.entry_price,
                    t.exit_price,
                    a.confidence_score
                FROM trades t
                JOIN ai_decisions a ON t.ai_decision_id = a.decision_id
                WHERE t.realized_pnl IS NOT NULL
                """
                
                df = pd.read_sql_query(query, conn)
                
                if df.empty:
                    return {'message': 'æš‚æ— å·²å®Œæˆäº¤æ˜“æ•°æ®è¿›è¡Œå‚æ•°åˆ†æ'}
                
                # åˆ†æä¸åŒå‚æ•°ä¸‹çš„è¡¨ç°
                parameter_analysis = {
                    'leverage_performance': {},
                    'position_size_performance': {},
                    'holding_time_performance': {},
                    'confidence_threshold_analysis': {}
                }
                
                # æ æ†åˆ†æ
                leverage_groups = df.groupby('leverage')
                for leverage, group in leverage_groups:
                    parameter_analysis['leverage_performance'][leverage] = {
                        'trade_count': len(group),
                        'win_rate': (group['realized_pnl'] > 0).mean(),
                        'avg_pnl': group['realized_pnl'].mean(),
                        'total_pnl': group['realized_pnl'].sum()
                    }
                
                # ä»“ä½å¤§å°åˆ†æï¼ˆæŒ‰åˆ†ä½æ•°åˆ†ç»„ï¼‰
                df['position_size_quantile'] = pd.qcut(df['quantity'], q=3, labels=['Small', 'Medium', 'Large'])
                size_groups = df.groupby('position_size_quantile')
                for size, group in size_groups:
                    parameter_analysis['position_size_performance'][str(size)] = {
                        'trade_count': len(group),
                        'win_rate': (group['realized_pnl'] > 0).mean(),
                        'avg_pnl': group['realized_pnl'].mean()
                    }
                
                # æŒä»“æ—¶é—´åˆ†æ
                if df['holding_duration'].notna().any():
                    df['holding_hours'] = df['holding_duration'] / 3600
                    df['holding_category'] = pd.cut(df['holding_hours'], 
                                                   bins=[0, 1, 6, 24, float('inf')], 
                                                   labels=['<1h', '1-6h', '6-24h', '>24h'])
                    
                    time_groups = df.groupby('holding_category')
                    for time_cat, group in time_groups:
                        if len(group) > 0:
                            parameter_analysis['holding_time_performance'][str(time_cat)] = {
                                'trade_count': len(group),
                                'win_rate': (group['realized_pnl'] > 0).mean(),
                                'avg_pnl': group['realized_pnl'].mean()
                            }
                
                return parameter_analysis
                
        except Exception as e:
            logger.error(f"å‚æ•°ä¼˜åŒ–åˆ†æå¤±è´¥: {e}")
            return {'error': str(e)}
    
    def generate_optimization_plan(self) -> Dict[str, Any]:
        """
        ç”Ÿæˆç»¼åˆä¼˜åŒ–è®¡åˆ’
        æ•´åˆæ‰€æœ‰åˆ†æç»“æœï¼Œæä¾›å…·ä½“çš„æ”¹è¿›æ­¥éª¤
        """
        try:
            prompt_analysis = self.analyze_prompt_effectiveness()
            signal_analysis = self.optimize_signal_extraction_rules()
            param_analysis = self.analyze_optimal_parameters()
            
            optimization_plan = {
                'immediate_actions': [],  # ç«‹å³å¯æ‰§è¡Œçš„æ”¹è¿›
                'short_term_goals': [],   # çŸ­æœŸç›®æ ‡ï¼ˆ1-2å‘¨ï¼‰
                'long_term_strategy': [], # é•¿æœŸç­–ç•¥ï¼ˆ1ä¸ªæœˆ+ï¼‰
                'priority_score': {}
            }
            
            # åŸºäºåˆ†æç»“æœç”Ÿæˆå…·ä½“å»ºè®®
            
            # 1. æç¤ºè¯ä¼˜åŒ–å»ºè®®
            if 'vpa_usage_by_model' in prompt_analysis:
                for model, data in prompt_analysis['vpa_usage_by_model'].items():
                    if data['vpa_usage_rate'] < 0.5:  # VPAæœ¯è¯­ä½¿ç”¨ç‡ä½
                        optimization_plan['immediate_actions'].append({
                            'action': f'ä¼˜åŒ–{model}çš„VPAæç¤ºè¯',
                            'reason': f'å½“å‰VPAæœ¯è¯­ä½¿ç”¨ç‡ä»…{data["vpa_usage_rate"]:.1%}',
                            'implementation': 'ai/trading_prompts.pyä¸­å¢åŠ æ›´å¤šVPAä¸“ä¸šæœ¯è¯­',
                            'priority': 'high',
                            'effort': 'low'
                        })
            
            # 2. ä¿¡å·æå–æ”¹è¿›
            if 'extraction_analysis' in signal_analysis:
                missed_count = len(signal_analysis['extraction_analysis'].get('missed_signals', []))
                if missed_count > 0:
                    optimization_plan['short_term_goals'].append({
                        'goal': 'æ”¹è¿›ä¿¡å·æå–å‡†ç¡®æ€§',
                        'target': f'å‡å°‘{missed_count}ä¸ªæ¼æå–ä¿¡å·',
                        'implementation': 'trading/signal_executor.pyä¸­çš„æ­£åˆ™è¡¨è¾¾å¼ä¼˜åŒ–',
                        'timeline': '1-2å‘¨',
                        'priority': 'medium'
                    })
            
            # 3. å‚æ•°ä¼˜åŒ–å»ºè®®
            if 'leverage_performance' in param_analysis:
                best_leverage = max(param_analysis['leverage_performance'].keys(),
                                  key=lambda k: param_analysis['leverage_performance'][k]['win_rate'])
                optimization_plan['immediate_actions'].append({
                    'action': f'è°ƒæ•´é»˜è®¤æ æ†åˆ°{best_leverage}x',
                    'reason': f'æ æ†{best_leverage}xèƒœç‡æœ€é«˜',
                    'implementation': 'config/trading_config.pyä¸­çš„é»˜è®¤æ æ†è®¾ç½®',
                    'priority': 'medium',
                    'effort': 'low'
                })
            
            # 4. é•¿æœŸç­–ç•¥
            optimization_plan['long_term_strategy'].extend([
                {
                    'strategy': 'å»ºç«‹AIæ¨¡å‹A/Bæµ‹è¯•æ¡†æ¶',
                    'description': 'åŒæ—¶è¿è¡Œå¤šä¸ªæ¨¡å‹å¹¶å¯¹æ¯”è¡¨ç°',
                    'benefits': 'æŒç»­ä¼˜åŒ–æ¨¡å‹é€‰æ‹©',
                    'timeline': '1ä¸ªæœˆ'
                },
                {
                    'strategy': 'å®ç°åŠ¨æ€å‚æ•°è°ƒæ•´',
                    'description': 'æ ¹æ®å¸‚åœºæ¡ä»¶è‡ªåŠ¨è°ƒæ•´é£é™©å‚æ•°',
                    'benefits': 'æé«˜é€‚åº”æ€§å’Œç¨³å®šæ€§',
                    'timeline': '2ä¸ªæœˆ'
                }
            ])
            
            # è®¡ç®—ä¼˜å…ˆçº§è¯„åˆ†
            total_improvements = (len(optimization_plan['immediate_actions']) + 
                                len(optimization_plan['short_term_goals']) + 
                                len(optimization_plan['long_term_strategy']))
            
            optimization_plan['priority_score'] = {
                'total_improvements': total_improvements,
                'high_priority': len([a for a in optimization_plan['immediate_actions'] if a.get('priority') == 'high']),
                'quick_wins': len([a for a in optimization_plan['immediate_actions'] if a.get('effort') == 'low']),
                'optimization_potential': 'high' if total_improvements > 5 else 'medium' if total_improvements > 2 else 'low'
            }
            
            return optimization_plan
            
        except Exception as e:
            logger.error(f"ä¼˜åŒ–è®¡åˆ’ç”Ÿæˆå¤±è´¥: {e}")
            return {'error': str(e)}

def main():
    """æ¼”ç¤ºç­–ç•¥ä¼˜åŒ–åŠŸèƒ½"""
    try:
        optimizer = StrategyOptimizer()
        
        print("ğŸ¯ å¼€å§‹ç­–ç•¥ä¼˜åŒ–åˆ†æ...")
        
        print("\nğŸ“ åˆ†ææç¤ºè¯æ•ˆæœ...")
        prompt_results = optimizer.analyze_prompt_effectiveness()
        if 'vpa_usage_by_model' in prompt_results:
            print("VPAæœ¯è¯­ä½¿ç”¨ç‡:")
            for model, data in prompt_results['vpa_usage_by_model'].items():
                print(f"  {model}: {data['vpa_usage_rate']:.1%}")
        
        print("\nğŸ” åˆ†æä¿¡å·æå–è§„åˆ™...")
        signal_results = optimizer.optimize_signal_extraction_rules()
        if 'extraction_analysis' in signal_results:
            missed = len(signal_results['extraction_analysis'].get('missed_signals', []))
            print(f"å‘ç° {missed} ä¸ªæ¼æå–çš„ä¿¡å·")
        
        print("\nâš™ï¸ åˆ†ææœ€ä¼˜å‚æ•°...")
        param_results = optimizer.analyze_optimal_parameters()
        
        print("\nğŸ“‹ ç”Ÿæˆä¼˜åŒ–è®¡åˆ’...")
        plan = optimizer.generate_optimization_plan()
        
        print(f"\nğŸ† ä¼˜åŒ–æ½œåŠ›: {plan['priority_score']['optimization_potential'].upper()}")
        print(f"æ€»æ”¹è¿›é¡¹: {plan['priority_score']['total_improvements']}")
        print(f"é«˜ä¼˜å…ˆçº§é¡¹: {plan['priority_score']['high_priority']}")
        print(f"å¿«é€Ÿå®ç°é¡¹: {plan['priority_score']['quick_wins']}")
        
        print("\nğŸ’¡ ç«‹å³å¯æ‰§è¡Œçš„æ”¹è¿›:")
        for action in plan['immediate_actions'][:3]:
            print(f"  â€¢ {action['action']}")
            print(f"    åŸå› : {action['reason']}")
            print(f"    å®æ–½: {action['implementation']}")
        
    except Exception as e:
        print(f"âŒ ç­–ç•¥ä¼˜åŒ–åˆ†æå¤±è´¥: {e}")

if __name__ == "__main__":
    main()