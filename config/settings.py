import os
from dotenv import load_dotenv

load_dotenv()

class Settings:
    # OpenRouter API
    OPENROUTER_API_KEY = os.getenv('OPENROUTER_API_KEY')
    OPENROUTER_BASE_URL = "https://openrouter.ai/api/v1"
    
    # Available models for testing (OpenRouter 2025 Latest)
    MODELS = {
        # ğŸ”¥ 2025 Latest Flagship Models
        'gpt5-chat': 'openai/gpt-5-chat',                    # GPT-5 Chat (æ¨è)
        'gpt5-mini': 'openai/gpt-5-mini',                    # GPT-5 Mini (ç»æµç‰ˆ)
        'gpt5-nano': 'openai/gpt-5-nano',                    # GPT-5 Nano (è¶…è½»é‡)
        'claude-opus-41': 'anthropic/claude-opus-4.1',        # Claude Opus 4.1
        'gemini-25-pro': 'google/gemini-2.5-pro',            # Gemini 2.5 Pro
        'grok4': 'x-ai/grok-4',                              # Grok 4
        
        # OpenAI Models
        'gpt4': 'openai/gpt-4-turbo-2024-04-09',
        'gpt4o': 'openai/gpt-4o-2024-11-20',
        'gpt4o-mini': 'openai/gpt-4o-mini-2024-07-18',
        'o1': 'openai/o1-2024-12-17',
        'o1-mini': 'openai/o1-mini-2024-09-12',
        
        # Anthropic Claude Models  
        'claude': 'anthropic/claude-3.5-sonnet-20241022',
        'claude-haiku': 'anthropic/claude-3.5-haiku-20241022',
        'claude-opus': 'anthropic/claude-3-opus-20240229',
        
        # Google Gemini Models
        'gemini': 'google/gemini-pro-1.5',
        'gemini-flash': 'google/gemini-flash-1.5',
        'gemini-2': 'google/gemini-2.0-flash-exp',
        
        # xAI Grok Models
        'grok': 'x-ai/grok-beta',
        'grok-vision': 'x-ai/grok-vision-beta',
        
        # Meta Llama Models (é«˜æ€§ä»·æ¯”é€‰æ‹©)
        'llama': 'meta-llama/llama-3.1-70b-instruct',
        'llama-405b': 'meta-llama/llama-3.1-405b-instruct'
    }
    
    # Binance API (optional)
    BINANCE_API_KEY = os.getenv('BINANCE_API_KEY')
    BINANCE_SECRET_KEY = os.getenv('BINANCE_SECRET_KEY')
    
    # Data settings
    DEFAULT_SYMBOL = 'ETHUSDT'
    DEFAULT_TIMEFRAME = '1h'
    DEFAULT_LIMIT = 50
    
    # Multi-Model Validation Settings
    VALIDATION_CONFIG = {
        # ä¸»è¦éªŒè¯æ¨¡å‹ï¼ˆåŸºäºPhase2æµ‹è¯•ç»“æœï¼‰
        'primary_models': ['gpt5-mini', 'claude-opus-41'],
        
        # è¾…åŠ©éªŒè¯æ¨¡å‹
        'validation_models': ['gpt4o-mini', 'gemini-flash', 'claude-haiku'],
        
        # å…±è¯†é˜ˆå€¼è®¾ç½®
        'consensus_threshold': 0.6,     # 60%ä¸€è‡´æ€§é˜ˆå€¼
        'high_confidence_threshold': 0.8, # 80%é«˜ç½®ä¿¡åº¦é˜ˆå€¼
        
        # éªŒè¯è¡Œä¸ºæ§åˆ¶
        'enable_arbitration': True,      # å¯ç”¨ä»²è£æœºåˆ¶
        'arbitrator_model': 'claude-haiku', # ä»²è£æ¨¡å‹
        'max_models_per_validation': 5,  # å•æ¬¡éªŒè¯æœ€å¤§æ¨¡å‹æ•°
        'timeout_seconds': 120,          # éªŒè¯è¶…æ—¶æ—¶é—´
        
        # æ€§èƒ½æ§åˆ¶
        'enable_optimization': True,     # å¯ç”¨æ€§èƒ½ä¼˜åŒ–
        'timeout_per_request': 60,       # å•ä¸ªè¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’)
        
        # è´¨é‡æ§åˆ¶
        'minimum_models_for_consensus': 2, # æœ€å°‘æ¨¡å‹æ•°é‡
        'disagreement_alert_threshold': 3, # åˆ†æ­§è­¦æŠ¥é˜ˆå€¼
        
        # ç¼“å­˜è®¾ç½®
        'enable_response_cache': False,   # å¯ç”¨å“åº”ç¼“å­˜
        'cache_duration_minutes': 30,     # ç¼“å­˜æŒç»­æ—¶é—´
    }
    
    # VPAåˆ†æä¸“ç”¨è®¾ç½®
    VPA_ANALYSIS_CONFIG = {
        # VPAä¿¡å·æƒé‡ï¼ˆç”¨äºå…±è¯†è®¡ç®—ï¼‰
        'signal_weights': {
            'market_phase': 0.30,      # å¸‚åœºé˜¶æ®µï¼ˆæœ€é‡è¦ï¼‰
            'vpa_signal': 0.25,        # VPAä¿¡å·
            'price_direction': 0.25,   # ä»·æ ¼æ–¹å‘
            'confidence': 0.10,        # ç½®ä¿¡åº¦
            'key_levels': 0.10         # å…³é”®ä»·ä½
        },
        
        # å…³é”®ä»·ä½å®¹å·®
        'key_level_tolerance': 0.01,     # 1%ä»·æ ¼å®¹å·®
        
        # åˆ†ææ·±åº¦è®¾ç½®
        'default_lookback_bars': 50,     # é»˜è®¤å›çœ‹Kçº¿æ•°é‡
        'pattern_analysis_bars': 30,     # å½¢æ€åˆ†æKçº¿æ•°é‡
        'volume_analysis_period': 20,    # æˆäº¤é‡åˆ†æå‘¨æœŸ
        
        # è´¨é‡è¯„åˆ†æ ‡å‡†
        'quality_score_weights': {
            'vpa_terminology': 30,        # VPAæœ¯è¯­ä½¿ç”¨
            'market_phase_clarity': 25,   # å¸‚åœºé˜¶æ®µè¯†åˆ«æ¸…æ™°åº¦
            'data_reference': 20,         # æ•°æ®å¼•ç”¨å…·ä½“æ€§
            'trading_signals': 15,        # äº¤æ˜“ä¿¡å·è´¨é‡
            'risk_assessment': 10         # é£é™©è¯„ä¼°å®Œæ•´æ€§
        }
    }
    
    # Analysis settings - Token Limits (OpenRouter 2025 Latest)
    TOKEN_LIMITS = {
        # ğŸ”¥ 2025 Latest Flagship Models
        'gpt5-chat': 400000,     # GPT-5 Chat (400K context)
        'gpt5-mini': 400000,     # GPT-5 Mini (400K context)
        'gpt5-nano': 400000,     # GPT-5 Nano (400K context)
        'claude-opus-41': 500000, # Claude Opus 4.1 (500K context)
        'gemini-25-pro': 10000000, # Gemini 2.5 Pro (10M context)
        'grok4': 1000000,        # Grok 4 (1M context)
        
        # OpenAI Models
        'gpt4': 128000,         # GPT-4 Turbo
        'gpt4o': 128000,        # GPT-4o
        'gpt4o-mini': 128000,   # GPT-4o mini
        'o1': 200000,           # o1 reasoning model
        'o1-mini': 128000,      # o1 mini
        
        # Anthropic Claude Models
        'claude': 200000,       # Claude 3.5 Sonnet
        'claude-haiku': 200000, # Claude 3.5 Haiku
        'claude-opus': 200000,  # Claude 3 Opus
        
        # Google Gemini Models
        'gemini': 2097152,      # Gemini Pro 1.5 (2M tokens)
        'gemini-flash': 1048576, # Gemini Flash 1.5 (1M tokens)
        'gemini-2': 1048576,    # Gemini 2.0 Flash
        
        # xAI Grok Models
        'grok': 131072,         # Grok Beta (128K)
        'grok-vision': 131072,  # Grok Vision Beta
        
        # Meta Llama Models
        'llama': 131072,        # Llama 3.1 70B (128K)
        'llama-405b': 131072    # Llama 3.1 405B (128K)
    }
    
    @classmethod
    def validate(cls):
        """éªŒè¯å¿…éœ€çš„é…ç½®æ˜¯å¦å­˜åœ¨"""
        if not cls.OPENROUTER_API_KEY:
            raise ValueError("OPENROUTER_API_KEY is required. Please set it in .env file")
        
        # éªŒè¯å¤šæ¨¡å‹éªŒè¯é…ç½®
        validation_config = cls.VALIDATION_CONFIG
        
        # æ£€æŸ¥ä¸»è¦æ¨¡å‹æ˜¯å¦åœ¨å¯ç”¨æ¨¡å‹åˆ—è¡¨ä¸­
        for model in validation_config['primary_models']:
            if model not in cls.MODELS:
                raise ValueError(f"Primary model '{model}' not found in available models")
        
        # æ£€æŸ¥éªŒè¯æ¨¡å‹æ˜¯å¦åœ¨å¯ç”¨æ¨¡å‹åˆ—è¡¨ä¸­
        for model in validation_config['validation_models']:
            if model not in cls.MODELS:
                raise ValueError(f"Validation model '{model}' not found in available models")
        
        # æ£€æŸ¥ä»²è£æ¨¡å‹
        arbitrator = validation_config['arbitrator_model']
        if arbitrator not in cls.MODELS:
            raise ValueError(f"Arbitrator model '{arbitrator}' not found in available models")
        
        # éªŒè¯é˜ˆå€¼è®¾ç½®åˆç†æ€§
        if not 0 < validation_config['consensus_threshold'] <= 1:
            raise ValueError("Consensus threshold must be between 0 and 1")
        
        if not 0 < validation_config['high_confidence_threshold'] <= 1:
            raise ValueError("High confidence threshold must be between 0 and 1")
        
        # éªŒè¯VPAé…ç½®æƒé‡æ€»å’Œ
        vpa_weights = cls.VPA_ANALYSIS_CONFIG['signal_weights']
        total_weight = sum(vpa_weights.values())
        if abs(total_weight - 1.0) > 0.01:  # å…è®¸1%è¯¯å·®
            raise ValueError(f"VPA signal weights must sum to 1.0, got {total_weight}")
        
        quality_weights = cls.VPA_ANALYSIS_CONFIG['quality_score_weights']
        total_quality_weight = sum(quality_weights.values())
        if total_quality_weight != 100:
            raise ValueError(f"Quality score weights must sum to 100, got {total_quality_weight}")
        
        return True
    
    @classmethod
    def get_validation_config(cls):
        """è·å–éªŒè¯é…ç½®"""
        return cls.VALIDATION_CONFIG.copy()
    
    @classmethod
    def get_vpa_config(cls):
        """è·å–VPAåˆ†æé…ç½®"""
        return cls.VPA_ANALYSIS_CONFIG.copy()
    
    @classmethod
    def get_model_tiers(cls):
        """è·å–æ¨¡å‹åˆ†çº§ä¿¡æ¯"""
        return {
            'flagship': ['gpt5-chat', 'gpt5-mini', 'claude-opus-41', 'gemini-25-pro', 'grok4'],
            'production': ['gpt4o', 'claude', 'gemini'],
            'economy': ['gpt4o-mini', 'claude-haiku', 'gemini-flash', 'gpt5-nano'],
            'reasoning': ['o1', 'o1-mini'],
            'large_context': ['gemini-25-pro', 'claude-opus-41', 'gemini'],
        }
    
    # Model recommendations for different analysis types
    RECOMMENDED_MODELS = {
        'simple': ['gemini-flash', 'gpt5-nano', 'gpt4o-mini'],
        'complete': ['gpt4o-mini', 'claude', 'gemini'],
        'enhanced': ['gpt5-mini', 'claude-opus-41', 'gpt5-chat']
    }
    
    # åˆ†ææ¨¡å¼é…ç½®
    ANALYSIS_MODES = {
        'simple': {
            'default_model': 'gemini-flash',
            'fallback_model': 'gpt4o-mini',
            'timeout': 20
        },
        'complete': {
            'default_model': 'gpt4o-mini',
            'fallback_model': 'claude',
            'timeout': 45
        },
        'enhanced': {
            'default_model': 'gpt5-mini',
            'fallback_model': 'claude-opus-41',
            'timeout': 90
        }
    }

    @classmethod
    def get_recommended_models_for_task(cls, analysis_type: str = 'simple'):
        """æ ¹æ®åˆ†æç±»å‹è·å–æ¨èæ¨¡å‹"""
        return cls.RECOMMENDED_MODELS.get(analysis_type, cls.RECOMMENDED_MODELS['simple'])